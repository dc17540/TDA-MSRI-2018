{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "theCsv[\"avg_bottle_dist_dim0\"] =theCsv5[\"avg_bottle_dist_dim0\"]\n",
    "theCsv[\"sd_bottle_dist_dim0\"] =theCsv5[\"sd_bottle_dist_dim0\"]\n",
    "\n",
    "\n",
    "#theCsv[\"avg_bottle_dist_dim0\"] =theCsv6[\"avg_bottle_dist_dim0\"]\n",
    "#theCsv[\"sd_bottle_dist_dim0\"] =theCsv6[\"sd_bottle_dist_dim0\"]\n",
    "\n",
    "theCsv[\"avg_bottle_dist_dim0\"] =theCsv7[\"avg_bottle_dist_dim0\"]\n",
    "theCsv[\"sd_bottle_dist_dim0\"] =theCsv7[\"sd_bottle_dist_dim0\"]\n",
    "118\n",
    "\n",
    "['N', 'R', 'R', 'N', 'N', 'AF', 'N', 'R', 'N', 'AF', 'N', 'N', 'N', 'R', 'AF', 'AF', 'N', 'AF', 'N', 'N', 'N', 'R', 'R', 'R', 'AF', 'R', 'N', 'N', 'R', 'R', 'R', 'N', 'N', 'AF', 'N', 'R', 'N', 'R', 'R', 'AF', 'AF', 'N', 'R', 'R', 'N', 'N', 'R', 'N', 'N', 'R', 'AF', 'AF', 'N', 'R', 'R', 'AF', 'AF', 'N', 'N', 'N', 'N', 'N', 'AF', 'R', 'R', 'N', 'R', 'R', 'N', 'AF', 'AF', 'N', 'R', 'AF', 'R', 'R', 'AF', 'AF', 'R', 'R', 'AF', 'R', 'R', 'AF', 'N', 'N', 'N', 'AF', 'AF', 'AF', 'AF', 'R', 'N', 'AF', 'AF', 'AF', 'AF', 'N', 'R', 'N', 'N', 'AF', 'R', 'AF', 'N', 'R', 'N', 'AF', 'AF', 'R', 'N', 'R', 'R', 'R', 'AF', 'AF', 'AF', 'N', 'R', 'R', 'N', 'N', 'AF', 'R', 'N', 'N', 'R', 'AF', 'R', 'R', 'N', 'R', 'N', 'N', 'R', 'N', 'N', 'N', 'AF', 'N', 'N', 'AF', 'N', 'N', 'R', 'N', 'AF', 'R', 'N', 'N', 'R', 'R', 'AF', 'AF', 'R', 'AF', 'N', 'R', 'N', 'N', 'AF', 'AF', 'N', 'R', 'AF', 'N', 'AF', 'AF', 'R', 'AF', 'AF', 'AF', 'R', 'R', 'N', 'N', 'R', 'N', 'N', 'AF', 'N', 'AF', 'R', 'R', 'R', 'AF', 'AF', 'R', 'AF', 'AF', 'R', 'R', 'N', 'AF', 'R', 'AF', 'R', 'AF']\n",
    "\n",
    "['N', 'R', 'R', 'N', 'N', 'AF', 'N', 'R', 'N', 'AF', 'N', 'N', 'N', 'R', 'AF', 'AF', 'N', 'AF', 'N', 'N', 'N', 'R', 'R', 'R', 'AF', 'R', 'N', 'N', 'R', 'R', 'R', 'N', 'N', 'AF', 'N', 'R', 'N', 'R', 'R', 'AF', 'AF', 'N', 'R', 'R', 'N', 'N', 'R', 'N', 'N', 'R', 'AF', 'AF', 'N', 'R', 'R', 'AF', 'AF', 'N', 'N', 'N', 'N', 'N', 'AF', 'R', 'R', 'N', 'R', 'R', 'N', 'AF', 'AF', 'N', 'R', 'AF', 'R', 'R', 'AF', 'AF', 'R', 'R', 'AF', 'R', 'R', 'AF', 'N', 'N', 'N', 'AF', 'AF', 'AF', 'AF', 'R', 'N', 'AF', 'AF', 'AF', 'AF', 'N', 'R', 'N', 'N', 'AF', 'R', 'AF', 'N', 'R', 'N', 'AF', 'AF', 'R', 'N', 'R', 'R', 'R', 'AF', 'AF', 'AF', 'N', 'R', 'R', 'N', 'N', 'AF', 'R', 'N', 'N', 'R', 'AF', 'R', 'R', 'N', 'R', 'N', 'N', 'R', 'N', 'N', 'N', 'AF', 'N', 'N', 'AF', 'N', 'N', 'R', 'N', 'AF', 'R', 'N', 'N', 'R', 'R', 'AF', 'AF', 'R', 'AF', 'N', 'R', 'N', 'N', 'AF', 'AF', 'N', 'R', 'AF', 'N', 'AF', 'AF', 'R', 'AF', 'AF', 'AF', 'R', 'R', 'N', 'N', 'R', 'N', 'N', 'AF', 'N', 'AF', 'R', 'R', 'R', 'AF', 'AF', 'R', 'AF', 'AF', 'R', 'R', 'N', 'AF', 'R', 'AF', 'R', 'AF']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "theTotal = []\n",
    "classDict = {}\n",
    "lineCount = 0\n",
    "\n",
    "x = open(\"REFERENCE-v3.csv\")\n",
    "for line in x:\n",
    "    line = line.strip()\n",
    "    a,b = line.split(\",\")\n",
    "    theTotal.append(b)\n",
    "    \n",
    "    \n",
    "\n",
    "  \n",
    "#theFrame = {\"mean\":[],\"std_dev\":[],\"theClass\":[]}\n",
    "\n",
    "theCsv = pd.read_csv(\"0_8528_Organized_Mean_sd_dimension_0.csv\", index_col=0)\n",
    "theCsv2 = pd.read_csv(\"0_8528_Organized_Mean_sd_dimension_1.csv\",index_col=0)\n",
    "theCsv3 = pd.read_csv(\"0-8528_Organized_Mean_sd_dimension_2.csv\",index_col=0)\n",
    "'''\n",
    "theCsv2 = pd.read_csv(\"Mean_sd_dimension_1.csv\",index_col=0)\n",
    "theCsv3 = pd.read_csv(\"Mean_sd_dimension_2.csv\",index_col=0)\n",
    "theCsv4 = pd.read_csv(\"Lifetimes_dim_0_1_2.csv\",index_col=0)\n",
    "theCsv5 = pd.read_csv(\"Maximum_lifetimes_all_dims.csv\",index_col=0)\n",
    "theCsv6 = pd.read_csv(\"reduced_bottleneck_ave_sd_dist_dim1.csv\",index_col=0)\n",
    "theCsv7 = pd.read_csv(\"reduced_bottleneck_ave_sd_dist_dim2.csv\",index_col=0)\n",
    "theCsv8 = pd.read_csv(\"number_of_births_deaths_dim0.csv\",index_col=0)\n",
    "theCsv9 = pd.read_csv(\"number_of_births_deaths_dim1.csv\",index_col=0)\n",
    "theCsv10 = pd.read_csv(\"number_of_births_deaths_dim2.csv\",index_col=0)\n",
    "theCsv11 = pd.read_csv(\"skewness_birth_dim012.csv\",index_col=0)\n",
    "theCsv12 = pd.read_csv(\"skewness_death_dim012.csv\",index_col=0)\n",
    "theCsv13 = pd.read_csv(\"a.csv\",index_col=0)\n",
    "theCsv14 = pd.read_csv(\"Total_matrix_RR_interval_2392.csv\",index_col=0)\n",
    "theCsv15 = pd.read_csv(\"rr_normal.csv\",index_col=0)\n",
    "theCsv16 = pd.read_csv(\"rr_R.csv\",index_col=0)\n",
    "'''\n",
    "#theCsv8 = pd.read_csv(\"reduced_bottleneck_ave_sd_dist_dim2.csv\",index_col=0)\n",
    "#bigData = theCsv.append(theCsv2, ignore_index=True)\n",
    "\n",
    "#print(bigData)\n",
    "\n",
    "aList = []\n",
    "aList2 = []\n",
    "aList3 = []\n",
    "for i in range(0,200):\n",
    "    aList.append(\"N\")\n",
    "    aList2.append(0)\n",
    "    aList3.append(0)\n",
    "\n",
    "for i in range(0,200):\n",
    "    aList.append(\"AF\")\n",
    "    aList2.append(1)\n",
    "    aList3.append(0)\n",
    "    \n",
    "for i in range(0,200):\n",
    "    aList.append(\"R\")\n",
    "    aList2.append(0)\n",
    "    aList3.append(1)\n",
    "\n",
    "#theCsv[\"Normal\"] = np.asarray(aList)\n",
    "#theCsv[\"AF\"] = np.asarray(aList2)\n",
    "#theCsv[\"Random\"] = np.asarray(aList3)\n",
    "#### make dataframe \n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#theCsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#theCsv2.loc[599] =[0,0,0,0]\n",
    "#theCsv2.loc[600] =[0,0,0,0]\n",
    "#theCsv2\n",
    "#bigdata = pd.concat([theCsv, theCsv2])\n",
    "\n",
    "\n",
    "#theCsv[\"RR_AF_mean\"] = theCsv14[\"0\"]\n",
    "#theCsv[\"RR_AF_SD\"] = theCsv14[\"1\"]\n",
    "#theCsv[\"RR_AF_Skew\"] = theCsv14[\"3\"]\n",
    "\n",
    "theCsv[\"Means_dim1_birth\"] = theCsv2[\"Means_dim1_birth\"]\n",
    "theCsv[\"Means_dim1_death\"] = theCsv2[\"Means_dim1_birth\"]\n",
    "theCsv[\"sd_dim1_birth\"] = theCsv2[\"sd_dim1_birth\"]\n",
    "theCsv[\"sd_dim1_death\"] =theCsv2[\"sd_dim1_death\"]\n",
    "\n",
    "#theCsv[\"Means_dim2_birth\"] = theCsv3[\"Means_dim2_birth\"]\n",
    "theCsv[\"Means_dim2_death\"] = theCsv3[\"Means_dim2_birth\"]\n",
    "theCsv[\"sd_dim2_birth\"] = theCsv3[\"sd_dim2_birth\"]\n",
    "theCsv[\"sd_dim2_death\"] =theCsv3[\"sd_dim2_death\"]\n",
    "'''\n",
    "#theCsv[\"Means_dim0_birth\"] = theCsv4[\"Means_dim0_birth\"]\n",
    "#theCsv[\"Means_dim0_death\"] = theCsv4[\"Means_dim0_birth\"]\n",
    "#theCsv[\"sd_dim0_birth\"] = theCsv4[\"sd_dim0_birth\"]\n",
    "#theCsv[\"sd_dim0_death\"] =theCsv4[\"sd_dim0_death\"]\n",
    "\n",
    "\n",
    "theCsv[\"Lifetime_dim0\"] = theCsv4[\"Lifetime_dim0\"]\n",
    "theCsv[\"Lifetime_dim1\"] = theCsv4[\"Lifetime_dim1\"]\n",
    "theCsv[\"Lifetime_dim2\"] =theCsv4[\"Lifetime_dim2\"]\n",
    "\n",
    "\n",
    "#theCsv[\"avg_bottle_dist_dim0\"] =theCsv5[\"Max_life_dim0\"]\n",
    "#theCsv[\"sd_bottle_dist_dim0\"] =theCsv5[\"Max_life_dim1\"]\n",
    "\n",
    "\n",
    "#theCsv[\"avg_bottle_dist_dim1\"] =theCsv5[\"Max_life_dim0\"]\n",
    "#theCsv[\"sd_bottle_dist_dim1\"] =theCsv6[\"V2\"]\n",
    "\n",
    "#theCsv[\"avg_bottle_dist_dim2\"] =theCsv7[\"V1\"]\n",
    "#theCsv[\"sd_bottle_dist_dim2\"] =theCsv7[\"V2\"]\n",
    "\n",
    "#theCsv[\"num_dim0\"] = theCsv8[\"x\"]\n",
    "#theCsv[\"num_dim1\"] = theCsv9[\"x\"]\n",
    "#theCsv[\"num_dim2\"] = theCsv10[\"x\"]\n",
    "\n",
    "#theCsv[\"num_dim1\"] = theCsv10[\"x\"]\n",
    "\n",
    "#theCsv[\"skew_death1\"] =theCsv12[\"skew.death.dim1\"]\n",
    "#theCsv[\"skew_death2\"] =theCsv12[\"skew.death.dim2\"]\n",
    "#theCsv[\"skew_death0\"] =theCsv12[\"skew.death.dim0\"]\n",
    "\n",
    "\n",
    "theCsv[\"skew_birth1\"] = theCsv11[\"skew.birth.dim1\"]\n",
    "#theCsv[\"skew_birth2\"] = theCsv11[\"skew.birth.dim2\"]\n",
    "print(len(theCsv[\"skew_birth1\"]))\n",
    "\n",
    "theCsv[\"num_per0\"] = theCsv14[\"0\"]\n",
    "theCsv[\"num_per1\"] = theCsv14[\"1\"]\n",
    "theCsv[\"num_per2\"] = theCsv14[\"2\"]\n",
    "theCsv[\"num_per2\"] = theCsv14[\"3\"]\n",
    "\n",
    "\n",
    "\n",
    "#theCsv[\"RR_R_mean\"] = theCsv16[\"0\"]\n",
    "#print(theCsv)\n",
    "#theCsv\n",
    "#print(np.isnan(theCsv))\n",
    "\n",
    "#theCsv[\"num_per0\"][1956] = 1000\n",
    "#theCsv[\"num_per1\"][1956] = 1000\n",
    "#theCsv[\"num_per2\"][1956] = 1000\n",
    "print(len(theTotal))\n",
    "'''\n",
    "theCsv[\"Normal\"] = theTotal\n",
    "#theCsv\n",
    "#print(theCsv)\n",
    "#print(theTotal)\n",
    "#theCsv.fillna(theCsv.mean())\n",
    "\n",
    "#print(np.where(theCsv.values >= np.finfo(np.float64).max))\n",
    "theCsv\n",
    "theCsv = theCsv.loc[:, ~theCsv.columns.str.contains('^Unnamed')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N', 'N', 'N', 'O', 'O', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'N', '~', 'N', 'N', 'O', 'O', 'N', 'O', 'N', 'O', 'A', 'O', '~', 'N', 'N', 'O', 'N', 'O', 'N', 'N', 'O', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'O', 'A', 'N', 'N', 'N', 'A', 'N', 'O', 'N', 'N', 'A', 'N', 'N', 'N', 'N', 'O', 'N', 'O', 'N', 'O', 'A', 'O', 'O', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'N', '~', 'O', 'A', 'N', 'N', 'O', 'A', 'O', 'N', 'N', 'O', 'N', 'A', 'N', 'O', 'A', 'N', 'N', 'N', 'O', 'N', 'O', 'O', 'N', 'N', 'N', 'N', 'O', 'N', '~', 'A', 'N', 'N', 'N', 'N', '~', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'A', 'N', 'N', 'N', 'N', 'O', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'O', 'N', 'O', 'N', 'A', 'N', 'N', 'A', 'N', 'O', 'A', 'O', 'N', 'N', 'O', 'N', 'A', 'N', 'N', 'N', 'O', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'O', 'A', 'O', 'A', 'O', 'O', 'A', 'O', 'O', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'O', 'N', 'A', 'O', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'O', 'O', 'O', 'N', 'A', 'N', 'O', 'A', 'N', 'O', 'O', 'A', 'N', 'A', 'N', 'N', 'N', 'N', 'N', 'O', 'A', 'N', 'A', 'N', 'N', 'N', 'N', 'O', 'A', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'O', 'N', 'O', 'N', 'N', 'N', 'N', 'A', 'N', 'A', 'A', 'N', 'O', 'A', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'A', 'N', 'O', 'N', 'N', 'N', 'O', 'N', 'N', '~', 'O', 'O', 'N', 'N', 'N', 'N', 'A', 'O', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'O', 'N', 'O', 'N', 'N', 'N', '~', 'N', 'N', 'O', 'N', '~', 'N', 'N', 'N', 'O', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'A', 'N', 'N', 'N', 'N', 'O', 'O', 'N', 'O', 'N', 'N', 'A', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'A', 'O', 'N', 'O', 'O', 'O', 'N', '~', 'N', 'O', 'N', 'N', 'N', 'O', 'N', 'O', 'N', 'N', 'N', 'O', 'O', 'N', 'N', 'O', 'N', 'O', 'A', 'N', 'N', 'O', 'O', 'N', 'N', 'O', 'A', 'N', 'N', 'O', 'N', 'N', 'N', 'A', 'N', 'O', 'N', 'N', 'N', 'A', 'N', 'N', 'N', 'N', 'A', 'N', 'A', 'N', 'O', 'N', 'N', 'O', 'O', 'N', 'A', 'N', 'N', 'N', 'O', 'N', 'O', 'N', '~', '~', 'N', 'N', 'A', 'N', 'N', 'N', 'N', 'O', 'O', 'O', '~', 'O', 'N', 'N', 'O', 'O', 'N', 'N', 'N', '~', 'N', 'O', 'N', 'N', 'N', 'O', 'A', 'N', 'N', 'A', 'N', 'O', 'O', 'N', 'A', 'N', 'N', 'O', 'O', 'O', 'N', 'N', 'N', 'N', 'O', 'A', 'N', 'N', 'A', '~', 'N', 'N', 'O', 'O', 'N', 'A', 'O', 'O', 'O', 'A', 'O', 'N', '~', 'N', 'O', 'N', 'O', 'N', 'A', 'O', 'N', 'O', 'O', 'N', 'O', 'N', '~', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'O', 'N', 'N', 'O', 'N', 'N', 'O', 'N', 'O', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'A', 'N', 'N', 'A', 'N', 'N', 'O', 'N', 'O', 'A', 'N', 'N', 'N', 'N', 'O', 'O', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'O', 'A', 'N', 'N', 'N', 'N', 'A', 'N', 'N', 'N', 'O', 'O', 'N', 'O', '~', 'O', 'N', 'A', '~', 'N', 'N', 'O', 'O', 'N', 'N', 'N', 'O', 'O', 'A', 'N', 'A', 'A', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'A', 'O', 'N', 'O', 'O', 'O', 'O', 'O', 'A', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'A', 'A', 'O', 'N', 'O', 'N', 'O', 'O', 'A', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'N', '~', 'N', 'N', 'N', 'O', 'A', 'N', 'N', 'N', 'N', 'N', 'N', '~', 'O', 'O', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'O', '~', 'N', 'O', 'N', 'A', 'O', 'N', 'N', 'N', 'O', 'N', 'O', 'O', 'N', 'N', 'O', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'O', 'O', 'N', 'O', 'N', 'O', 'A', 'N', 'N', 'N', 'O', 'A', 'O', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'A', 'O', 'N', 'N', 'N', 'O', 'O', 'N', 'N', 'N', 'O', 'N', 'N', 'O', 'N', 'O', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'O', 'O', 'N', 'A', 'N', 'O', 'O', 'O', 'A', 'O', 'O', 'O', 'N', 'N', 'N', 'O', 'O', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'O', 'N', 'O', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'O', 'N', 'N', 'N', 'N', 'O', 'N', 'O', 'N', 'N', '~', 'N', 'N', 'O', 'N', 'N', 'O', 'N', 'A', 'O', 'O', 'N', 'N', 'N', 'N', 'O', 'O', 'N', 'N', 'N', 'O', 'N', '~', 'N', 'N', 'N', 'N', 'A', 'N', 'O', 'N', 'N', 'N', 'N', 'O', 'N', 'O', 'N', 'A', 'A', 'O', '~', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'O', '~', 'O', 'O', 'N', 'O', 'O', 'O', 'N', 'O', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'O', 'N', 'O', 'O', 'N', 'N', 'N', 'O', 'N', 'A', 'N', 'N', 'N', 'N', 'A', 'N', 'N', 'N', 'N', 'O', 'O', 'A', 'N', 'O', 'N', '~', 'O', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'O', 'O', 'N', 'N', '~', 'A', 'O', 'N', 'N', 'N', 'O', 'N', 'O', 'O', 'N', '~', 'O', 'O', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'O', 'A', 'A', 'O', '~', 'N', 'N', 'N', 'N', 'A', 'N', 'N', 'N', 'N', 'N', 'O', '~', 'O', 'O', 'A', 'O', 'N', 'O', 'N', 'N', 'A', 'O', 'O', 'N', 'N', 'N', 'N', 'N', 'A', 'N', 'O', 'N', '~', '~', 'A', 'O', 'N', '~', 'N', 'O', 'O', 'N', 'N', 'N', 'A', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'O', 'A', 'O', 'O', 'O', 'N', 'O', 'O', 'N', 'N', 'N', 'N', 'N', 'O', 'O', 'O', 'O', 'N', 'N', 'N', 'O', 'O', 'N', '~', 'O', 'N', 'N', 'O', 'O', 'N', 'O', 'A', 'N', 'N', 'N', 'O', 'N', 'N', 'O', 'N', 'N', 'N', 'O', 'N', 'O', 'O', 'N', 'O', 'N', 'N', 'O', 'N', 'N', 'N', 'O', 'A', 'N', 'N', 'O', 'O', 'O', 'O', 'O', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'O', 'N', 'N', 'A', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'N', '~', 'N', 'A', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'O', 'N', 'N', 'O', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'A', 'N', 'N', 'O', 'N', 'N', 'N', '~', 'N', 'A', '~', 'N', 'N', 'O', 'N', 'O', 'N', 'N', 'N', 'O', 'A', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'A', 'O', 'O', 'N', 'O', 'N', 'N', 'N', 'N', 'O', 'O', 'O', 'N', 'O', 'N', 'N', 'O', 'O', 'N', 'O', 'N', 'O', 'N', 'O', 'N', 'O', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'A', 'O', 'N', 'O', 'N', 'O', 'N', 'A', 'N', 'N', 'N', 'N', 'O', 'O', 'N', 'N', 'N', '~', 'N', 'N', 'O', 'N', 'N', 'O', 'O', 'N', 'N', 'O', 'O', 'N', 'N', 'O', 'N', 'N', 'O', 'O', 'A', 'O', 'N', 'N', 'O', 'N', 'N', 'O', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'A', 'A', 'O', 'O', 'O', 'O', 'O', 'N', 'O', 'N', 'A', 'O', 'N', 'O', 'O', 'N', 'N', 'N', 'N', 'N', '~', 'O', 'N', 'N', 'O', 'N', 'N', 'A', 'O', 'N', 'N', 'A', 'N', 'A', 'O', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'O', 'N', 'O', 'O', 'N', 'N', 'N', 'O', '~', 'N', 'N', 'N', 'A', 'O', 'N', 'A', 'N', 'N', 'A', 'O', 'A', 'O', 'N', 'O', 'N', 'O', 'N', 'N', 'N', 'N', 'A', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'O', 'N', 'N', 'N', 'A', 'O', 'N', 'A', 'A', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'O', 'N', 'O', 'N', 'N', 'O', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'A', 'N', 'A', 'A', 'O', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'O', 'N', '~', 'O', 'N', 'O', '~', 'N', 'N', '~', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'O', 'O', 'N', 'N', 'O', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'A', 'N', 'N', 'A', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'O', 'O', 'O', 'N', 'O', 'N', 'O', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'O', 'N', 'N', 'N', 'O', 'O', 'N', 'N', 'O', 'N', 'O', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'A', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'A', 'N', 'N', 'N', 'N', 'N', 'O', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'A', 'N', 'O', 'N', 'N', 'O', 'A', 'N', 'N', 'O', 'N', 'N', 'O', 'N', 'O', 'A', 'N', 'N', 'O', 'A', 'N', 'N', 'N', 'N', 'N', 'O', 'O', 'N', 'N', 'O', 'N', 'O', 'N', 'O', 'O', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'O', 'O', 'N', 'N', '~', 'O', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'O', 'N', 'O', 'O', 'N', 'N', 'O', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'N', '~', 'O', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'O', 'O', 'N', 'N', 'O', 'N', 'O', 'N', 'N', 'N', 'O', 'A', 'N', 'N', '~', 'O', 'N', 'O', 'N', 'N', 'O', 'N', 'O', 'O', 'A', 'O', 'N', 'N', 'O', 'O', 'N', 'N', 'N', 'N', 'O', 'A', 'N', 'A', 'N', 'O', 'N', 'N', 'N', 'O', 'N', 'N', 'A', 'N', 'O', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'A', 'O', 'A', 'N', 'O', 'N', 'O', 'N', 'N', '~', 'O', 'N', 'N', 'N', 'A', 'N', 'A', 'N', 'O', 'O', 'O', 'O', 'N', 'A', 'N', '~', 'N', 'O', 'A', 'N', 'O', 'N', 'O', 'N', 'N', 'N', 'N', 'O', 'O', 'N', 'N', 'N', 'N', 'O', '~', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'O', 'N', 'A', 'A', 'N', 'N', 'N', 'O', 'O', 'N', 'N', 'A', 'O', 'O', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'A', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'O', 'N', 'N', 'N', 'N', 'A', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'A', 'N', 'N', 'N', 'A', 'A', 'O', 'O', 'O', 'N', 'N', 'A', 'N', 'O', 'N', 'N', 'O', 'O', '~', 'O', 'N', 'N', 'N', 'O', 'O', 'N', 'N', 'O', 'N', 'O', 'N', '~', 'N', 'O', 'A', 'O', 'N', '~', 'A', 'N', 'N', 'N', 'N', 'A', 'N', 'N', 'N', 'N', 'O', 'N', 'O', 'N', 'N', 'N', 'O', 'N', 'O', 'N', 'O', 'O', 'O', 'O', 'O', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'O', 'N', 'O', 'N', 'N', '~', 'N', 'O', 'N', 'A', 'O', 'N', 'N', 'N', '~', 'O', 'O', 'O', 'O', 'O', 'O', 'A', 'N', 'N', 'O', 'N', 'N', 'O', 'N', 'O', 'N', 'O', 'N', 'N', 'O', 'A', 'O', 'N', 'N', '~', 'N', 'O', 'N', 'O', 'N', 'N', 'O', 'N', 'A', 'N', 'A', 'A', 'O', 'N', 'N', 'N', 'O', 'A', 'N', 'O', 'O', 'N', 'O', 'N', 'N', 'O', 'A', 'N', 'O', '~', '~', 'O', 'O', 'A', 'A', 'O', 'O', 'N', 'N', 'O', '~', 'O', 'O', 'N', 'O', 'N', 'N', 'A', 'O', 'O', 'N', 'N', 'O', 'N', 'A', 'O', 'N', 'N', 'N', 'N', 'O', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'O', 'A', 'N', 'N', 'N', 'O', 'A', 'N', 'O', 'N', 'N', 'O', 'N', 'N', 'O', 'O', 'N', 'N', 'N', 'A', 'O', 'O', 'N', 'N', 'N', 'N', 'N', '~', 'O', 'A', 'A', 'N', 'N', 'N', '~', 'N', 'N', 'N', 'N', 'N', 'O', 'O', 'O', 'N', 'O', 'N', 'N', 'N', 'N', 'O', 'O', 'N', '~', '~', 'N', 'N', 'N', 'N', 'N', 'N', 'A', 'N', 'N', 'N', 'N', 'A', 'N', 'N', 'O', 'A', 'N', 'O', 'N', 'N', 'N', 'N', 'O', 'N', 'A', 'N', 'N', 'O', 'N', 'O', '~', 'O', 'N', 'O', '~', 'N', 'N', 'N', 'O', 'N', 'N', 'O', 'N', 'A', 'N', 'O', 'N', 'O', 'N', 'N', 'N', 'A', 'A', 'N', 'O', 'N', 'N', 'O', 'O', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'O', 'O', 'O', 'N', 'A', 'N', 'N', 'N', 'O', 'N', 'O', 'N', 'N', 'A', 'O', 'N', 'O', 'N', 'N', 'N', 'O', 'O', 'A', 'N', 'O', 'O', 'N', 'N', 'N', 'N', 'A', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'N', '~', 'A', 'N', 'O', 'A', 'A', '~', 'O', 'O', 'A', 'O', 'N', 'N', 'N', 'N', 'N', 'A', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'A', 'N', 'O', 'N', 'N', 'O', 'N', 'O', 'N', 'N', 'A', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'O', 'N', 'O', 'A', 'N', 'O', 'O', 'O', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', '~', 'N', 'N', 'N', 'O', 'N', 'N', 'A', 'N', 'N', 'N', 'N', 'O', 'N', 'O', 'N', 'N', 'N', 'O', 'O', 'N', 'O', 'N', 'N', 'N', 'N', 'A', 'N', 'O', 'O', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'A', 'N', 'N', 'O', 'N', 'A', '~', 'N', 'O', 'N', 'O', 'A', 'A', 'N', 'N', 'N', 'N', 'N', '~', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'A', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'A', 'N', 'N', 'O', 'A', 'N', '~', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'N', '~', 'N', 'N', 'N', 'N', 'N', 'O', 'N', '~', 'O', 'N', '~', 'N', 'N', 'N', 'O', 'N', 'O', '~', 'O', 'N', 'A', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'N', '~', 'A', 'N', 'A', 'N', 'N', 'N', 'N', 'N', 'O', 'O', 'N', 'A', 'N', 'N', 'N', '~', 'N', 'A', 'N', 'N', 'O', 'O', 'O', 'O', 'N', 'A', 'N', 'N', 'O', 'N', 'O', 'N', 'O', 'O', 'N', 'O', 'O', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'O', 'O', 'O', 'N', 'O', 'A', 'N', 'N', 'O', 'N', 'O', 'O', 'N', 'N', 'N', 'O', 'O', 'N', 'O', 'O', 'O', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'O', 'N', 'O', 'N', 'N', 'N', 'N', 'O', 'N', 'A', 'N', 'N', 'O', 'O', 'A', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'O', 'N', 'A', 'N', 'O', 'O', 'O', 'A', 'N', 'O', 'O', 'N', 'O', 'N', 'O', 'O', 'N', 'N', '~', 'N', 'N', 'O', 'O', 'N', 'N', 'N', 'O', 'N', 'N', 'A', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'N', '~', 'N', 'N', 'N', 'N', 'N', 'A', 'N', 'O', 'N', 'N', 'A', 'A', 'O', 'N', 'N', 'O', 'N', 'N', 'O', 'A', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'N', '~', 'A', 'O', 'O', 'N', 'N', 'N', 'A', 'N', 'N', 'N', 'N', '~', 'N', 'N', 'O', 'N', '~', 'O', 'A', 'O', 'N', 'N', 'O', 'O', 'N', 'O', 'O', 'A', 'N', 'N', 'A', 'N', 'N', '~', 'N', '~', 'O', 'N', 'N', 'O', 'O', 'N', 'N', 'O', 'O', 'N', 'N', 'O', 'N', 'N', '~', 'N', 'O', 'O', 'O', 'N', 'N', 'O', 'N', 'O', '~', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'O', 'O', 'N', 'N', 'O', 'N', 'O', 'N', 'O', 'N', 'A', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'O', 'N', 'N', 'O', 'N', 'O', 'N', 'O', 'O', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'A', 'A', 'O', 'O', 'N', 'O', 'N', 'N', 'N', 'O', 'N', 'O', 'O', 'N', 'O', 'O', 'N', 'N', 'A', '~', 'N', 'O', 'O', 'O', 'O', 'N', 'N', 'A', '~', 'N', 'A', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'A', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'A', 'O', 'A', 'N', 'A', 'N', 'O', 'O', 'N', 'O', 'N', 'N', 'N', '~', 'N', 'N', 'A', 'N', 'O', 'N', 'O', 'A', 'A', 'N', 'A', 'N', 'N', 'O', 'A', 'N', 'O', 'N', 'O', 'N', 'N', 'N', 'O', 'N', 'N', 'O', 'N', 'N', 'O', 'N', 'O', 'O', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'A', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', '~', 'A', 'N', 'A', 'N', 'N', 'N', 'A', 'N', 'N', 'O', 'N', 'O', 'A', 'N', 'O', 'O', 'N', 'N', 'N', 'A', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'A', 'O', 'A', 'O', 'N', 'O', 'A', 'N', 'O', 'O', 'N', 'A', 'N', 'N', 'N', 'A', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'O', 'N', 'O', 'O', '~', 'N', 'O', 'O', 'O', 'O', 'O', 'N', 'N', 'N', 'O', 'N', 'O', 'N', 'A', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'O', 'O', 'O', 'O', 'N', 'O', 'O', 'O', 'O', 'O', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'A', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'A', 'N', 'N', 'N', 'N', 'A', 'N', 'N', 'N', 'O', '~', 'O', 'N', 'A']\n"
     ]
    }
   ],
   "source": [
    "### code from meduim torwards data scienec example\n",
    "# Labels are the values we want to pred\n",
    "\n",
    "labels = np.array(theCsv[\"Normal\"])\n",
    "\n",
    "# Remove the labels from the features\n",
    "# axis 1 refers to the columns\n",
    "theCsv = theCsv.drop('Normal', axis = 1)\n",
    "#theCsv = theCsv.drop('AF', axis = 1)\n",
    "#theCsv = theCsv.drop('Random', axis = 1)\n",
    "\n",
    "# Saving feature names for later use\n",
    "feature_list = list(theCsv.columns)\n",
    "\n",
    "# Convert to numpy array\n",
    "features = np.array(theCsv)\n",
    "\n",
    "\n",
    "# Using Skicit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(theCsv, labels, test_size = 0.33, random_state = 42)\n",
    "\n",
    "\n",
    "print(test_labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model we are using\n",
    "#from sklearn.ensemble import RandomForest\n",
    "predict_list = []\n",
    "# Instantiate model with 1000 decision trees\n",
    "for i in range(0,1):\n",
    "    #rf = RandomForestClassifier(bootstrap=True,max_depth=20,max_features=\"sqrt\",min_samples_leaf=4,min_samples_split=10,n_estimators=50,random_state=118)\n",
    "    rf = RandomForestClassifier(bootstrap=True,max_depth=10,max_features=\"sqrt\",min_samples_leaf=1,min_samples_split=5,n_estimators=600,random_state=42)\n",
    "\n",
    "rf = RandomForestClassifier(bootstrap=True,max_depth=10,max_features=\"sqrt\",min_samples_leaf=1,min_samples_split=5,n_estimators=600,random_state=42)\n",
    "\n",
    "    \n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(train_features, train_labels)\n",
    "\n",
    "predictions = rf.predict(test_features)\n",
    "predict_list.append(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N' 'N' 'N' ..., 'O' 'N' 'O']\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N' 'N' 'N' ..., 'O' 'N' 'A']\n"
     ]
    }
   ],
   "source": [
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.561342279079\n"
     ]
    }
   ],
   "source": [
    "theMax = 0\n",
    "for i in range(0,1):    \n",
    "    if(accuracy_score(test_labels, predict_list[i]) > theMax):\n",
    "        theMax = np.average(f1_score(test_labels, predictions, average=None))\n",
    "print(theMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  30    6  207    2]\n",
      " [   0 1691   13    1]\n",
      " [  18   39  710    7]\n",
      " [   5   15   56   15]]\n"
     ]
    }
   ],
   "source": [
    "results = confusion_matrix(test_labels, predictions,labels=[\"A\", \"N\", \"O\",\"~\"])\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print('Parameters currently in use:\\n')\n",
    "#print(rf.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7076828762553866\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "var1 = 36/(29+28)\n",
    "var2 = 48/(31+39)\n",
    "var3 = 112/(73+66)\n",
    "\n",
    "print((var1+var2+var3)/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
