{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "theCsv[\"avg_bottle_dist_dim0\"] =theCsv5[\"avg_bottle_dist_dim0\"]\n",
    "theCsv[\"sd_bottle_dist_dim0\"] =theCsv5[\"sd_bottle_dist_dim0\"]\n",
    "\n",
    "\n",
    "#theCsv[\"avg_bottle_dist_dim0\"] =theCsv6[\"avg_bottle_dist_dim0\"]\n",
    "#theCsv[\"sd_bottle_dist_dim0\"] =theCsv6[\"sd_bottle_dist_dim0\"]\n",
    "\n",
    "theCsv[\"avg_bottle_dist_dim0\"] =theCsv7[\"avg_bottle_dist_dim0\"]\n",
    "theCsv[\"sd_bottle_dist_dim0\"] =theCsv7[\"sd_bottle_dist_dim0\"]\n",
    "118\n",
    "\n",
    "['N', 'R', 'R', 'N', 'N', 'AF', 'N', 'R', 'N', 'AF', 'N', 'N', 'N', 'R', 'AF', 'AF', 'N', 'AF', 'N', 'N', 'N', 'R', 'R', 'R', 'AF', 'R', 'N', 'N', 'R', 'R', 'R', 'N', 'N', 'AF', 'N', 'R', 'N', 'R', 'R', 'AF', 'AF', 'N', 'R', 'R', 'N', 'N', 'R', 'N', 'N', 'R', 'AF', 'AF', 'N', 'R', 'R', 'AF', 'AF', 'N', 'N', 'N', 'N', 'N', 'AF', 'R', 'R', 'N', 'R', 'R', 'N', 'AF', 'AF', 'N', 'R', 'AF', 'R', 'R', 'AF', 'AF', 'R', 'R', 'AF', 'R', 'R', 'AF', 'N', 'N', 'N', 'AF', 'AF', 'AF', 'AF', 'R', 'N', 'AF', 'AF', 'AF', 'AF', 'N', 'R', 'N', 'N', 'AF', 'R', 'AF', 'N', 'R', 'N', 'AF', 'AF', 'R', 'N', 'R', 'R', 'R', 'AF', 'AF', 'AF', 'N', 'R', 'R', 'N', 'N', 'AF', 'R', 'N', 'N', 'R', 'AF', 'R', 'R', 'N', 'R', 'N', 'N', 'R', 'N', 'N', 'N', 'AF', 'N', 'N', 'AF', 'N', 'N', 'R', 'N', 'AF', 'R', 'N', 'N', 'R', 'R', 'AF', 'AF', 'R', 'AF', 'N', 'R', 'N', 'N', 'AF', 'AF', 'N', 'R', 'AF', 'N', 'AF', 'AF', 'R', 'AF', 'AF', 'AF', 'R', 'R', 'N', 'N', 'R', 'N', 'N', 'AF', 'N', 'AF', 'R', 'R', 'R', 'AF', 'AF', 'R', 'AF', 'AF', 'R', 'R', 'N', 'AF', 'R', 'AF', 'R', 'AF']\n",
    "\n",
    "['N', 'R', 'R', 'N', 'N', 'AF', 'N', 'R', 'N', 'AF', 'N', 'N', 'N', 'R', 'AF', 'AF', 'N', 'AF', 'N', 'N', 'N', 'R', 'R', 'R', 'AF', 'R', 'N', 'N', 'R', 'R', 'R', 'N', 'N', 'AF', 'N', 'R', 'N', 'R', 'R', 'AF', 'AF', 'N', 'R', 'R', 'N', 'N', 'R', 'N', 'N', 'R', 'AF', 'AF', 'N', 'R', 'R', 'AF', 'AF', 'N', 'N', 'N', 'N', 'N', 'AF', 'R', 'R', 'N', 'R', 'R', 'N', 'AF', 'AF', 'N', 'R', 'AF', 'R', 'R', 'AF', 'AF', 'R', 'R', 'AF', 'R', 'R', 'AF', 'N', 'N', 'N', 'AF', 'AF', 'AF', 'AF', 'R', 'N', 'AF', 'AF', 'AF', 'AF', 'N', 'R', 'N', 'N', 'AF', 'R', 'AF', 'N', 'R', 'N', 'AF', 'AF', 'R', 'N', 'R', 'R', 'R', 'AF', 'AF', 'AF', 'N', 'R', 'R', 'N', 'N', 'AF', 'R', 'N', 'N', 'R', 'AF', 'R', 'R', 'N', 'R', 'N', 'N', 'R', 'N', 'N', 'N', 'AF', 'N', 'N', 'AF', 'N', 'N', 'R', 'N', 'AF', 'R', 'N', 'N', 'R', 'R', 'AF', 'AF', 'R', 'AF', 'N', 'R', 'N', 'N', 'AF', 'AF', 'N', 'R', 'AF', 'N', 'AF', 'AF', 'R', 'AF', 'AF', 'AF', 'R', 'R', 'N', 'N', 'R', 'N', 'N', 'AF', 'N', 'AF', 'R', 'R', 'R', 'AF', 'AF', 'R', 'AF', 'AF', 'R', 'R', 'N', 'AF', 'R', 'AF', 'R', 'AF']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "theTotal = []\n",
    "classDict = {}\n",
    "lineCount = 0\n",
    "\n",
    "x = open(\"200_set_of_Norm_AF_Rand.csv\")\n",
    "for line in x:\n",
    "    line = line.strip()\n",
    "    #print(line)\n",
    "    a,b,c,d = line.split(\",\")\n",
    "    if(lineCount != 0):\n",
    "            #normalListTrain.append(b)\n",
    "            theTotal.append(b)\n",
    "            classDict[b] = [\"N\"]\n",
    "            #normalListTest.append(b)\n",
    "            #AFListTrain.append(c)\n",
    "            theTotal.append(c)\n",
    "            classDict[c] = [\"AF\"]\n",
    "            #AFListTest.append(c)\n",
    "            #randomListTest.append(d)\n",
    "            theTotal.append(d)\n",
    "            classDict[\"d\"] = [\"R\"]\n",
    "    lineCount += 1\n",
    "\n",
    "            \n",
    "theFrame = {\"mean\":[],\"std_dev\":[],\"theClass\":[]}\n",
    "\n",
    "theCsv = pd.read_csv(\"Reduced_Pers_Mean_sd_dimension_0.csv\", index_col=0)\n",
    "theCsv2 = pd.read_csv(\"Reduced_Pers_Mean_sd_dimension_1.csv\",index_col=0)\n",
    "theCsv3 = pd.read_csv(\"Reduced_Pers_Mean_sd_dimension_2.csv\",index_col=0)\n",
    "theCsv4 = pd.read_csv(\"Reduced_Pers_Lifetimes_dim_0_1_2.csv\",index_col=0)\n",
    "theCsv5 = pd.read_csv(\"reduced_bottleneck_ave_sd_dim0.csv\",index_col=0)\n",
    "theCsv6 = pd.read_csv(\"reduced_bottleneck_ave_sd_dist_dim1.csv\",index_col=0)\n",
    "theCsv7 = pd.read_csv(\"reduced_bottleneck_ave_sd_dist_dim2.csv\",index_col=0)\n",
    "#theCsv8 = pd.read_csv(\"reduced_bottleneck_ave_sd_dist_dim2.csv\",index_col=0)\n",
    "#bigData = theCsv.append(theCsv2, ignore_index=True)\n",
    "\n",
    "#print(bigData)\n",
    "\n",
    "aList = []\n",
    "aList2 = []\n",
    "aList3 = []\n",
    "for i in range(0,200):\n",
    "    aList.append(\"N\")\n",
    "    aList2.append(0)\n",
    "    aList3.append(0)\n",
    "\n",
    "for i in range(0,200):\n",
    "    aList.append(\"AF\")\n",
    "    aList2.append(1)\n",
    "    aList3.append(0)\n",
    "    \n",
    "for i in range(0,200):\n",
    "    aList.append(\"R\")\n",
    "    aList2.append(0)\n",
    "    aList3.append(1)\n",
    "\n",
    "#theCsv[\"Normal\"] = np.asarray(aList)\n",
    "#theCsv[\"AF\"] = np.asarray(aList2)\n",
    "#theCsv[\"Random\"] = np.asarray(aList3)\n",
    "#### make dataframe \n",
    "###\n",
    "#bigData  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#theCsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#theCsv2.loc[599] =[0,0,0,0]\n",
    "#theCsv2.loc[600] =[0,0,0,0]\n",
    "#theCsv2\n",
    "#bigdata = pd.concat([theCsv, theCsv2])\n",
    "\n",
    "theCsv[\"Means_dim1_birth\"] = theCsv2[\"Means_dim1_birth\"]\n",
    "theCsv[\"Means_dim1_death\"] = theCsv2[\"Means_dim1_birth\"]\n",
    "theCsv[\"sd_dim1_birth\"] = theCsv2[\"sd_dim1_birth\"]\n",
    "theCsv[\"sd_dim1_death\"] =theCsv2[\"sd_dim1_death\"]\n",
    "\n",
    "theCsv[\"Means_dim2_birth\"] = theCsv3[\"Means_dim2_birth\"]\n",
    "theCsv[\"Means_dim2_death\"] = theCsv3[\"Means_dim2_birth\"]\n",
    "theCsv[\"sd_dim2_birth\"] = theCsv3[\"sd_dim2_birth\"]\n",
    "theCsv[\"sd_dim2_death\"] =theCsv3[\"sd_dim2_death\"]\n",
    "\n",
    "#theCsv[\"Means_dim0_birth\"] = theCsv4[\"Means_dim0_birth\"]\n",
    "#theCsv[\"Means_dim0_death\"] = theCsv4[\"Means_dim0_birth\"]\n",
    "#theCsv[\"sd_dim0_birth\"] = theCsv4[\"sd_dim0_birth\"]\n",
    "#theCsv[\"sd_dim0_death\"] =theCsv4[\"sd_dim0_death\"]\n",
    "\n",
    "#theCsv[\"Lifetime_dim0\"] = theCsv4[\"Lifetime_dim0\"]\n",
    "#theCsv[\"Lifetime_dim1\"] = theCsv4[\"Lifetime_dim1\"]\n",
    "#theCsv[\"Lifetime_dim2\"] =theCsv4[\"Lifetime_dim2\"]\n",
    "\n",
    "\n",
    "theCsv[\"avg_bottle_dist_dim0\"] =theCsv5[\"V1\"]\n",
    "theCsv[\"sd_bottle_dist_dim0\"] =theCsv5[\"V2\"]\n",
    "\n",
    "\n",
    "#theCsv[\"avg_bottle_dist_dim1\"] =theCsv6[\"V1\"]\n",
    "#theCsv[\"sd_bottle_dist_dim1\"] =theCsv6[\"V2\"]\n",
    "\n",
    "theCsv[\"avg_bottle_dist_dim2\"] =theCsv7[\"V1\"]\n",
    "theCsv[\"sd_bottle_dist_dim2\"] =theCsv7[\"V2\"]\n",
    "\n",
    "#theCsv\n",
    "#print(np.isnan(theCsv))\n",
    "theCsv[\"Normal\"] = np.asarray(aList)\n",
    "#theCsv\n",
    "\n",
    "#theCsv.fillna(theCsv.mean())\n",
    "\n",
    "#print(np.where(theCsv.values >= np.finfo(np.float64).max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N', 'R', 'R', 'N', 'N', 'AF', 'N', 'R', 'N', 'AF', 'N', 'N', 'N', 'R', 'AF', 'AF', 'N', 'AF', 'N', 'N', 'N', 'R', 'R', 'R', 'AF', 'R', 'N', 'N', 'R', 'R', 'R', 'N', 'N', 'AF', 'N', 'R', 'N', 'R', 'R', 'AF', 'AF', 'N', 'R', 'R', 'N', 'N', 'R', 'N', 'N', 'R', 'AF', 'AF', 'N', 'R', 'R', 'AF', 'AF', 'N', 'N', 'N', 'N', 'N', 'AF', 'R', 'R', 'N', 'R', 'R', 'N', 'AF', 'AF', 'N', 'R', 'AF', 'R', 'R', 'AF', 'AF', 'R', 'R', 'AF', 'R', 'R', 'AF', 'N', 'N', 'N', 'AF', 'AF', 'AF', 'AF', 'R', 'N', 'AF', 'AF', 'AF', 'AF', 'N', 'R', 'N', 'N', 'AF', 'R', 'AF', 'N', 'R', 'N', 'AF', 'AF', 'R', 'N', 'R', 'R', 'R', 'AF', 'AF', 'AF', 'N', 'R', 'R', 'N', 'N', 'AF', 'R', 'N', 'N', 'R', 'AF', 'R', 'R', 'N', 'R', 'N', 'N', 'R', 'N', 'N', 'N', 'AF', 'N', 'N', 'AF', 'N', 'N', 'R', 'N', 'AF', 'R', 'N', 'N', 'R', 'R', 'AF', 'AF', 'R', 'AF', 'N', 'R', 'N', 'N', 'AF', 'AF', 'N', 'R', 'AF', 'N', 'AF', 'AF', 'R', 'AF', 'AF', 'AF', 'R', 'R', 'N', 'N', 'R', 'N', 'N', 'AF', 'N', 'AF', 'R', 'R', 'R', 'AF', 'AF', 'R', 'AF', 'AF', 'R', 'R', 'N', 'AF', 'R', 'AF', 'R', 'AF']\n"
     ]
    }
   ],
   "source": [
    "### code from meduim torwards data scienec example\n",
    "# Labels are the values we want to pred\n",
    "\n",
    "labels = np.array(theCsv[\"Normal\"])\n",
    "\n",
    "# Remove the labels from the features\n",
    "# axis 1 refers to the columns\n",
    "theCsv = theCsv.drop('Normal', axis = 1)\n",
    "#theCsv = theCsv.drop('AF', axis = 1)\n",
    "#theCsv = theCsv.drop('Random', axis = 1)\n",
    "\n",
    "# Saving feature names for later use\n",
    "feature_list = list(theCsv.columns)\n",
    "\n",
    "# Convert to numpy array\n",
    "features = np.array(theCsv)\n",
    "\n",
    "\n",
    "# Using Skicit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(theCsv, labels, test_size = 0.33, random_state = 42)\n",
    "\n",
    "\n",
    "print(test_labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model we are using\n",
    "#from sklearn.ensemble import RandomForest\n",
    "predict_list = []\n",
    "# Instantiate model with 1000 decision trees\n",
    "for i in range(0,300):\n",
    "    #rf = RandomForestClassifier(bootstrap=True,max_depth=20,max_features=\"sqrt\",min_samples_leaf=4,min_samples_split=10,n_estimators=50,random_state=118)\n",
    "    rf = RandomForestClassifier(bootstrap=True,max_depth=20,max_features=\"sqrt\",min_samples_leaf=4,min_samples_split=10,n_estimators=50,random_state=i)\n",
    "\n",
    "# Train the model on training data\n",
    "    rf.fit(train_features, train_labels)\n",
    "\n",
    "    predictions = rf.predict(test_features)\n",
    "    predict_list.append(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.560606060606\n",
      "1 0.555555555556\n",
      "2 0.580808080808\n",
      "3 0.585858585859\n",
      "4 0.565656565657\n",
      "5 0.580808080808\n",
      "6 0.565656565657\n",
      "7 0.585858585859\n",
      "8 0.580808080808\n",
      "9 0.560606060606\n",
      "10 0.575757575758\n",
      "11 0.570707070707\n",
      "12 0.570707070707\n",
      "13 0.565656565657\n",
      "14 0.565656565657\n",
      "15 0.540404040404\n",
      "16 0.570707070707\n",
      "17 0.590909090909\n",
      "18 0.560606060606\n",
      "19 0.570707070707\n",
      "20 0.59595959596\n",
      "21 0.550505050505\n",
      "22 0.565656565657\n",
      "23 0.535353535354\n",
      "24 0.555555555556\n",
      "25 0.570707070707\n",
      "26 0.560606060606\n",
      "27 0.560606060606\n",
      "28 0.525252525253\n",
      "29 0.560606060606\n",
      "30 0.570707070707\n",
      "31 0.60101010101\n",
      "32 0.560606060606\n",
      "33 0.565656565657\n",
      "34 0.550505050505\n",
      "35 0.540404040404\n",
      "36 0.585858585859\n",
      "37 0.550505050505\n",
      "38 0.545454545455\n",
      "39 0.585858585859\n",
      "40 0.545454545455\n",
      "41 0.560606060606\n",
      "42 0.565656565657\n",
      "43 0.570707070707\n",
      "44 0.570707070707\n",
      "45 0.555555555556\n",
      "46 0.560606060606\n",
      "47 0.550505050505\n",
      "48 0.565656565657\n",
      "49 0.555555555556\n",
      "50 0.606060606061\n",
      "51 0.580808080808\n",
      "52 0.560606060606\n",
      "53 0.565656565657\n",
      "54 0.560606060606\n",
      "55 0.585858585859\n",
      "56 0.570707070707\n",
      "57 0.580808080808\n",
      "58 0.560606060606\n",
      "59 0.565656565657\n",
      "60 0.580808080808\n",
      "61 0.545454545455\n",
      "62 0.560606060606\n",
      "63 0.585858585859\n",
      "64 0.560606060606\n",
      "65 0.560606060606\n",
      "66 0.545454545455\n",
      "67 0.560606060606\n",
      "68 0.535353535354\n",
      "69 0.540404040404\n",
      "70 0.565656565657\n",
      "71 0.575757575758\n",
      "72 0.535353535354\n",
      "73 0.520202020202\n",
      "74 0.585858585859\n",
      "75 0.555555555556\n",
      "76 0.575757575758\n",
      "77 0.550505050505\n",
      "78 0.570707070707\n",
      "79 0.570707070707\n",
      "80 0.550505050505\n",
      "81 0.555555555556\n",
      "82 0.590909090909\n",
      "83 0.575757575758\n",
      "84 0.565656565657\n",
      "85 0.560606060606\n",
      "86 0.590909090909\n",
      "87 0.575757575758\n",
      "88 0.565656565657\n",
      "89 0.545454545455\n",
      "90 0.565656565657\n",
      "91 0.565656565657\n",
      "92 0.565656565657\n",
      "93 0.580808080808\n",
      "94 0.565656565657\n",
      "95 0.570707070707\n",
      "96 0.565656565657\n",
      "97 0.555555555556\n",
      "98 0.590909090909\n",
      "99 0.545454545455\n",
      "100 0.555555555556\n",
      "101 0.575757575758\n",
      "102 0.570707070707\n",
      "103 0.550505050505\n",
      "104 0.570707070707\n",
      "105 0.616161616162\n",
      "106 0.59595959596\n",
      "107 0.560606060606\n",
      "108 0.560606060606\n",
      "109 0.550505050505\n",
      "110 0.565656565657\n",
      "111 0.550505050505\n",
      "112 0.585858585859\n",
      "113 0.565656565657\n",
      "114 0.585858585859\n",
      "115 0.580808080808\n",
      "116 0.560606060606\n",
      "117 0.560606060606\n",
      "118 0.60101010101\n",
      "119 0.585858585859\n",
      "120 0.550505050505\n",
      "121 0.535353535354\n",
      "122 0.525252525253\n",
      "123 0.555555555556\n",
      "124 0.570707070707\n",
      "125 0.570707070707\n",
      "126 0.540404040404\n",
      "127 0.590909090909\n",
      "128 0.540404040404\n",
      "129 0.555555555556\n",
      "130 0.560606060606\n",
      "131 0.560606060606\n",
      "132 0.560606060606\n",
      "133 0.555555555556\n",
      "134 0.555555555556\n",
      "135 0.590909090909\n",
      "136 0.560606060606\n",
      "137 0.590909090909\n",
      "138 0.570707070707\n",
      "139 0.580808080808\n",
      "140 0.580808080808\n",
      "141 0.590909090909\n",
      "142 0.535353535354\n",
      "143 0.590909090909\n",
      "144 0.575757575758\n",
      "145 0.575757575758\n",
      "146 0.560606060606\n",
      "147 0.565656565657\n",
      "148 0.550505050505\n",
      "149 0.570707070707\n",
      "150 0.560606060606\n",
      "151 0.580808080808\n",
      "152 0.575757575758\n",
      "153 0.555555555556\n",
      "154 0.570707070707\n",
      "155 0.565656565657\n",
      "156 0.540404040404\n",
      "157 0.565656565657\n",
      "158 0.565656565657\n",
      "159 0.550505050505\n",
      "160 0.555555555556\n",
      "161 0.550505050505\n",
      "162 0.60101010101\n",
      "163 0.555555555556\n",
      "164 0.575757575758\n",
      "165 0.580808080808\n",
      "166 0.560606060606\n",
      "167 0.585858585859\n",
      "168 0.550505050505\n",
      "169 0.575757575758\n",
      "170 0.565656565657\n",
      "171 0.565656565657\n",
      "172 0.555555555556\n",
      "173 0.550505050505\n",
      "174 0.565656565657\n",
      "175 0.560606060606\n",
      "176 0.565656565657\n",
      "177 0.545454545455\n",
      "178 0.575757575758\n",
      "179 0.565656565657\n",
      "180 0.560606060606\n",
      "181 0.525252525253\n",
      "182 0.590909090909\n",
      "183 0.585858585859\n",
      "184 0.580808080808\n",
      "185 0.585858585859\n",
      "186 0.555555555556\n",
      "187 0.550505050505\n",
      "188 0.575757575758\n",
      "189 0.560606060606\n",
      "190 0.580808080808\n",
      "191 0.550505050505\n",
      "192 0.590909090909\n",
      "193 0.570707070707\n",
      "194 0.570707070707\n",
      "195 0.590909090909\n",
      "196 0.550505050505\n",
      "197 0.570707070707\n",
      "198 0.555555555556\n",
      "199 0.570707070707\n",
      "200 0.565656565657\n",
      "201 0.565656565657\n",
      "202 0.560606060606\n",
      "203 0.575757575758\n",
      "204 0.570707070707\n",
      "205 0.560606060606\n",
      "206 0.545454545455\n",
      "207 0.575757575758\n",
      "208 0.540404040404\n",
      "209 0.560606060606\n",
      "210 0.535353535354\n",
      "211 0.575757575758\n",
      "212 0.560606060606\n",
      "213 0.535353535354\n",
      "214 0.540404040404\n",
      "215 0.575757575758\n",
      "216 0.565656565657\n",
      "217 0.585858585859\n",
      "218 0.530303030303\n",
      "219 0.560606060606\n",
      "220 0.580808080808\n",
      "221 0.575757575758\n",
      "222 0.570707070707\n",
      "223 0.580808080808\n",
      "224 0.580808080808\n",
      "225 0.550505050505\n",
      "226 0.590909090909\n",
      "227 0.545454545455\n",
      "228 0.560606060606\n",
      "229 0.570707070707\n",
      "230 0.560606060606\n",
      "231 0.580808080808\n",
      "232 0.570707070707\n",
      "233 0.590909090909\n",
      "234 0.570707070707\n",
      "235 0.570707070707\n",
      "236 0.575757575758\n",
      "237 0.565656565657\n",
      "238 0.530303030303\n",
      "239 0.540404040404\n",
      "240 0.545454545455\n",
      "241 0.560606060606\n",
      "242 0.565656565657\n",
      "243 0.550505050505\n",
      "244 0.540404040404\n",
      "245 0.560606060606\n",
      "246 0.565656565657\n",
      "247 0.555555555556\n",
      "248 0.565656565657\n",
      "249 0.580808080808\n",
      "250 0.555555555556\n",
      "251 0.545454545455\n",
      "252 0.570707070707\n",
      "253 0.575757575758\n",
      "254 0.550505050505\n",
      "255 0.560606060606\n",
      "256 0.565656565657\n",
      "257 0.535353535354\n",
      "258 0.59595959596\n",
      "259 0.550505050505\n",
      "260 0.580808080808\n",
      "261 0.570707070707\n",
      "262 0.570707070707\n",
      "263 0.565656565657\n",
      "264 0.540404040404\n",
      "265 0.565656565657\n",
      "266 0.575757575758\n",
      "267 0.570707070707\n",
      "268 0.585858585859\n",
      "269 0.560606060606\n",
      "270 0.555555555556\n",
      "271 0.585858585859\n",
      "272 0.555555555556\n",
      "273 0.555555555556\n",
      "274 0.575757575758\n",
      "275 0.555555555556\n",
      "276 0.580808080808\n",
      "277 0.555555555556\n",
      "278 0.590909090909\n",
      "279 0.590909090909\n",
      "280 0.550505050505\n",
      "281 0.560606060606\n",
      "282 0.550505050505\n",
      "283 0.565656565657\n",
      "284 0.575757575758\n",
      "285 0.59595959596\n",
      "286 0.515151515152\n",
      "287 0.580808080808\n",
      "288 0.560606060606\n",
      "289 0.525252525253\n",
      "290 0.550505050505\n",
      "291 0.575757575758\n",
      "292 0.580808080808\n",
      "293 0.570707070707\n",
      "294 0.530303030303\n",
      "295 0.580808080808\n",
      "296 0.550505050505\n",
      "297 0.611111111111\n",
      "298 0.580808080808\n",
      "299 0.555555555556\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,300):    \n",
    "    print(str(i) +\" \" +str(accuracy_score(test_labels, predict_list[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.59595959596\n"
     ]
    }
   ],
   "source": [
    "theMax = 0\n",
    "for i in range(0,300):    \n",
    "    if(accuracy_score(test_labels, predict_list[i]) > theMax):\n",
    "        theMax = accuracy_score(test_labels, predict_list[i])\n",
    "print(theMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Parameters currently in use:\\n')\n",
    "print(rf.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "random_grid ={'bootstrap': [True, False],\n",
    " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    " 'max_features': ['auto', 'sqrt'],\n",
    " 'min_samples_leaf': [1, 2, 4],\n",
    " 'min_samples_split': [2, 5, 10],\n",
    " 'n_estimators': [10,15,20,25,30,50,100,200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 500, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(train_features, train_labels)\n",
    "\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeScore():\n",
    "    total = [[0,0,0],[0,0,0],[0,0,0]]\n",
    "    \n",
    "    predict = ['N', 'R', 'R', 'N', 'N', 'AF', 'N', 'R', 'N', 'AF', 'N', 'N', 'N', 'R', 'AF', 'AF', 'N', 'AF', 'N', 'N', 'N', 'R', 'R', 'R', 'AF', 'R', 'N', 'N', 'R', 'R', 'R', 'N', 'N', 'AF', 'N', 'R', 'N', 'R', 'R', 'AF', 'AF', 'N', 'R', 'R', 'N', 'N', 'R', 'N', 'N', 'R', 'AF', 'AF', 'N', 'R', 'R', 'AF', 'AF', 'N', 'N', 'N', 'N', 'N', 'AF', 'R', 'R', 'N', 'R', 'R', 'N', 'AF', 'AF', 'N', 'R', 'AF', 'R', 'R', 'AF', 'AF', 'R', 'R', 'AF', 'R', 'R', 'AF', 'N', 'N', 'N', 'AF', 'AF', 'AF', 'AF', 'R', 'N', 'AF', 'AF', 'AF', 'AF', 'N', 'R', 'N', 'N', 'AF', 'R', 'AF', 'N', 'R', 'N', 'AF', 'AF', 'R', 'N', 'R', 'R', 'R', 'AF', 'AF', 'AF', 'N', 'R', 'R', 'N', 'N', 'AF', 'R', 'N', 'N', 'R', 'AF', 'R', 'R', 'N', 'R', 'N', 'N', 'R', 'N', 'N', 'N', 'AF', 'N', 'N', 'AF', 'N', 'N', 'R', 'N', 'AF', 'R', 'N', 'N', 'R', 'R', 'AF', 'AF', 'R', 'AF', 'N', 'R', 'N', 'N', 'AF', 'AF', 'N', 'R', 'AF', 'N', 'AF', 'AF', 'R', 'AF', 'AF', 'AF', 'R', 'R', 'N', 'N', 'R', 'N', 'N', 'AF', 'N', 'AF', 'R', 'R', 'R', 'AF', 'AF', 'R', 'AF', 'AF', 'R', 'R', 'N', 'AF', 'R', 'AF', 'R', 'AF']\n",
    "\n",
    "\n",
    "    list1 = [0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
    " 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    " 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    " 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
    " 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
    " 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1]\n",
    "    \n",
    "    list2 = [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
    " 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
    " 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0,\n",
    " 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
    " 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
    " 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,]\n",
    "    \n",
    "    \n",
    "    list3 = [0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0,\n",
    " 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
    " 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
    " 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
    " 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
    " 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0,]\n",
    "     \n",
    "    \n",
    "    \n",
    "    for i in range(0,len(list1)):\n",
    "        print(len(list1))\n",
    "        print(len(predict))\n",
    "        if(list1[i] == 1 and predict[i] == \"N\"):\n",
    "            total[0][0] += 1\n",
    "        elif(list1[i] == 1 and predict[i] == \"AF\"):\n",
    "            total[1][0] += 1\n",
    "        elif(list1[i] == 1 and predict[i] == \"R\"):\n",
    "            total[2][0] += 1\n",
    "            \n",
    "            \n",
    "    for i in range(0,len(list2)):\n",
    "        if(list2[i] == 1 and predict[i] == \"N\"):\n",
    "            total[0][1] += 1\n",
    "        elif(list2[i] == 1 and predict[i] == \"AF\"):\n",
    "            total[1][1] += 1\n",
    "        elif(list2[i] == 1 and predict[i] == \"R\"):\n",
    "            total[2][1] += 1\n",
    "\n",
    "    for i in range(0,len(list3)):\n",
    "        if(list3[i] == 1 and predict[i] == \"N\"):\n",
    "            total[0][2] += 1\n",
    "        elif(list3[i] == 1 and predict[i] == \"AF\"):\n",
    "            total[1][2] += 1\n",
    "        elif(list3[i] == 1 and predict[i] == \"R\"):\n",
    "            total[2][2] += 1\n",
    "\n",
    "    print(total)\n",
    "\n",
    "\n",
    "computeScore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var1 = 36/(29+28)\n",
    "var2 = 48/(31+39)\n",
    "var3 = 112/(73+66)\n",
    "\n",
    "print((var1+var2+var3)/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
