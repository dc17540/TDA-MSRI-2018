{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "theCsv[\"avg_bottle_dist_dim0\"] =theCsv5[\"avg_bottle_dist_dim0\"]\n",
    "theCsv[\"sd_bottle_dist_dim0\"] =theCsv5[\"sd_bottle_dist_dim0\"]\n",
    "\n",
    "\n",
    "#theCsv[\"avg_bottle_dist_dim0\"] =theCsv6[\"avg_bottle_dist_dim0\"]\n",
    "#theCsv[\"sd_bottle_dist_dim0\"] =theCsv6[\"sd_bottle_dist_dim0\"]\n",
    "\n",
    "theCsv[\"avg_bottle_dist_dim0\"] =theCsv7[\"avg_bottle_dist_dim0\"]\n",
    "theCsv[\"sd_bottle_dist_dim0\"] =theCsv7[\"sd_bottle_dist_dim0\"]\n",
    "118\n",
    "\n",
    "['N', 'R', 'R', 'N', 'N', 'AF', 'N', 'R', 'N', 'AF', 'N', 'N', 'N', 'R', 'AF', 'AF', 'N', 'AF', 'N', 'N', 'N', 'R', 'R', 'R', 'AF', 'R', 'N', 'N', 'R', 'R', 'R', 'N', 'N', 'AF', 'N', 'R', 'N', 'R', 'R', 'AF', 'AF', 'N', 'R', 'R', 'N', 'N', 'R', 'N', 'N', 'R', 'AF', 'AF', 'N', 'R', 'R', 'AF', 'AF', 'N', 'N', 'N', 'N', 'N', 'AF', 'R', 'R', 'N', 'R', 'R', 'N', 'AF', 'AF', 'N', 'R', 'AF', 'R', 'R', 'AF', 'AF', 'R', 'R', 'AF', 'R', 'R', 'AF', 'N', 'N', 'N', 'AF', 'AF', 'AF', 'AF', 'R', 'N', 'AF', 'AF', 'AF', 'AF', 'N', 'R', 'N', 'N', 'AF', 'R', 'AF', 'N', 'R', 'N', 'AF', 'AF', 'R', 'N', 'R', 'R', 'R', 'AF', 'AF', 'AF', 'N', 'R', 'R', 'N', 'N', 'AF', 'R', 'N', 'N', 'R', 'AF', 'R', 'R', 'N', 'R', 'N', 'N', 'R', 'N', 'N', 'N', 'AF', 'N', 'N', 'AF', 'N', 'N', 'R', 'N', 'AF', 'R', 'N', 'N', 'R', 'R', 'AF', 'AF', 'R', 'AF', 'N', 'R', 'N', 'N', 'AF', 'AF', 'N', 'R', 'AF', 'N', 'AF', 'AF', 'R', 'AF', 'AF', 'AF', 'R', 'R', 'N', 'N', 'R', 'N', 'N', 'AF', 'N', 'AF', 'R', 'R', 'R', 'AF', 'AF', 'R', 'AF', 'AF', 'R', 'R', 'N', 'AF', 'R', 'AF', 'R', 'AF']\n",
    "\n",
    "['N', 'R', 'R', 'N', 'N', 'AF', 'N', 'R', 'N', 'AF', 'N', 'N', 'N', 'R', 'AF', 'AF', 'N', 'AF', 'N', 'N', 'N', 'R', 'R', 'R', 'AF', 'R', 'N', 'N', 'R', 'R', 'R', 'N', 'N', 'AF', 'N', 'R', 'N', 'R', 'R', 'AF', 'AF', 'N', 'R', 'R', 'N', 'N', 'R', 'N', 'N', 'R', 'AF', 'AF', 'N', 'R', 'R', 'AF', 'AF', 'N', 'N', 'N', 'N', 'N', 'AF', 'R', 'R', 'N', 'R', 'R', 'N', 'AF', 'AF', 'N', 'R', 'AF', 'R', 'R', 'AF', 'AF', 'R', 'R', 'AF', 'R', 'R', 'AF', 'N', 'N', 'N', 'AF', 'AF', 'AF', 'AF', 'R', 'N', 'AF', 'AF', 'AF', 'AF', 'N', 'R', 'N', 'N', 'AF', 'R', 'AF', 'N', 'R', 'N', 'AF', 'AF', 'R', 'N', 'R', 'R', 'R', 'AF', 'AF', 'AF', 'N', 'R', 'R', 'N', 'N', 'AF', 'R', 'N', 'N', 'R', 'AF', 'R', 'R', 'N', 'R', 'N', 'N', 'R', 'N', 'N', 'N', 'AF', 'N', 'N', 'AF', 'N', 'N', 'R', 'N', 'AF', 'R', 'N', 'N', 'R', 'R', 'AF', 'AF', 'R', 'AF', 'N', 'R', 'N', 'N', 'AF', 'AF', 'N', 'R', 'AF', 'N', 'AF', 'AF', 'R', 'AF', 'AF', 'AF', 'R', 'R', 'N', 'N', 'R', 'N', 'N', 'AF', 'N', 'AF', 'R', 'R', 'R', 'AF', 'AF', 'R', 'AF', 'AF', 'R', 'R', 'N', 'AF', 'R', 'AF', 'R', 'AF']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "theTotal = []\n",
    "classDict = {}\n",
    "lineCount = 0\n",
    "\n",
    "x = open(\"2000_label.csv\")\n",
    "for line in x:\n",
    "    line = line.strip()\n",
    "    #print(line)\n",
    "    a,b,c = line.split(\",\")\n",
    "    theTotal.append(c[1])\n",
    "    \n",
    "    lineCount += 1\n",
    "theTotal = theTotal[1:len(theTotal)]\n",
    "            \n",
    "theFrame = {\"mean\":[],\"std_dev\":[],\"theClass\":[]}\n",
    "\n",
    "theCsv = pd.read_csv(\"Mean_sd_dimension_0.csv\", index_col=0)\n",
    "theCsv2 = pd.read_csv(\"Mean_sd_dimension_1.csv\",index_col=0)\n",
    "theCsv3 = pd.read_csv(\"Mean_sd_dimension_2.csv\",index_col=0)\n",
    "theCsv4 = pd.read_csv(\"Lifetimes_dim_0_1_2.csv\",index_col=0)\n",
    "theCsv5 = pd.read_csv(\"Maximum_lifetimes_all_dims.csv\",index_col=0)\n",
    "theCsv6 = pd.read_csv(\"reduced_bottleneck_ave_sd_dist_dim1.csv\",index_col=0)\n",
    "theCsv7 = pd.read_csv(\"reduced_bottleneck_ave_sd_dist_dim2.csv\",index_col=0)\n",
    "theCsv8 = pd.read_csv(\"number_of_births_deaths_dim0.csv\",index_col=0)\n",
    "theCsv9 = pd.read_csv(\"number_of_births_deaths_dim1.csv\",index_col=0)\n",
    "theCsv10 = pd.read_csv(\"number_of_births_deaths_dim2.csv\",index_col=0)\n",
    "theCsv11 = pd.read_csv(\"skewness_birth_dim12.csv\",index_col=0)\n",
    "theCsv12 = pd.read_csv(\"skewness_death_dim012.csv\",index_col=0)\n",
    "theCsv13 = pd.read_csv(\"a.csv\",index_col=0)\n",
    "theCsv14 = pd.read_csv(\"Total_matrix_RR_interval_2000.csv\",index_col=0)\n",
    "theCsv15 = pd.read_csv(\"rr_normal.csv\",index_col=0)\n",
    "theCsv16 = pd.read_csv(\"rr_R.csv\",index_col=0)\n",
    "#theCsv8 = pd.read_csv(\"reduced_bottleneck_ave_sd_dist_dim2.csv\",index_col=0)\n",
    "#bigData = theCsv.append(theCsv2, ignore_index=True)\n",
    "\n",
    "#print(bigData)\n",
    "\n",
    "aList = []\n",
    "aList2 = []\n",
    "aList3 = []\n",
    "for i in range(0,200):\n",
    "    aList.append(\"N\")\n",
    "    aList2.append(0)\n",
    "    aList3.append(0)\n",
    "\n",
    "for i in range(0,200):\n",
    "    aList.append(\"AF\")\n",
    "    aList2.append(1)\n",
    "    aList3.append(0)\n",
    "    \n",
    "for i in range(0,200):\n",
    "    aList.append(\"R\")\n",
    "    aList2.append(0)\n",
    "    aList3.append(1)\n",
    "\n",
    "#theCsv[\"Normal\"] = np.asarray(aList)\n",
    "#theCsv[\"AF\"] = np.asarray(aList2)\n",
    "#theCsv[\"Random\"] = np.asarray(aList3)\n",
    "#### make dataframe \n",
    "###\n",
    "#bigData  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#theCsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dr-dunstan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/dr-dunstan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1956\n",
      "      Means_dim0_birth  Means_dim0_death  sd_dim0_birth  sd_dim0_death  \\\n",
      "1                    0          0.867140              0       0.118419   \n",
      "2                    0          0.464306              0       0.179611   \n",
      "3                    0          0.379515              0       0.143459   \n",
      "4                    0          0.272712              0       0.128959   \n",
      "5                    0          0.245428              0       0.085050   \n",
      "6                    0          0.394447              0       0.103590   \n",
      "7                    0          0.513328              0       0.092833   \n",
      "8                    0          0.264466              0       0.136429   \n",
      "9                    0          0.954105              0       0.246072   \n",
      "10                   0          0.767066              0       0.205642   \n",
      "11                   0          0.219961              0       0.065375   \n",
      "12                   0          0.421948              0       0.166689   \n",
      "13                   0          0.284072              0       0.110296   \n",
      "14                   0          0.875187              0       0.283130   \n",
      "15                   0          0.232764              0       0.061793   \n",
      "16                   0          0.839356              0       0.307597   \n",
      "17                   0          0.624257              0       0.101029   \n",
      "18                   0          0.451223              0       0.208449   \n",
      "19                   0          1.237513              0       0.232213   \n",
      "20                   0          0.565598              0       0.118577   \n",
      "21                   0          0.634137              0       0.497510   \n",
      "22                   0          0.342422              0       0.077296   \n",
      "23                   0          0.684302              0       0.154189   \n",
      "24                   0          0.348923              0       0.150243   \n",
      "25                   0          1.060193              0       0.476461   \n",
      "26                   0          0.499824              0       0.315447   \n",
      "27                   0          0.826084              0       0.240843   \n",
      "28                   0          0.524234              0       0.118790   \n",
      "29                   0          0.721206              0       0.204188   \n",
      "30                   0          0.328023              0       0.113441   \n",
      "...                ...               ...            ...            ...   \n",
      "1927                 0          0.646482              0       0.444006   \n",
      "1928                 0          0.278486              0       0.073121   \n",
      "1929                 0          1.153589              0       0.304377   \n",
      "1930                 0          0.709579              0       0.208475   \n",
      "1931                 0          0.435603              0       0.254048   \n",
      "1932                 0          0.382789              0       0.121102   \n",
      "1933                 0          0.938481              0       0.250241   \n",
      "1934                 0          0.448634              0       0.108946   \n",
      "1935                 0          0.313289              0       0.155942   \n",
      "1936                 0          0.538606              0       0.219914   \n",
      "1937                 0          0.439602              0       0.107415   \n",
      "1938                 0          0.370429              0       0.142259   \n",
      "1939                 0          0.964471              0       0.116450   \n",
      "1940                 0          0.435497              0       0.152053   \n",
      "1941                 0          0.497290              0       0.103943   \n",
      "1942                 0          0.523983              0       0.252110   \n",
      "1943                 0          0.472185              0       0.049382   \n",
      "1944                 0          0.291076              0       0.203424   \n",
      "1945                 0          0.316256              0       0.084514   \n",
      "1946                 0          0.825971              0       0.368188   \n",
      "1947                 0          0.528943              0       0.267448   \n",
      "1948                 0          0.366638              0       0.123460   \n",
      "1949                 0          0.618637              0       0.216883   \n",
      "1950                 0          0.422982              0       0.233861   \n",
      "1951                 0          0.138387              0       0.103991   \n",
      "1952                 0          0.447661              0       0.200646   \n",
      "1953                 0          0.387984              0       0.106689   \n",
      "1954                 0          0.228309              0       0.082979   \n",
      "1955                 0          0.243817              0       0.121231   \n",
      "1956                 0          0.395659              0       0.152626   \n",
      "\n",
      "         num_per0     num_per1     num_per2 Normal  \n",
      "1      248.428571    87.045238    -1.059212      N  \n",
      "2      217.777778    27.424419    -3.700081      N  \n",
      "3      282.741935    53.210457     0.536402      N  \n",
      "4      162.700000    66.916169     1.178835      A  \n",
      "5      310.642857    19.669073    -1.909149      A  \n",
      "6      287.300000    15.539520    -0.404926      N  \n",
      "7      258.246377    47.675353    -1.794191      N  \n",
      "8      189.282609    33.261587     0.504180      O  \n",
      "9      276.015625     7.003330    -0.200431      A  \n",
      "10     254.285714     4.651092    -0.786530      N  \n",
      "11     267.593750    10.708815    -2.474211      N  \n",
      "12     193.133333    10.910953     3.242943      N  \n",
      "13     324.812500    25.671528    -0.114771      O  \n",
      "14     196.766667    63.109790     0.113302      N  \n",
      "15     214.585366    26.475922    -4.415577      A  \n",
      "16     120.589041     4.040330    -0.262060      N  \n",
      "17     335.720000    10.113437    -0.626692      O  \n",
      "18     238.404255    27.970090    -2.471607      N  \n",
      "19     226.894737    22.762838     0.180133      N  \n",
      "20     281.967742     5.778067    -0.195120      O  \n",
      "21     222.850000   169.642352     2.911617      N  \n",
      "22     246.314286    53.663913    -2.165616      ~  \n",
      "23     295.655172     4.907952    -0.220557      O  \n",
      "24     309.750000     2.640684    -0.217468      N  \n",
      "25     196.931818    37.330464     0.673173      N  \n",
      "26     281.984127     2.319634     0.248172      A  \n",
      "27     176.755102     5.698301     1.125003      N  \n",
      "28     284.403226   101.345538    -0.274236      O  \n",
      "29     212.341463     9.979515     0.863284      O  \n",
      "30     226.394737    94.458440    -0.488919      N  \n",
      "...           ...          ...          ...    ...  \n",
      "1927   168.403846    39.869142     0.979839      N  \n",
      "1928   217.150000     6.287090     0.339456      A  \n",
      "1929   243.388889    40.880094    -2.472965      N  \n",
      "1930   217.375000    60.962155     0.180010      O  \n",
      "1931   272.781250    20.292755    -5.063062      A  \n",
      "1932   293.250000    61.992641    -1.015917      N  \n",
      "1933   262.787879    97.511696    -0.926205      O  \n",
      "1934   241.750000    83.875279    -0.112810      N  \n",
      "1935   289.333333    35.258411    -0.790169      ~  \n",
      "1936   161.370370    49.524516    -0.186016      O  \n",
      "1937   287.666667     8.279828    -0.289522      A  \n",
      "1938   245.055556    75.676190     0.490655      N  \n",
      "1939   203.476190    92.477343     2.283586      N  \n",
      "1940   242.333333    15.322460    -0.805907      O  \n",
      "1941   180.377551    10.490535     0.116846      N  \n",
      "1942   176.591837    62.343983    -0.700945      O  \n",
      "1943   267.454545    25.734178    -1.316298      N  \n",
      "1944   192.612903    25.559138    -4.101540      N  \n",
      "1945   335.827586    49.406874    -1.260125      N  \n",
      "1946   215.250000    10.386891     0.399842      O  \n",
      "1947   232.552632     9.988671    -0.199180      O  \n",
      "1948   267.439394     5.651840     0.011442      O  \n",
      "1949   274.709677    70.319636    -0.370289      N  \n",
      "1950   236.384615    14.819626     0.563254      A  \n",
      "1951   277.235294    20.174327    -0.434712      N  \n",
      "1952   374.521739   472.018042     4.377841      N  \n",
      "1953   302.689655     5.389027    -0.328732      N  \n",
      "1954   224.820513    35.797057     1.049579      N  \n",
      "1955   323.888889     5.539978    -0.033271      N  \n",
      "1956  1000.000000  1000.000000  1000.000000      N  \n",
      "\n",
      "[1956 rows x 8 columns]\n",
      "['N', 'N', 'N', 'A', 'A', 'N', 'N', 'O', 'A', 'N', 'N', 'N', 'O', 'N', 'A', 'N', 'O', 'N', 'N', 'O', 'N', '~', 'O', 'N', 'N', 'A', 'N', 'O', 'O', 'N', 'N', 'N', '~', 'N', 'N', 'N', 'O', 'N', 'N', 'O', 'N', 'O', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'A', 'O', 'N', 'O', 'N', 'O', 'N', 'N', 'N', 'O', 'N', 'A', 'N', 'O', 'O', 'A', 'N', 'N', 'O', 'O', 'N', 'O', 'O', 'N', 'N', 'N', 'O', 'O', 'N', 'N', 'N', 'A', 'O', 'N', 'A', 'N', 'O', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'O', 'A', 'A', 'O', 'N', 'N', '~', 'O', 'N', 'O', 'N', 'N', 'N', 'O', 'O', 'N', 'N', 'N', 'O', 'O', 'O', 'N', 'O', 'N', '~', 'O', 'N', 'A', 'N', 'N', 'O', 'A', 'O', 'N', 'N', 'O', 'A', 'O', '~', 'N', 'A', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'A', 'N', 'O', 'O', 'N', 'O', 'O', 'N', '~', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'O', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'O', '~', 'N', 'O', 'N', '~', 'N', 'O', '~', 'N', 'N', 'A', 'N', 'O', 'O', 'O', 'N', 'O', 'A', 'A', 'O', 'N', 'O', 'N', 'N', 'N', 'N', 'A', 'N', 'N', 'N', 'N', 'N', 'A', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'O', 'A', 'N', 'N', 'O', 'A', 'N', 'O', 'N', 'N', 'N', 'O', 'O', 'N', 'N', 'A', 'N', 'N', 'A', 'N', 'O', 'A', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'A', 'N', 'N', 'O', 'O', 'N', 'O', 'N', 'N', 'O', 'N', 'O', 'N', 'N', 'O', 'N', 'O', 'N', 'O', 'N', 'N', 'N', 'N', 'N', '~', 'O', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'A', 'N', 'N', 'O', 'O', 'O', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'O', 'N', 'O', 'N', 'O', 'O', 'O', 'O', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'N', '~', 'N', 'N', 'O', 'N', 'A', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'O', 'O', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'O', 'A', 'O', 'A', 'N', 'O', 'O', 'N', 'O', 'N', 'A', 'A', 'O', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'A', 'N', 'N', 'N', 'N', 'O', 'O', 'N', 'O', 'O', 'A', 'N', 'O', 'N', 'N', 'N', 'A', 'A', 'N', 'A', 'N', 'O', 'O', '~', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'A', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'A', 'O', 'N', 'O', 'N', 'O', 'N', 'A', '~', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'O', 'N', 'O', 'O', 'A', 'N', 'N', 'N', 'N', 'N', 'N', 'A', 'N', 'N', 'N', 'O', 'O', 'N', 'N', 'O', 'O', 'N', 'N', 'N', 'N', 'A', 'N', 'O', 'N', 'N', 'N', 'N', 'A', 'A', 'O', 'O', 'O', '~', 'N', 'N', 'N', 'N', 'O', 'O', 'N', 'N', 'O', 'N', 'O', '~', 'N', 'O', 'N', 'N', 'A', 'N', 'O', 'N', 'N', 'N', 'O', 'N', 'A', 'N', 'N', 'O', 'N', 'O', 'O', 'N', 'O', 'N', 'O', 'O', 'N', 'N', 'O', 'N', 'N', 'N', 'O', 'N', 'O', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'O', '~', 'N', 'A', 'N', 'A', 'N', '~', 'A', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'O', 'N', 'N', 'O', 'N', 'N', 'A', 'O', 'A', 'A', 'N', 'N', 'N', 'N', '~', 'N', 'A', 'N', 'O', 'A', 'A', 'O', 'N', 'N', '~', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'O', 'N', 'O', 'N', 'N', 'A', 'N', 'N', 'O', 'N', 'A', 'O', 'O', 'N', 'O', 'N', 'O', 'N', 'O', 'O', 'N', 'A', 'N', 'O', 'N', 'A', 'N', 'N', 'N', 'A', 'N', 'N', 'O', 'N', 'O', 'N', 'N', 'N', 'O', 'A', 'N', 'N', 'N', 'O', 'N', 'O', 'O', 'N', '~', 'A', 'N', 'O', 'N', 'N', 'O', 'O', 'O', '~', 'A', 'O', 'N', 'A', '~', 'A', 'A', 'N', 'O', 'N', 'N', 'O', 'N', 'N', 'N', 'O', 'N', 'O', 'O', 'N', 'N', 'A', 'O', 'O', 'A', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'A', 'O', 'N', 'N', 'O', 'N', 'A', 'O', 'O', 'O', 'N', 'O', 'O', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'N', '~', 'N', 'N', 'N', 'N', 'O', 'O', 'O', 'O', 'N', 'A', 'O', '~', 'N', 'A', 'N', 'N', 'N', 'N', 'A', 'O', 'N', 'N', 'O', 'O', 'O', 'O', 'O', 'N', 'N', 'N', 'O', 'N', 'A', 'N', 'N', 'A', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'O', 'N', '~', 'N', 'N', 'N', 'O', 'N', 'O', 'O', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'A', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'O', 'O', 'O', 'O', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'A', 'N', 'N', 'N', 'N', 'N', 'A', 'O', 'A', 'N', 'N', 'O', 'A', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'A', 'O', 'O', 'A', 'O', 'N', 'N', 'O', 'N', 'O', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'A', 'N', 'O', 'N', 'O', 'N', 'N', 'N', 'N', 'O', 'O', 'N', 'O', 'O', 'N', 'O', 'N', 'N', 'N', 'A', 'N', 'O', 'N', 'N', 'O', 'O', 'A', 'A', 'N', 'N', 'N', 'N', 'A', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'A', 'N', 'A', 'N', 'O', 'O', 'O', 'O', 'N', 'N', 'O', 'N', 'A', 'N', 'N', 'N', 'O', 'N', 'N', 'O', 'A', 'N', 'A', 'O', 'N', 'O', 'N', 'O', 'N', 'A', 'O', '~', 'N', 'N', 'N', '~', 'O', 'N', 'O', 'N', 'O', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'A', '~', 'N', 'N', 'N', 'N', 'N', 'N', 'A', 'N', 'N', 'N', 'N', 'N', 'A', 'N', 'N', 'N', 'N', 'A', 'O', 'N', 'O', 'O', 'O', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'O', 'A', 'A', 'O', 'N', 'A', 'N', 'N', 'O', 'N', 'N', 'A', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'N', '~', 'N', 'O', 'N', 'N', 'O', 'N', '~', 'O', 'O', 'N', 'A', 'A', 'N', 'O', 'A', 'N', 'O', 'N', 'N', 'O', 'N', 'N', 'A', 'O', 'N', 'N', 'O', 'A', 'O', 'O', 'N', 'N', 'N', 'O', 'O', 'N', 'N', 'O', 'A', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'O', '~', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'A', 'O', 'O', 'N', 'O', 'O', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'A', 'O', 'N', 'O', 'N', 'O', 'N', '~', 'N', 'N', 'A', 'O', 'N', 'N', 'O', 'N', '~', 'N', 'A', 'N', 'O', 'N', 'O', 'N', 'O', 'N', 'O', 'N', 'O', 'O', 'N', 'N', 'O', 'O', 'O', 'N', 'N', 'O', 'A', 'O', 'N', 'N', 'N', 'N', 'A', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'A', 'N', 'N', 'O', 'N', 'N', 'O', 'A', 'O', 'O', 'O', 'N', 'N', 'N', 'O', 'N', 'O', 'N', 'N', 'N', 'A', 'N', 'N', 'N', 'N', 'O', 'O', 'O', 'N', 'N', 'A', 'O', 'N', 'N', 'A', '~', 'N', 'N', 'N', 'O', 'O', 'O', '~', 'N', 'N', 'A', 'N', 'A', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'A', 'A', 'N', 'N', 'N', 'O', '~', 'N', 'N', 'N', 'O', 'O', 'O', 'N', 'N', 'N', 'N', 'O', 'N', 'O', 'N', 'A', 'O', 'O', 'N', 'O', 'O', 'N', 'O', 'O', 'N', 'A', 'A', 'O', 'N', 'N', 'N', 'O', 'A', 'O', 'N', 'N', 'A', 'N', 'O', 'O', 'O', 'N', 'N', 'N', 'O', 'N', 'A', 'A', 'A', 'O', 'N', 'N', 'N', 'O', 'O', 'O', 'N', 'N', 'N', 'O', 'N', 'O', 'N', 'A', 'O', 'N', 'O', 'N', 'N', 'N', 'N', 'O', 'N', 'O', 'N', 'O', 'A', 'O', 'O', 'N', 'A', 'N', 'N', 'N', 'A', 'O', 'O', 'N', 'N', 'N', 'A', 'A', 'O', 'N', 'A', 'N', 'N', 'N', 'N', 'A', 'N', 'A', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'A', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'A', 'N', 'O', 'N', 'O', 'N', 'O', 'O', 'O', 'N', 'N', 'O', 'O', 'A', 'N', 'N', 'N', 'O', 'N', 'N', '~', 'N', '~', 'N', 'N', 'A', 'N', 'N', 'O', 'N', 'O', 'N', 'N', 'N', 'N', 'A', 'N', 'N', 'N', 'A', 'A', 'N', 'N', 'O', 'N', 'N', 'N', 'O', 'O', 'O', 'O', 'N', 'N', 'N', 'N', 'O', 'A', 'N', 'O', 'N', 'O', 'N', 'O', 'O', 'O', 'O', 'O', 'O', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'O', 'N', 'N', 'N', 'A', 'N', 'N', 'O', 'N', 'N', 'N', 'O', 'N', 'N', 'A', '~', '~', 'N', 'O', 'N', 'N', 'N', 'N', 'O', 'A', 'N', 'N', 'N', 'O', 'O', 'O', 'O', 'A', 'N', 'A', 'N', 'N', 'O', 'O', 'O', 'N', '~', 'O', 'O', 'O', 'N', 'N', 'O', 'N', 'N', 'N', 'O', 'N', 'N', 'O', 'O', 'N', 'O', 'O', 'N', 'N', 'A', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'A', 'O', 'O', 'O', '~', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'O', 'O', '~', 'N', 'N', 'O', 'N', 'O', 'A', '~', 'O', 'O', 'O', 'A', 'O', 'O', 'O', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'O', '~', 'N', 'N', 'N', 'N', 'N', 'A', 'N', 'N', 'N', 'A', 'O', 'O', 'N', 'O', 'N', 'A', 'N', 'N', 'O', 'N', 'A', 'N', 'N', 'O', 'O', 'O', 'O', 'O', 'N', 'N', 'O', 'N', 'O', 'A', 'O', 'N', 'N', 'N', 'O', 'N', 'O', 'N', 'O', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'A', 'N', 'N', 'N', 'N', 'O', 'O', 'N', 'N', 'O', 'N', 'N', 'N', 'O', 'N', 'N', 'O', 'N', 'N', 'O', 'N', 'N', 'A', 'N', 'N', 'N', 'N', 'O', 'A', 'O', 'A', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'N', '~', 'N', 'O', 'N', 'A', 'N', 'N', 'N', 'A', 'N', 'A', 'N', 'O', 'N', 'O', 'O', 'N', 'N', '~', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'O', 'A', 'N', 'N', 'N', 'N', 'N', '~', 'N', 'O', 'N', 'N', 'N', 'O', 'N', '~', 'O', 'A', 'A', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'A', 'O', 'A', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'O', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'A', 'N', 'O', 'O', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'O', 'N', 'A', 'O', 'N', 'A', 'O', 'N', 'A', 'N', '~', 'O', 'N', 'N', 'N', 'O', 'N', 'N', 'O', 'N', 'A', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'O', 'A', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'A', 'N', 'N', 'O', 'O', 'N', 'N', 'O', 'N', 'N', 'O', 'N', 'N', 'A', 'N', 'N', 'N', '~', 'N', 'O', 'O', 'A', 'O', 'N', 'N', 'O', 'N', 'N', 'N', 'O', 'O', 'N', 'N', 'N', 'O', 'N', 'O', 'N', 'N', 'N', 'O', 'N', 'O', '~', 'O', 'O', 'N', 'O', 'N', 'N', 'N', 'O', 'N', 'N', 'O', 'O', 'A', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'A', 'N', 'N', 'O', 'N', 'O', 'N', 'N', 'N', 'N', 'A', 'N', 'N', 'O', 'O', 'N', 'N', 'N', 'N', 'N', 'O', 'O', 'N', 'N', '~', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'A', 'N', 'O', 'N', 'N', 'A', 'N', 'N', 'N', 'N', 'A', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'O', 'O', 'O', 'O', 'O', 'N', 'O', 'N', 'N', 'N', 'O', 'O', 'N', 'O', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'O', 'N', 'N', 'N', '~', 'N', 'N', 'O', 'O', 'N', 'N', 'N', 'N', 'N', 'A', 'N', 'O', 'N', 'N', 'A', 'N', 'O', 'A', 'N', 'O', 'N', '~', 'O', 'A', 'N', 'N', 'O', 'N', 'O', 'N', 'N', 'N', 'O', 'O', 'O', 'N', 'A', 'N', 'N', 'N', 'N', 'N', 'N']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dr-dunstan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:70: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#theCsv2.loc[599] =[0,0,0,0]\n",
    "#theCsv2.loc[600] =[0,0,0,0]\n",
    "#theCsv2\n",
    "#bigdata = pd.concat([theCsv, theCsv2])\n",
    "\n",
    "\n",
    "#theCsv[\"RR_AF_mean\"] = theCsv14[\"0\"]\n",
    "#theCsv[\"RR_AF_SD\"] = theCsv14[\"1\"]\n",
    "#theCsv[\"RR_AF_Skew\"] = theCsv14[\"3\"]\n",
    "'''\n",
    "theCsv[\"Means_dim1_birth\"] = theCsv2[\"Means_dim1_birth\"]\n",
    "theCsv[\"Means_dim1_death\"] = theCsv2[\"Means_dim1_birth\"]\n",
    "theCsv[\"sd_dim1_birth\"] = theCsv2[\"sd_dim1_birth\"]\n",
    "theCsv[\"sd_dim1_death\"] =theCsv2[\"sd_dim1_death\"]\n",
    "\n",
    "theCsv[\"Means_dim2_birth\"] = theCsv3[\"Means_dim2_birth\"]\n",
    "theCsv[\"Means_dim2_death\"] = theCsv3[\"Means_dim2_birth\"]\n",
    "theCsv[\"sd_dim2_birth\"] = theCsv3[\"sd_dim2_birth\"]\n",
    "theCsv[\"sd_dim2_death\"] =theCsv3[\"sd_dim2_death\"]\n",
    "'''\n",
    "#theCsv[\"Means_dim0_birth\"] = theCsv4[\"Means_dim0_birth\"]\n",
    "#theCsv[\"Means_dim0_death\"] = theCsv4[\"Means_dim0_birth\"]\n",
    "#theCsv[\"sd_dim0_birth\"] = theCsv4[\"sd_dim0_birth\"]\n",
    "#theCsv[\"sd_dim0_death\"] =theCsv4[\"sd_dim0_death\"]\n",
    "\n",
    "'''\n",
    "theCsv[\"Lifetime_dim0\"] = theCsv4[\"Lifetime_dim0\"]\n",
    "theCsv[\"Lifetime_dim1\"] = theCsv4[\"Lifetime_dim1\"]\n",
    "theCsv[\"Lifetime_dim2\"] =theCsv4[\"Lifetime_dim2\"]\n",
    "'''\n",
    "\n",
    "#theCsv[\"avg_bottle_dist_dim0\"] =theCsv5[\"Max_life_dim0\"]\n",
    "#theCsv[\"sd_bottle_dist_dim0\"] =theCsv5[\"Max_life_dim1\"]\n",
    "\n",
    "\n",
    "#theCsv[\"avg_bottle_dist_dim1\"] =theCsv5[\"Max_life_dim0\"]\n",
    "#theCsv[\"sd_bottle_dist_dim1\"] =theCsv6[\"V2\"]\n",
    "\n",
    "#theCsv[\"avg_bottle_dist_dim2\"] =theCsv7[\"V1\"]\n",
    "#theCsv[\"sd_bottle_dist_dim2\"] =theCsv7[\"V2\"]\n",
    "\n",
    "#theCsv[\"num_dim0\"] = theCsv8[\"x\"]\n",
    "#theCsv[\"num_dim1\"] = theCsv9[\"x\"]\n",
    "#theCsv[\"num_dim2\"] = theCsv10[\"x\"]\n",
    "\n",
    "#theCsv[\"num_dim1\"] = theCsv10[\"x\"]\n",
    "\n",
    "#theCsv[\"skew_death1\"] =theCsv12[\"skew.death.dim1\"]\n",
    "#theCsv[\"skew_death2\"] =theCsv12[\"skew.death.dim2\"]\n",
    "#theCsv[\"skew_death0\"] =theCsv12[\"skew.death.dim0\"]\n",
    "\n",
    "\n",
    "#theCsv[\"skew_birth1\"] = theCsv11[\"skew.birth.dim1\"]\n",
    "#theCsv[\"skew_birth2\"] = theCsv11[\"skew.birth.dim2\"]\n",
    "\n",
    "\n",
    "theCsv[\"num_per0\"] = theCsv14[\"0\"]\n",
    "theCsv[\"num_per1\"] = theCsv14[\"1\"]\n",
    "theCsv[\"num_per2\"] = theCsv14[\"3\"]\n",
    "\n",
    "\n",
    "\n",
    "#theCsv[\"RR_R_mean\"] = theCsv16[\"0\"]\n",
    "#print(theCsv)\n",
    "#theCsv\n",
    "#print(np.isnan(theCsv))\n",
    "\n",
    "theCsv[\"num_per0\"][1956] = 1000\n",
    "theCsv[\"num_per1\"][1956] = 1000\n",
    "theCsv[\"num_per2\"][1956] = 1000\n",
    "print(len(theTotal))\n",
    "\n",
    "theCsv[\"Normal\"] = theTotal\n",
    "#theCsv\n",
    "print(theCsv)\n",
    "print(theTotal)\n",
    "#theCsv.fillna(theCsv.mean())\n",
    "\n",
    "#print(np.where(theCsv.values >= np.finfo(np.float64).max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N', 'N', 'N', 'N', 'A', 'A', 'O', 'N', 'O', 'O', 'N', 'N', 'N', 'O', 'O', 'N', 'O', 'A', 'N', 'A', 'N', 'N', 'A', 'A', 'O', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'O', 'N', 'O', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'N', '~', '~', 'N', 'N', 'N', 'N', 'N', 'A', 'N', 'N', 'O', 'N', 'O', 'N', 'N', 'O', 'N', 'A', 'O', 'N', 'O', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'O', 'N', 'A', 'N', '~', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'A', 'N', 'N', 'N', 'A', 'O', 'N', 'A', 'O', 'O', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'A', 'N', 'O', 'O', 'A', 'A', 'N', 'N', 'A', 'N', 'N', 'O', 'N', 'N', 'N', 'O', 'N', 'O', 'O', 'N', 'N', 'N', 'O', 'O', 'O', 'N', 'N', 'N', 'O', 'O', 'N', 'N', 'O', 'O', 'N', 'O', 'A', 'N', 'O', 'O', 'N', 'N', 'N', 'O', 'N', 'O', 'N', 'N', 'A', 'N', 'N', 'N', 'N', 'O', 'N', 'O', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'O', 'O', 'O', 'N', 'N', 'A', 'A', 'O', 'N', 'N', 'N', 'N', 'N', 'A', 'N', 'O', 'N', 'O', 'O', 'N', 'N', 'N', 'N', 'O', 'A', 'O', 'N', 'N', 'O', 'N', 'O', 'A', 'A', 'N', 'O', 'N', 'O', 'A', 'A', 'N', 'A', 'N', 'O', 'A', 'N', '~', 'N', 'N', 'A', 'N', 'N', '~', 'N', 'O', 'O', 'N', 'O', 'O', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'O', 'A', 'N', 'N', 'A', 'N', 'N', 'N', 'A', 'O', 'O', 'N', 'N', 'O', 'N', 'N', 'N', 'O', 'N', 'O', 'N', 'A', 'N', 'O', 'N', 'A', '~', 'O', 'N', 'O', 'N', 'N', 'N', 'O', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'O', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'A', 'O', 'N', 'N', 'N', 'N', 'O', 'O', '~', 'N', 'O', 'N', 'O', 'N', 'N', 'N', 'O', 'O', 'N', 'N', 'O', '~', 'N', 'O', 'N', 'O', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'O', 'N', 'N', 'O', 'O', 'N', 'N', 'N', '~', 'O', 'O', 'O', 'N', 'O', 'N', 'N', 'A', 'O', 'N', 'N', 'A', 'N', 'A', 'N', 'N', 'N', 'O', 'O', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'A', 'O', 'O', 'N', 'N', 'A', 'A', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'A', 'N', 'N', 'O', 'N', 'N', 'O', 'O', 'N', 'N', 'N', 'N', 'N', '~', 'N', 'N', 'O', 'O', 'N', 'N', 'N', 'A', 'N', 'O', 'N', 'N', 'N', 'O', 'A', 'N', 'A', 'N', 'N', 'N', 'N', '~', 'N', 'N', 'O', 'O', 'N', 'N', 'N', 'N', 'A', 'N', 'O', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'N', '~', 'N', 'N', 'O', 'O', 'A', 'N', 'N', 'N', 'N', 'O', 'N', 'O', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'A', 'N', 'N', 'O', 'N', 'A', 'O', 'A', 'N', 'N', 'O', 'N', 'N', 'O', 'N', 'A', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'N', 'O', 'N', '~', 'N', 'A', 'N', 'N', 'N', 'N', 'A', 'O', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'N', 'N', 'A', 'N', 'N', 'O', 'A', 'O', 'O', 'N', 'N', 'N', 'N', 'O', 'N', 'O', 'N', 'N', 'N', 'O', 'N', 'O', 'O', 'N', 'N', 'O', 'O', 'A', 'O', '~', 'N', 'A', 'N', 'A', 'N', 'N', 'N', 'O', 'O', 'N', 'O', 'O', 'N', 'N', 'N', 'N', 'O', 'N', 'N', 'A', 'O', 'N', '~', 'A', 'N', 'N', 'O', 'N', 'N', '~', 'N', 'O', 'O', 'N', 'N', 'N', 'N', 'N', 'O', 'O', '~', 'N', 'O', 'N', 'O', 'N', 'N', 'O', 'N', 'O', 'O', 'N', 'N', 'N', 'O', 'N', 'N', 'A', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'O', 'O', 'O', 'O', 'N', 'N', 'N']\n"
     ]
    }
   ],
   "source": [
    "### code from meduim torwards data scienec example\n",
    "# Labels are the values we want to pred\n",
    "\n",
    "labels = np.array(theCsv[\"Normal\"])\n",
    "\n",
    "# Remove the labels from the features\n",
    "# axis 1 refers to the columns\n",
    "theCsv = theCsv.drop('Normal', axis = 1)\n",
    "#theCsv = theCsv.drop('AF', axis = 1)\n",
    "#theCsv = theCsv.drop('Random', axis = 1)\n",
    "\n",
    "# Saving feature names for later use\n",
    "feature_list = list(theCsv.columns)\n",
    "\n",
    "# Convert to numpy array\n",
    "features = np.array(theCsv)\n",
    "\n",
    "\n",
    "# Using Skicit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(theCsv, labels, test_size = 0.33, random_state = 42)\n",
    "\n",
    "\n",
    "print(test_labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model we are using\n",
    "#from sklearn.ensemble import RandomForest\n",
    "predict_list = []\n",
    "# Instantiate model with 1000 decision trees\n",
    "for i in range(0,700):\n",
    "    #rf = RandomForestClassifier(bootstrap=True,max_depth=20,max_features=\"sqrt\",min_samples_leaf=4,min_samples_split=10,n_estimators=50,random_state=118)\n",
    "    rf = RandomForestClassifier(bootstrap=True,max_depth=20,max_features=\"sqrt\",min_samples_leaf=4,min_samples_split=10,n_estimators=i+1,random_state=42)\n",
    "\n",
    "# Train the model on training data\n",
    "    rf.fit(train_features, train_labels)\n",
    "\n",
    "    predictions = rf.predict(test_features)\n",
    "    predict_list.append(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theMax = 0\n",
    "for i in range(0,1):    \n",
    "    if(accuracy_score(test_labels, predict_list[i]) > theMax):\n",
    "        theMax = np.average(f1_score(test_labels, predictions, average=None))\n",
    "print(theMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = confusion_matrix(test_labels, predictions,labels=[\"A\", \"N\", \"R\",\"~\"])\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print('Parameters currently in use:\\n')\n",
    "#print(rf.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "random_grid ={'bootstrap': [True, False],\n",
    " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    " 'max_features': ['auto', 'sqrt'],\n",
    " 'min_samples_leaf': [1, 2, 4],\n",
    " 'min_samples_split': [2, 5, 10],\n",
    " 'n_estimators': [10,15,20,25,30,50,100,200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "#rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 500, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "#rf_random.fit(train_features, train_labels)\n",
    "\n",
    "#rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var1 = 36/(29+28)\n",
    "var2 = 48/(31+39)\n",
    "var3 = 112/(73+66)\n",
    "\n",
    "print((var1+var2+var3)/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
