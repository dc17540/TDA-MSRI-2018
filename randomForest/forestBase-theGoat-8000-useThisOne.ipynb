{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing libares \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "import random "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "theCsv[\"avg_bottle_dist_dim0\"] =theCsv5[\"avg_bottle_dist_dim0\"]\n",
    "theCsv[\"sd_bottle_dist_dim0\"] =theCsv5[\"sd_bottle_dist_dim0\"]\n",
    "\n",
    "\n",
    "#theCsv[\"avg_bottle_dist_dim0\"] =theCsv6[\"avg_bottle_dist_dim0\"]\n",
    "#theCsv[\"sd_bottle_dist_dim0\"] =theCsv6[\"sd_bottle_dist_dim0\"]\n",
    "\n",
    "theCsv[\"avg_bottle_dist_dim0\"] =theCsv7[\"avg_bottle_dist_dim0\"]\n",
    "theCsv[\"sd_bottle_dist_dim0\"] =theCsv7[\"sd_bottle_dist_dim0\"]\n",
    "118\n",
    "\n",
    "['N', 'R', 'R', 'N', 'N', 'AF', 'N', 'R', 'N', 'AF', 'N', 'N', 'N', 'R', 'AF', 'AF', 'N', 'AF', 'N', 'N', 'N', 'R', 'R', 'R', 'AF', 'R', 'N', 'N', 'R', 'R', 'R', 'N', 'N', 'AF', 'N', 'R', 'N', 'R', 'R', 'AF', 'AF', 'N', 'R', 'R', 'N', 'N', 'R', 'N', 'N', 'R', 'AF', 'AF', 'N', 'R', 'R', 'AF', 'AF', 'N', 'N', 'N', 'N', 'N', 'AF', 'R', 'R', 'N', 'R', 'R', 'N', 'AF', 'AF', 'N', 'R', 'AF', 'R', 'R', 'AF', 'AF', 'R', 'R', 'AF', 'R', 'R', 'AF', 'N', 'N', 'N', 'AF', 'AF', 'AF', 'AF', 'R', 'N', 'AF', 'AF', 'AF', 'AF', 'N', 'R', 'N', 'N', 'AF', 'R', 'AF', 'N', 'R', 'N', 'AF', 'AF', 'R', 'N', 'R', 'R', 'R', 'AF', 'AF', 'AF', 'N', 'R', 'R', 'N', 'N', 'AF', 'R', 'N', 'N', 'R', 'AF', 'R', 'R', 'N', 'R', 'N', 'N', 'R', 'N', 'N', 'N', 'AF', 'N', 'N', 'AF', 'N', 'N', 'R', 'N', 'AF', 'R', 'N', 'N', 'R', 'R', 'AF', 'AF', 'R', 'AF', 'N', 'R', 'N', 'N', 'AF', 'AF', 'N', 'R', 'AF', 'N', 'AF', 'AF', 'R', 'AF', 'AF', 'AF', 'R', 'R', 'N', 'N', 'R', 'N', 'N', 'AF', 'N', 'AF', 'R', 'R', 'R', 'AF', 'AF', 'R', 'AF', 'AF', 'R', 'R', 'N', 'AF', 'R', 'AF', 'R', 'AF']\n",
    "\n",
    "['N', 'R', 'R', 'N', 'N', 'AF', 'N', 'R', 'N', 'AF', 'N', 'N', 'N', 'R', 'AF', 'AF', 'N', 'AF', 'N', 'N', 'N', 'R', 'R', 'R', 'AF', 'R', 'N', 'N', 'R', 'R', 'R', 'N', 'N', 'AF', 'N', 'R', 'N', 'R', 'R', 'AF', 'AF', 'N', 'R', 'R', 'N', 'N', 'R', 'N', 'N', 'R', 'AF', 'AF', 'N', 'R', 'R', 'AF', 'AF', 'N', 'N', 'N', 'N', 'N', 'AF', 'R', 'R', 'N', 'R', 'R', 'N', 'AF', 'AF', 'N', 'R', 'AF', 'R', 'R', 'AF', 'AF', 'R', 'R', 'AF', 'R', 'R', 'AF', 'N', 'N', 'N', 'AF', 'AF', 'AF', 'AF', 'R', 'N', 'AF', 'AF', 'AF', 'AF', 'N', 'R', 'N', 'N', 'AF', 'R', 'AF', 'N', 'R', 'N', 'AF', 'AF', 'R', 'N', 'R', 'R', 'R', 'AF', 'AF', 'AF', 'N', 'R', 'R', 'N', 'N', 'AF', 'R', 'N', 'N', 'R', 'AF', 'R', 'R', 'N', 'R', 'N', 'N', 'R', 'N', 'N', 'N', 'AF', 'N', 'N', 'AF', 'N', 'N', 'R', 'N', 'AF', 'R', 'N', 'N', 'R', 'R', 'AF', 'AF', 'R', 'AF', 'N', 'R', 'N', 'N', 'AF', 'AF', 'N', 'R', 'AF', 'N', 'AF', 'AF', 'R', 'AF', 'AF', 'AF', 'R', 'R', 'N', 'N', 'R', 'N', 'N', 'AF', 'N', 'AF', 'R', 'R', 'R', 'AF', 'AF', 'R', 'AF', 'AF', 'R', 'R', 'N', 'AF', 'R', 'AF', 'R', 'AF']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#getting lables \n",
    "theTotal = []\n",
    "classDict = {}\n",
    "lineCount = 0\n",
    "\n",
    "x = open(\"REFERENCE-v3.csv\")\n",
    "for line in x:\n",
    "    line = line.strip()\n",
    "    a,b = line.split(\",\")\n",
    "    theTotal.append(b)\n",
    "    \n",
    "    \n",
    "\n",
    "  \n",
    "#theFrame = {\"mean\":[],\"std_dev\":[],\"theClass\":[]}\n",
    "\n",
    "\n",
    "\n",
    "#reading in code\n",
    "theCsv = pd.read_csv(\"SD_matrix_8528_new_index.csv\", index_col=0)\n",
    "\n",
    "\n",
    "#theCsv = pd.read_csv(\"0_8528_Organized_Mean_sd_dimension_0.csv\", index_col=0)\n",
    "\n",
    "theCsv1 = pd.read_csv(\"Mean_matrix_8528.csv\",index_col=0)\n",
    "theCsv11 = pd.read_csv(\"Skew_matrix_8528.csv\",index_col=0)\n",
    "theCsv111 = pd.read_csv(\"Kurt_matrix_8528.csv\",index_col=0)\n",
    "\n",
    "theCsv2 = pd.read_csv(\"0_8528_Organized_Mean_sd_dimension_1.csv\",index_col=0)\n",
    "theCsv3 = pd.read_csv(\"0_8528_Organized_Mean_sd_dimension_2.csv\",index_col=0)\n",
    "theCsv4 = pd.read_csv(\"0-8528sum_of_lifetimes.csv\",index_col=0)\n",
    "#0-8528_sd_lifetimes.csv\n",
    "theCsv5 = pd.read_csv(\"0_8528_skew_lifetimes_dim_1_2.csv\",index_col=0)\n",
    "theCsv6 = pd.read_csv(\"0_8528_Organized_Mean_sd_dimension_0.csv\",index_col=0)\n",
    "theCsv7 = pd.read_csv(\"0_8528_diagdist_mean_sd_dim12.csv\",index_col=0)\n",
    "#print(theCsv6[\"0\"])\n",
    "theCsv8 = pd.read_csv(\"0_8528_number_pts_dim_0_1_2.csv\",index_col=0)\n",
    "theCsv9 = pd.read_csv(\"0-8528_sd_lifetimes.csv\",index_col=0)\n",
    "theCsv10 = pd.read_csv(\"0_8528dim1_no_pers_pts_Mean_Sd.csv\",index_col=0)\n",
    "theCsv12 = pd.read_csv(\"0_8528nopers_pts_0_8528_kurt_lifetimes.csv\",index_col=0)\n",
    "theCsv13 = pd.read_csv(\"0_8528nopers_pts_0_8528_skew_lifetimes_dim_1_2.csv\",index_col=0)\n",
    "\n",
    "'''\n",
    "theCsv2 = pd.read_csv(\"Mean_sd_dimension_1.csv\",index_col=0)\n",
    "theCsv3 = pd.read_csv(\"Mean_sd_dimension_2.csv\",index_col=0)\n",
    "\n",
    "theCsv5 = pd.read_csv(\"Maximum_lifetimes_all_dims.csv\",index_col=0)\n",
    "\n",
    "\n",
    "theCsv9 = pd.read_csv(\"number_of_births_deaths_dim1.csv\",index_col=0)\n",
    "theCsv10 = pd.read_csv(\"number_of_births_deaths_dim2.csv\",index_col=0)\n",
    "theCsv11 = pd.read_csv(\"skewness_birth_dim012.csv\",index_col=0)\n",
    "theCsv12 = pd.read_csv(\"skewness_death_dim012.csv\",index_col=0)\n",
    "theCsv13 = pd.read_csv(\"a.csv\",index_col=0)\n",
    "theCsv14 = pd.read_csv(\"Total_matrix_RR_interval_2392.csv\",index_col=0)\n",
    "theCsv15 = pd.read_csv(\"rr_normal.csv\",index_col=0)\n",
    "theCsv16 = pd.read_csv(\"rr_R.csv\",index_col=0)\n",
    "'''\n",
    "#theCsv8 = pd.read_csv(\"reduced_bottleneck_ave_sd_dist_dim2.csv\",index_col=0)\n",
    "#bigData = theCsv.append(theCsv2, ignore_index=True)\n",
    "\n",
    "#print(bigData)\n",
    "\n",
    "aList = []\n",
    "aList2 = []\n",
    "aList3 = []\n",
    "for i in range(0,200):\n",
    "    aList.append(\"N\")\n",
    "    aList2.append(0)\n",
    "    aList3.append(0)\n",
    "\n",
    "for i in range(0,200):\n",
    "    aList.append(\"AF\")\n",
    "    aList2.append(1)\n",
    "    aList3.append(0)\n",
    "    \n",
    "for i in range(0,200):\n",
    "    aList.append(\"R\")\n",
    "    aList2.append(0)\n",
    "    aList3.append(1)\n",
    "\n",
    "#theCsv[\"Normal\"] = np.asarray(aList)\n",
    "#theCsv[\"AF\"] = np.asarray(aList2)\n",
    "#theCsv[\"Random\"] = np.asarray(aList3)\n",
    "#### make dataframe \n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#theCsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#all code to to create csv\n",
    "# stuff inbetweeen ''' ''' is commented code\n",
    "\n",
    "\n",
    "theCsv[\"Mean_RR\"] = theCsv1[\"0\"]\n",
    "theCsv[\"Skew_RR\"] = theCsv11[\"0\"]\n",
    "theCsv[\"Kurt_RR\"] = theCsv111[\"0\"]\n",
    "\n",
    "\n",
    "\n",
    "#theCsv[\"Means_dim1_birth\"] = theCsv6[\"Means_dim0_birth\"]\n",
    "#theCsv[\"Means_dim1_death\"] = theCsv6[\"Means_dim0_birth\"]\n",
    "#theCsv[\"sd_dim1_birth\"] = theCsv6[\"sd_dim0_birth\"]\n",
    "#theCsv[\"sd_dim1_death\"] =theCsv6[\"sd_dim0_death\"]\n",
    "\n",
    "theCsv[\"Means_dim1_birth\"] = theCsv2[\"Means_dim1_birth\"]\n",
    "theCsv[\"Means_dim1_death\"] = theCsv2[\"Means_dim1_birth\"]\n",
    "theCsv[\"sd_dim1_birth\"] = theCsv2[\"sd_dim1_birth\"]\n",
    "theCsv[\"sd_dim1_death\"] =theCsv2[\"sd_dim1_death\"]\n",
    "\n",
    "\n",
    "#theCsv[\"Means_dim2_birth\"] = theCsv3[\"Means_dim2_birth\"]\n",
    "theCsv[\"Means_dim2_death\"] = theCsv3[\"Means_dim2_birth\"]\n",
    "theCsv[\"sd_dim2_birth\"] = theCsv3[\"sd_dim2_birth\"]\n",
    "theCsv[\"sd_dim2_death\"] =theCsv3[\"sd_dim2_death\"]\n",
    "\n",
    "\n",
    "\n",
    "#theCsv[\"Lifetime_dim0\"] = theCsv4[\"Lifetime_dim0\"]\n",
    "theCsv[\"Lifetime_dim1\"] = theCsv4[\"Lifetime_dim1\"]\n",
    "theCsv[\"Lifetime_dim2\"] =theCsv4[\"Lifetime_dim2\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#theCsv[\"V1\"] =theCsv5[\"V2\"]\n",
    "#theCsv[\"sd_bottle_dist_dim0\"] =theCsv5[\"Max_life_dim1\"]\n",
    "\n",
    "#theCsv[\"sd_life_dim1\"] =theCsv5[\"sd_life_dim1\"]\n",
    "theCsv[\"skew_life_dim0\"] =theCsv5[\"skew_life_dim0\"]\n",
    "theCsv[\"skew_life_dim1\"] =theCsv5[\"skew_life_dim1\"]\n",
    "theCsv[\"skew_life_dim2\"] =theCsv5[\"skew_life_dim2\"]\n",
    "\n",
    "#theCsv[\"avg_dist_dim2\"] =theCsv7[\"avg_dist_dim2\"]\n",
    "theCsv[\"avg_dist_dim2\"] =theCsv7[\"sd_dist_dim1\"]\n",
    "\n",
    "#theCsv[\"num_dim0\"] = theCsv8[\"num_pts_dim0\"]\n",
    "theCsv[\"num_dim1\"] = theCsv8[\"num_pts_dim1\"]\n",
    "#theCsv[\"num_dim2\"] = theCsv8[\"num_pts_dim2\"]\n",
    "\n",
    "\n",
    "y = open(\"0-8528_sd_lifetimes.csv\")\n",
    "\n",
    "aList = []\n",
    "aList2 =[]\n",
    "count = 0\n",
    "for line in y:\n",
    "    if(count != 0):\n",
    "        line = line.strip()\n",
    "        a,b,c,d = line.split(\",\")\n",
    "        aList.append(b)\n",
    "        aList2.append(c)\n",
    "    count +=  1\n",
    "theCsv[\"sd_life_dim1\"] = np.array(aList)\n",
    "theCsv[\"sd_life_dim2\"] = np.array(aList2)\n",
    "\n",
    "theCsv[\"Means_dim1_birth_noPersist\"] = theCsv10[\"sd_dim1_birth\"]\n",
    "\n",
    "theCsv[\"Means_dim2_birth_noPersistt\"] = theCsv12[\"kurt_life_dim1\"]\n",
    "#theCsv[\"Means_dim2_birth_noPersisttttt\"] = theCsv13[\"skew_life_dim2\"]\n",
    "#theCsv[\"RR_top\"] \n",
    "#theCsv[\"RR_top\"][8528] = 1000\n",
    "#8528\n",
    "\n",
    "#theCsv[\"avg_bottle_dist_dim1\"] =theCsv5[\"Max_life_dim0\"]\n",
    "#theCsv[\"sd_bottle_dist_dim1\"] =theCsv6[\"V2\"]\n",
    "\n",
    "#\n",
    "#theCsv[\"sd_bottle_dist_dim2\"] =theCsv7[\"V2\"]\n",
    "\n",
    "#theCsv[\"num_dim0\"] = theCsv8[\"x\"]\n",
    "#theCsv[\"num_dim1\"] = theCsv9[\"x\"]\n",
    "#theCsv[\"num_dim2\"] = theCsv10[\"x\"]\n",
    "\n",
    "#theCsv[\"num_dim1\"] = theCsv10[\"x\"]\n",
    "\n",
    "#theCsv[\"skew_death1\"] =theCsv12[\"skew.death.dim1\"]\n",
    "#theCsv[\"skew_death2\"] =theCsv12[\"skew.death.dim2\"]\n",
    "#theCsv[\"skew_death0\"] =theCsv12[\"skew.death.dim0\"]\n",
    "\n",
    "'''\n",
    "theCsv[\"skew_birth1\"] = theCsv11[\"skew.birth.dim1\"]\n",
    "#theCsv[\"skew_birth2\"] = theCsv11[\"skew.birth.dim2\"]\n",
    "print(len(theCsv[\"skew_birth1\"]))\n",
    "\n",
    "theCsv[\"num_per0\"] = theCsv14[\"0\"]\n",
    "theCsv[\"num_per1\"] = theCsv14[\"1\"]\n",
    "theCsv[\"num_per2\"] = theCsv14[\"2\"]\n",
    "theCsv[\"num_per2\"] = theCsv14[\"3\"]\n",
    "\n",
    "\n",
    "\n",
    "#theCsv[\"RR_R_mean\"] = theCsv16[\"0\"]\n",
    "#print(theCsv)\n",
    "#theCsv\n",
    "#print(np.isnan(theCsv))\n",
    "\n",
    "#theCsv[\"num_per0\"][1956] = 1000\n",
    "#theCsv[\"num_per1\"][1956] = 1000\n",
    "#theCsv[\"num_per2\"][1956] = 1000\n",
    "print(len(theTotal))\n",
    "\n",
    "\n",
    "print(theCsv)\n",
    "theCsv[\"Normal\"] = theTotal\n",
    "#theCsv\n",
    "#print(theCsv)\n",
    "#print(theTotal)\n",
    "theCsv.fillna(1000)\n",
    "theCsv.replace(np.inf, 1000)\n",
    "\n",
    "#print(np.where(theCsv.values >= np.finfo(np.float64).max))\n",
    "#theCsv\n",
    "#theCsv = theCsv.loc[:, ~theCsv.columns.str.contains('^Unnamed')]\n",
    "\n",
    "\n",
    "#theCsv22 = theCsv.isnull().any\n",
    "\n",
    "\n",
    "#for i in range(0,8529):\n",
    "#    if(theCsv22[\"RR_top\"][i] != True):\n",
    "#        print(i)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(theCsv[\"RR_top\"])\n",
    "theCsv\n",
    "'''\n",
    "theCsv[\"Normal\"] = theTotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\n",
      "(8528, 23)\n",
      "(7412, 23)\n"
     ]
    }
   ],
   "source": [
    "#code to get balaned training or balanced testing\n",
    "# not used for now \n",
    "theCsv\n",
    "theCsv_sorted = theCsv.sort_values(by='Normal')\n",
    "\n",
    "print(theCsv_sorted[\"Normal\"][1])\n",
    "theL = []\n",
    "normList = []\n",
    "oList =[]\n",
    "aaList = []\n",
    "noiseList =[]\n",
    "for i in range(1,8529):\n",
    "    if(theCsv[\"Normal\"][i] == \"~\"):\n",
    "        noiseList.append(i)\n",
    "    elif(theCsv[\"Normal\"][i]== \"A\"):\n",
    "        aaList.append(i)\n",
    "    elif(theCsv[\"Normal\"][i] == \"O\"):\n",
    "        oList.append(i)\n",
    "    else:\n",
    "        normList.append(i)\n",
    "        \n",
    "        \n",
    "normSamp = np.random.choice(normList, len(noiseList),replace=False)\n",
    "aaSamp = np.random.choice(aaList, len(noiseList),replace=False)\n",
    "oSamp = np.random.choice(oList,len(noiseList),replace=False)\n",
    "noiseSamp = np.random.choice(noiseList,len(noiseList),replace=False)\n",
    "\n",
    "#theCsv = theCsv.set_index(theL)\n",
    "\n",
    "#print(len(normSamp))\n",
    "#print(len(aaSamp))\n",
    "#print(len(oSamp))\n",
    "#print(len(noiseSamp))\n",
    "\n",
    "random.Random(500)\n",
    "\n",
    "theFinList = normSamp.tolist() + aaSamp.tolist() + oSamp.tolist() + noiseSamp.tolist()\n",
    "#print(len(theFinList))\n",
    "\n",
    "        \n",
    "theTrain =  theCsv.drop(theFinList)\n",
    "#print(list(set([x for x in theFinList if a.count(x) > 1])))\n",
    "\n",
    "print(theCsv.shape)\n",
    "print(theTrain.shape)\n",
    "theTest = theCsv[~theCsv.index.isin(theTrain.index)]\n",
    "#print(theCsv[~theCsv.index.isin(theTrain.index)].shape)\n",
    "theTrain.shape\n",
    "\n",
    "bal_train_labels = np.array(theTest[\"Normal\"])\n",
    "bal_test_labels = np.array(theTrain[\"Normal\"])\n",
    "theTest = theTest.drop(\"Normal\",axis=1)\n",
    "theTrain = theTrain.drop(\"Normal\",axis=1)\n",
    "theTempp = theTrain\n",
    "theTrain = theTest\n",
    "theTest = theTempp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Labels are the values we want to pred\n",
    "\n",
    "#code to get a unblanced test and train\n",
    "\n",
    "labels = np.array(theCsv[\"Normal\"])\n",
    "\n",
    "# Remove the labels from the features\n",
    "# axis 1 refers to the columns\n",
    "theCsv = theCsv.drop('Normal', axis = 1)\n",
    "#theCsv = theCsv.drop('AF', axis = 1)\n",
    "#theCsv = theCsv.drop('Random', axis = 1)\n",
    "\n",
    "# Saving feature names for later use\n",
    "feature_list = list(theCsv.columns)\n",
    "\n",
    "# Convert to numpy array\n",
    "features = np.array(theCsv)\n",
    "\n",
    "\n",
    "# Using Skicit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(theCsv, labels, test_size = 0.11726, random_state = 42)\n",
    "\n",
    "\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#code to train the random forest\n",
    "predict_list = []\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0,1):\n",
    "    #rf = RandomForestClassifier(bootstrap=True,max_depth=20,max_features=\"sqrt\",min_samples_leaf=4,min_samples_split=10,n_estimators=50,random_state=118)\n",
    "    rf = RandomForestClassifier(bootstrap=True,max_depth=10,max_features=\"sqrt\",min_samples_leaf=1,min_samples_split=5,n_estimators=600,random_state=40,class_weight=\"balanced\")\n",
    "\n",
    "#rf = RandomForestClassifier(bootstrap=True,max_depth=10,max_features=\"sqrt\",min_samples_leaf=1,min_samples_split=5,n_estimators=600,random_state=42)\n",
    "\n",
    "    \n",
    "\n",
    "# Train the model on training data\n",
    "    rf.fit(train_features,train_labels)\n",
    "\n",
    "    #test the model and append the results\n",
    "    predictions = rf.predict(test_features)\n",
    "    predict_list.append(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0  Mean_RR  Skew_RR  Kurt_RR  Means_dim1_birth  Means_dim1_death  \\\n",
      "5     65.34   161.19     1.20     0.09              1.43              1.43   \n",
      "6     19.67   309.93    -1.91     2.96              0.48              0.48   \n",
      "10     6.86   275.81    -0.23    -0.74              0.56              0.56   \n",
      "15    60.25   192.72     0.08    -0.89              1.44              1.44   \n",
      "22   123.86   204.03     2.79     9.14              1.63              1.63   \n",
      "34    88.36   255.24    -1.06    -0.57              1.74              1.74   \n",
      "38    48.13   313.62    -1.92     5.31              0.68              0.68   \n",
      "41    55.49   224.53    -0.00     0.02              2.44              2.44   \n",
      "54    54.67   231.53    -0.14     0.66              3.75              3.75   \n",
      "56    46.42   144.78     0.52     1.60              2.51              2.51   \n",
      "58    28.17   197.95     0.57     2.88              0.52              0.52   \n",
      "65    43.14   249.17    -1.07     3.61              0.81              0.81   \n",
      "87    15.50   173.64     0.01    -1.87              0.77              0.77   \n",
      "99    44.12   246.88    -2.26     4.80              2.26              2.26   \n",
      "106   58.18   242.37    -1.86     1.92              2.53              2.53   \n",
      "115   32.91   195.09    -1.82     3.11              1.27              1.27   \n",
      "125   65.45   178.44    -0.48    -1.35              1.41              1.41   \n",
      "128   50.52   286.00     0.71     0.13              0.63              0.63   \n",
      "139   71.48   248.33    -0.95    -0.80              2.03              2.03   \n",
      "141   22.07   228.29    -0.57    -0.87              1.25              1.25   \n",
      "158   12.90   187.98    -1.12     6.19              1.20              1.20   \n",
      "162   12.64   244.68    -0.10    -0.78              0.98              0.98   \n",
      "164   71.91   178.36    -0.26    -1.36              1.67              1.67   \n",
      "176   39.60   276.50    -3.11     9.84              0.63              0.63   \n",
      "191   35.53   259.39    -4.22    19.55              0.72              0.72   \n",
      "196   10.50    87.50     0.00    -2.00              0.97              0.97   \n",
      "201   58.40   196.31    -0.69    -0.65              0.41              0.41   \n",
      "205   66.87   158.83     0.58    -0.63              0.48              0.48   \n",
      "206    6.16   309.74     0.09    -0.77              0.44              0.44   \n",
      "220   14.11   186.57    -0.14    -0.79              0.93              0.93   \n",
      "...     ...      ...      ...      ...               ...               ...   \n",
      "8331  44.13   263.47    -0.76     2.46              0.77              0.77   \n",
      "8343   9.32   235.61    -0.65    -0.16              0.78              0.78   \n",
      "8348  35.53   283.23    -1.34     2.22              1.11              1.11   \n",
      "8353  11.34   135.62     1.05     2.55              1.23              1.23   \n",
      "8372  90.75   159.55     0.62    -0.93              1.73              1.73   \n",
      "8377  44.79   103.83     1.41     0.55              2.82              2.82   \n",
      "8378  39.14   235.77    -1.17     0.28              1.26              1.26   \n",
      "8380  33.88   241.80    -3.55    14.58              0.65              0.65   \n",
      "8392  62.67   297.26     0.25    -0.72              0.49              0.49   \n",
      "8394   7.40   186.15    -0.09    -0.43              0.73              0.73   \n",
      "8402  28.30   119.50     1.09    -0.73              2.05              2.05   \n",
      "8405  44.10   243.00    -0.68     0.40              0.42              0.42   \n",
      "8407  15.78   301.07    -4.44    19.58              0.40              0.40   \n",
      "8409  30.42   133.40    -0.52     0.54              1.78              1.78   \n",
      "8414  34.87   182.28     0.13    -1.29              0.75              0.75   \n",
      "8431  41.37   223.71    -0.14     1.02              0.79              0.79   \n",
      "8433  24.97   224.45    -1.27     0.67              1.16              1.16   \n",
      "8436  84.17   282.86    -1.50     0.72              0.32              0.32   \n",
      "8445  21.25   293.67    -0.76    -0.39              1.04              1.04   \n",
      "8451  30.94   233.36     1.32     2.49              0.60              0.60   \n",
      "8456   2.96   106.97    -0.80     5.66              1.47              1.47   \n",
      "8461   8.18   242.26     0.09    -0.38              1.13              1.13   \n",
      "8464  95.96   177.77     1.24     2.03              2.36              2.36   \n",
      "8468  83.25   191.54     0.76     1.62              4.33              4.33   \n",
      "8477   1.52   261.50     0.03    -1.18              0.99              0.99   \n",
      "8489  61.28   156.91    -0.12    -1.65              2.04              2.04   \n",
      "8490  20.32   244.18    -2.98    10.94              1.00              1.00   \n",
      "8493  75.76   157.38     0.69    -0.91              1.49              1.49   \n",
      "8505  47.01   236.83    -2.84     6.56              1.63              1.63   \n",
      "8517   7.75   250.12    -0.33    -0.55              1.15              1.15   \n",
      "\n",
      "      sd_dim1_birth  sd_dim1_death  Means_dim2_death  sd_dim2_birth  \\\n",
      "5              1.43           0.29              1.57           0.16   \n",
      "6              0.16           0.16              0.68           0.08   \n",
      "10             0.16           0.16              0.73           0.15   \n",
      "15             1.44           0.26              1.63           0.27   \n",
      "22             1.63           1.15              1.44           0.62   \n",
      "34             1.74           1.16              1.67           1.15   \n",
      "38             0.68           0.46              0.85           0.48   \n",
      "41             2.44           2.08              2.57           0.74   \n",
      "54             3.75           3.89              4.32           2.43   \n",
      "56             2.51           0.49              3.11           0.48   \n",
      "58             0.52           0.29              0.55           0.06   \n",
      "65             0.81           0.13              0.97           0.06   \n",
      "87             0.77           0.27              1.12           0.12   \n",
      "99             1.98           2.02              2.82           2.35   \n",
      "106            2.53           2.52              2.71           2.22   \n",
      "115            1.27           0.29              1.40           0.18   \n",
      "125            1.41           0.34              1.51           0.23   \n",
      "128            0.63           0.19              0.77           0.08   \n",
      "139            2.03           2.82              0.77           0.12   \n",
      "141            1.25           0.22              1.56           0.07   \n",
      "158            1.20           0.82              1.25           0.56   \n",
      "162            0.98           0.49              1.69           0.15   \n",
      "164            1.67           0.89              1.83           0.49   \n",
      "176            0.63           0.14              0.83           0.16   \n",
      "191            0.30           0.31              0.89           0.12   \n",
      "196            0.97           1.31              1.08           0.07   \n",
      "201            0.41           0.08              0.47           0.07   \n",
      "205            0.48           0.10              0.62           0.08   \n",
      "206            0.34           0.35              1.14           0.00   \n",
      "220            0.93           0.39              0.98           0.26   \n",
      "...             ...            ...               ...            ...   \n",
      "8331           0.77           0.28              1.04           0.04   \n",
      "8343           0.78           0.56              1.49           0.03   \n",
      "8348           0.34           0.34              1.43           0.14   \n",
      "8353           1.23           0.16              1.53           0.09   \n",
      "8372           1.73           2.18              0.87           0.41   \n",
      "8377           2.82           3.45              0.93           1.07   \n",
      "8378           1.26           1.07              1.48           0.24   \n",
      "8380           0.13           0.13              0.71           0.07   \n",
      "8392           0.49           0.30              0.76           0.25   \n",
      "8394           0.17           0.17              0.90           0.06   \n",
      "8402           2.05           4.30              1.12           2.58   \n",
      "8405           0.42           0.06              0.51           0.05   \n",
      "8407           0.40           0.26              0.36           0.29   \n",
      "8409           1.78           1.37              1.47           0.16   \n",
      "8414           0.75           0.10              0.86           0.08   \n",
      "8431           0.79           0.20              0.88           0.06   \n",
      "8433           1.16           0.51              1.31           0.05   \n",
      "8436           0.32           0.14              0.39           0.06   \n",
      "8445           0.31           0.33              1.19           0.19   \n",
      "8451           0.60           0.21              0.68           0.07   \n",
      "8456           1.47           0.67              1.82           0.56   \n",
      "8461           0.61           0.61              1.13           0.17   \n",
      "8464           2.36           2.32              2.29           2.66   \n",
      "8468           4.33           1.68              3.68           1.79   \n",
      "8477           0.19           0.15              1.23           0.07   \n",
      "8489           2.04           0.71              2.12           0.84   \n",
      "8490           1.00           0.56              1.45           0.66   \n",
      "8493           1.49           0.89              1.37           0.18   \n",
      "8505           1.92           1.95              1.63           0.88   \n",
      "8517           0.14           0.14              1.28           0.11   \n",
      "\n",
      "                 ...              Lifetime_dim2  skew_life_dim0  \\\n",
      "5                ...                       5.66            0.34   \n",
      "6                ...                       1.07            0.19   \n",
      "10               ...                       1.62           -0.33   \n",
      "15               ...                       3.92            0.69   \n",
      "22               ...                       0.26            2.57   \n",
      "34               ...                       3.18            1.23   \n",
      "38               ...                       0.30            1.04   \n",
      "41               ...                       2.79            1.80   \n",
      "54               ...                       0.63            1.33   \n",
      "56               ...                       1.77            0.95   \n",
      "58               ...                       2.44            2.05   \n",
      "65               ...                       0.45            1.44   \n",
      "87               ...                       1.06            0.86   \n",
      "99               ...                       0.27            1.47   \n",
      "106              ...                       0.17            1.18   \n",
      "115              ...                       2.24            0.38   \n",
      "125              ...                       6.93            0.33   \n",
      "128              ...                       1.05            0.60   \n",
      "139              ...                       0.25            2.09   \n",
      "141              ...                       1.48            0.81   \n",
      "158              ...                       4.44            0.65   \n",
      "162              ...                       0.93            1.49   \n",
      "164              ...                       0.79            0.74   \n",
      "176              ...                       1.92           -0.64   \n",
      "191              ...                       0.54            0.27   \n",
      "196              ...                       0.85            2.39   \n",
      "201              ...                       2.34            0.65   \n",
      "205              ...                       1.96           -0.52   \n",
      "206              ...                       0.01            0.58   \n",
      "220              ...                       2.26            0.90   \n",
      "...              ...                        ...             ...   \n",
      "8331             ...                       0.24            0.81   \n",
      "8343             ...                       0.40            3.11   \n",
      "8348             ...                       2.35            0.20   \n",
      "8353             ...                      12.99           -0.23   \n",
      "8372             ...                       2.14            0.86   \n",
      "8377             ...                       0.23            1.57   \n",
      "8378             ...                       1.29            3.18   \n",
      "8380             ...                       6.56            0.65   \n",
      "8392             ...                       0.61            1.41   \n",
      "8394             ...                       1.61            0.51   \n",
      "8402             ...                       1.88            1.48   \n",
      "8405             ...                       2.63           -0.36   \n",
      "8407             ...                       0.02            1.69   \n",
      "8409             ...                       4.21            1.57   \n",
      "8414             ...                       3.79            0.36   \n",
      "8431             ...                       0.39            2.00   \n",
      "8433             ...                       1.98            1.65   \n",
      "8436             ...                       0.76            1.34   \n",
      "8445             ...                       2.60            0.38   \n",
      "8451             ...                       2.21            0.73   \n",
      "8456             ...                       3.89            0.60   \n",
      "8461             ...                       1.52           -0.01   \n",
      "8464             ...                       2.42            1.68   \n",
      "8468             ...                       1.14            0.63   \n",
      "8477             ...                       0.86            0.56   \n",
      "8489             ...                       5.43           -0.10   \n",
      "8490             ...                       2.18            5.07   \n",
      "8493             ...                       0.73            0.48   \n",
      "8505             ...                       1.46            3.10   \n",
      "8517             ...                       6.31            0.31   \n",
      "\n",
      "      skew_life_dim1  skew_life_dim2  avg_dist_dim2  num_dim1  sd_life_dim1  \\\n",
      "5               1.23            1.46           0.05       438   0.078112237   \n",
      "6               1.14            0.99           0.02       297   0.034731052   \n",
      "10              1.86            1.51           0.03       325   0.042920596   \n",
      "15              3.54            3.37           0.06       476   0.100909552   \n",
      "22              6.57            1.43           0.08       243   0.145688642   \n",
      "34             10.74            4.37           0.09       508   0.169000645   \n",
      "38              1.27            0.76           0.07       206   0.108973031   \n",
      "41             17.61            2.78           0.12       419   0.529132837   \n",
      "54             13.28            4.05           0.13       222   0.671557103   \n",
      "56              8.06            4.08           0.11       309   0.202849557   \n",
      "58             14.16            2.25           0.02       552   0.046457793   \n",
      "65              3.17            3.01           0.03       101   0.048394656   \n",
      "87              2.38            0.83           0.05       184   0.078044827   \n",
      "99             13.77            2.37           0.07       226   0.431253115   \n",
      "106            13.21            2.68           0.12       267   0.456708285   \n",
      "115             2.27            1.55           0.04       399   0.065313917   \n",
      "125             8.94            2.17           0.05       554   0.091407402   \n",
      "128             1.82            1.30           0.04       208   0.056971512   \n",
      "139            11.60            1.79           0.14       249   0.448561351   \n",
      "141             2.14            3.74           0.07       103   0.120759271   \n",
      "158            14.83            1.57           0.06       572   0.157059184   \n",
      "162             4.38            1.18           0.05        78   0.113293898   \n",
      "164             6.43            2.24           0.07       284   0.112345713   \n",
      "176             5.31            5.48           0.04       452   0.062298509   \n",
      "191            11.98            1.66           0.04       397   0.098522343   \n",
      "196            18.78            1.60           0.03       424   0.201178278   \n",
      "201             3.36            1.60           0.01       520   0.018808426   \n",
      "205             3.03            3.00           0.02       527   0.023924277   \n",
      "206             7.31            0.68           0.02        96   0.074723785   \n",
      "220             8.92            2.14           0.04       476   0.075844375   \n",
      "...              ...             ...            ...       ...           ...   \n",
      "8331            6.94            0.67           0.02       111   0.045656965   \n",
      "8343            7.45            2.17           0.03       133   0.074698333   \n",
      "8348            1.57            1.90           0.06       296   0.088753667   \n",
      "8353            1.24            1.41           0.06       535   0.087888469   \n",
      "8372            5.95            1.91           0.07       440   0.126922021   \n",
      "8377           10.94            0.40           0.11       187   0.383300383   \n",
      "8378            1.64            2.20           0.05       396    0.08089724   \n",
      "8380            1.82            2.15           0.03       759    0.04126304   \n",
      "8392            8.22            3.84           0.02       259   0.038357671   \n",
      "8394            1.41            1.55           0.03       315     0.0386529   \n",
      "8402           13.02            1.17           0.17       401   0.359781189   \n",
      "8405            1.94            2.16           0.02       554   0.027790367   \n",
      "8407            8.39            0.32           0.01       159   0.015062925   \n",
      "8409           20.18            1.98           0.06       555   0.266359512   \n",
      "8414            1.58            1.79           0.03       663   0.039797133   \n",
      "8431            2.09            1.09           0.03       185   0.052873629   \n",
      "8433            3.66            3.38           0.05       282   0.083558115   \n",
      "8436           14.18            3.06           0.02       392   0.075452046   \n",
      "8445            1.92            1.36           0.05       274   0.085273548   \n",
      "8451            5.52            1.78           0.02       437    0.04104442   \n",
      "8456            7.05            1.39           0.07       529    0.11741132   \n",
      "8461            2.06            5.93           0.05       250   0.074176035   \n",
      "8464           17.83            3.40           0.04       409    0.21080006   \n",
      "8468            7.40            2.15           0.23       311   0.399987537   \n",
      "8477            1.21            3.74           0.05       175   0.073113629   \n",
      "8489            5.21            1.21           0.05       471   0.095646179   \n",
      "8490            1.05            3.03           0.03       301   0.048564707   \n",
      "8493           10.76            1.76           0.09       376   0.174984244   \n",
      "8505            8.14            2.49           0.07       278   0.142676398   \n",
      "8517            1.46            2.25           0.06       591   0.083630263   \n",
      "\n",
      "      sd_life_dim2 Means_dim1_birth_noPersist Means_dim2_birth_noPersistt  \n",
      "5      0.036152811                       1.43                        3.59  \n",
      "6      0.007718969                       0.16                        2.95  \n",
      "10     0.019205254                       0.16                        6.33  \n",
      "15      0.02129992                       1.44                       13.85  \n",
      "22     0.008791388                       1.62                       31.34  \n",
      "34     0.027925729                       1.74                      174.79  \n",
      "38     0.006674156                       0.66                        3.61  \n",
      "41     0.032404502                       2.43                       78.59  \n",
      "54     0.062739776                       3.74                       95.25  \n",
      "56     0.060741852                       2.52                       82.44  \n",
      "58     0.011420365                       0.52                        9.39  \n",
      "65     0.027158577                       0.81                       15.92  \n",
      "87     0.022859544                       0.77                        6.10  \n",
      "99     0.009622027                       1.98                       24.53  \n",
      "106    0.026230332                       2.53                       89.01  \n",
      "115    0.014589347                       1.27                        3.63  \n",
      "125    0.020741308                       1.41                       18.62  \n",
      "128     0.01324993                       0.63                        5.31  \n",
      "139    0.009808925                       2.02                        5.33  \n",
      "141    0.022876904                       1.26                        3.50  \n",
      "158    0.015055801                       1.20                       26.00  \n",
      "162    0.039410674                       0.98                       11.92  \n",
      "164     0.02107058                       1.68                       51.06  \n",
      "176     0.01847366                       0.63                       33.46  \n",
      "191    0.007955251                       0.30                      140.52  \n",
      "196     0.01452226                       0.97                       66.87  \n",
      "201    0.007619341                       0.41                       17.20  \n",
      "205    0.011617871                       0.48                       10.31  \n",
      "206    0.001762973                       0.34                       51.65  \n",
      "220    0.012052334                       0.93                        7.68  \n",
      "...            ...                        ...                         ...  \n",
      "8331   0.006442545                       0.77                        2.67  \n",
      "8343    0.00751442                       0.79                       27.58  \n",
      "8348   0.022734284                       0.34                        3.13  \n",
      "8353   0.034498729                       1.23                        3.60  \n",
      "8372   0.011354021                       1.72                       12.08  \n",
      "8377   0.003607168                       2.82                      112.66  \n",
      "8378   0.023591352                       1.26                        4.25  \n",
      "8380   0.011995092                       0.13                        4.86  \n",
      "8392   0.020215217                       0.49                        6.54  \n",
      "8394   0.009063717                       0.17                        3.23  \n",
      "8402   0.013677304                       2.04                      290.68  \n",
      "8405   0.008357993                       0.42                        5.63  \n",
      "8407   0.003170925                       0.40                       22.89  \n",
      "8409   0.016168177                       1.78                       56.97  \n",
      "8414   0.011629447                       0.75                        4.63  \n",
      "8431   0.011350471                       0.79                        3.98  \n",
      "8433   0.008508617                       1.16                        9.85  \n",
      "8436   0.007434334                       0.32                        2.93  \n",
      "8445   0.023696128                       0.31                        2.65  \n",
      "8451   0.009015727                       0.60                       41.09  \n",
      "8456   0.022073423                       1.47                       32.17  \n",
      "8461   0.016923397                       0.61                        4.87  \n",
      "8464   0.018677064                       2.35                       43.34  \n",
      "8468   0.022509501                       4.32                       66.14  \n",
      "8477   0.008797414                       0.19                        1.61  \n",
      "8489   0.027303731                       2.03                       31.24  \n",
      "8490   0.032073719                       1.00                        3.27  \n",
      "8493   0.009732341                       1.49                      172.55  \n",
      "8505   0.017607641                       1.80                       79.28  \n",
      "8517    0.01740357                       0.14                        4.28  \n",
      "\n",
      "[1116 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "#print(theTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N' 'N' 'N' 'O' 'O' 'N' 'O' 'N' 'N' 'N' 'N' 'N' 'N' 'O' 'N' '~' 'N' 'N'\n",
      " 'O' 'O' 'N' 'O' 'N' 'O' 'O' 'O' 'A' 'N' 'N' 'O' 'N' 'O' 'N' 'N' 'O' 'O'\n",
      " 'N' 'N' 'N' 'N' 'N' 'N' 'O' 'N' 'O' 'A' 'N' 'N' 'N' 'A' 'N' 'O' 'N' 'N'\n",
      " 'A' 'N' 'N' 'N' 'N' 'O' 'N' 'O' 'N' 'O' 'A' 'A' 'O' 'N' 'N' 'N' 'N' 'O'\n",
      " 'N' 'N' 'N' 'N' 'N' '~' 'O' 'A' 'N' 'N' 'O' 'A' 'O' 'N' 'N' 'O' 'N' 'A'\n",
      " 'N' 'O' 'A' 'N' 'N' 'N' 'O' 'N' 'O' 'O' 'N' 'N' 'N' 'N' 'O' 'N' '~' 'A'\n",
      " 'O' 'N' 'N' 'N' 'O' 'N' 'N' 'N' 'O' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'A' 'N'\n",
      " 'N' 'N' 'N' 'O' 'O' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'O' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N' 'N' 'N' 'O' 'N' 'N' 'N' 'N' 'O' 'N' 'O' 'N' 'A' 'N' 'N' 'A'\n",
      " 'N' 'O' 'A' 'O' 'N' 'N' 'O' 'N' 'A' 'N' 'N' 'O' 'O' 'N' 'A' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N' 'O' '~' 'A' 'A' 'A' 'A' 'O' 'A' 'O' 'O' 'N' 'O' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N' 'N' 'N' 'O' 'N' 'N' 'N' 'N' 'A' 'N' 'N' 'N' 'O' 'N' 'O' 'O'\n",
      " 'N' 'N' 'N' 'N' 'O' 'N' 'N' 'O' 'O' 'N' 'N' 'N' 'O' 'O' '~' 'N' 'A' 'N'\n",
      " 'O' 'A' 'N' 'O' 'O' 'A' 'N' 'A' 'N' 'N' 'N' 'N' 'N' 'O' 'O' 'N' 'A' 'N'\n",
      " 'N' 'N' 'N' 'O' 'O' 'N' 'N' 'N' 'O' 'N' 'N' 'N' 'N' 'O' 'N' 'O' 'N' 'N'\n",
      " 'N' 'N' 'A' 'N' 'O' 'A' 'N' 'A' 'A' 'N' 'O' 'N' 'O' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'A' 'N' 'N' 'N' 'O' 'N' 'O' 'N' 'N' 'N' 'O' 'N' 'N' 'O' 'O' 'N' 'N'\n",
      " 'N' 'O' 'N' 'A' 'O' 'N' 'N' 'O' 'O' 'N' '~' 'N' 'N' 'N' 'N' 'O' '~' 'N'\n",
      " 'A' 'N' 'N' 'N' 'A' 'N' 'N' 'O' 'N' 'O' 'N' 'N' 'N' 'O' 'O' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N' 'N' 'N' 'O' 'O' 'N' 'A' 'N' 'N' 'N' 'O' 'O' 'O' 'N' 'O' 'N'\n",
      " 'N' 'A' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'A' '~' 'N' 'O' 'O' 'O' 'N'\n",
      " '~' 'N' 'O' 'N' 'N' 'N' 'O' 'N' 'O' 'N' 'N' 'N' 'O' 'O' 'N' 'N' 'O' 'N'\n",
      " 'O' 'O' 'N' 'N' 'O' 'O' 'N' 'N' 'O' 'A' 'N' 'N' 'O' 'N' 'N' 'N' 'A' 'N'\n",
      " 'A' 'N' 'O' 'N' 'A' 'N' 'N' 'N' 'N' 'A' 'N' 'A' 'N' 'O' 'N' 'N' 'O' 'O'\n",
      " 'N' 'O' 'N' 'N' 'N' 'O' 'N' 'O' 'N' 'A' '~' 'N' 'N' 'A' '~' 'N' 'N' 'N'\n",
      " 'O' 'O' 'O' 'O' 'O' 'N' 'N' 'N' 'O' 'N' 'N' 'N' '~' 'N' 'A' 'N' 'N' 'N'\n",
      " 'O' 'A' 'N' 'N' 'A' 'N' 'O' 'O' 'N' 'O' 'N' 'N' 'O' 'O' 'O' 'N' 'N' 'N'\n",
      " 'N' 'O' 'O' 'N' 'N' 'O' 'O' 'N' 'N' 'O' 'O' 'N' 'A' 'O' 'O' 'O' 'A' 'O'\n",
      " 'N' 'A' 'N' 'O' 'N' 'O' 'N' 'A' 'O' 'N' 'O' '~' 'N' 'O' 'O' '~' 'N' 'N'\n",
      " 'N' 'N' 'N' 'N' 'N' 'O' 'O' 'N' 'N' 'O' 'N' 'N' 'A' 'N' 'O' 'N' 'N' 'O'\n",
      " 'N' 'N' 'N' 'N' 'A' 'N' 'N' 'A' 'N' 'N' 'A' 'N' 'O' 'A' 'O' 'N' 'N' 'N'\n",
      " 'O' 'N' 'O' 'N' 'N' 'N' 'N' 'O' 'N' 'N' 'O' 'A' 'N' 'N' 'N' 'N' 'A' 'N'\n",
      " 'N' 'N' 'O' 'O' 'N' 'O' '~' 'O' 'N' 'O' '~' 'N' 'N' 'O' 'O' 'N' 'N' 'N'\n",
      " 'O' 'O' 'O' 'N' 'A' 'A' 'N' 'N' 'O' 'N' 'N' 'N' 'N' 'A' 'O' 'N' 'O' '~'\n",
      " 'O' 'O' 'O' '~' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'A' 'A' 'A' 'N' 'O' '~'\n",
      " 'O' 'A' 'A' 'O' 'N' 'N' 'N' 'N' 'N' 'N' 'O' 'N' 'N' 'N' 'O' 'N' 'N' '~'\n",
      " 'O' 'N' 'N' 'N' 'N' 'O' 'N' 'N' 'N' 'O' 'O' 'N' 'N' 'N' 'N' 'N' 'N' '~'\n",
      " 'O' 'O' 'N' 'N' 'N' 'N' 'O' 'N' 'N' 'O' '~' 'N' 'O' 'N' 'O' 'O' 'N' 'N'\n",
      " '~' 'O' 'N' 'O' 'O' 'N' 'N' 'O' 'O' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'O' 'N' 'N' 'A' 'O' 'N' 'O' 'N' 'O' 'A' 'N' 'N' 'N' 'A' 'A' 'O' 'N'\n",
      " 'N' 'N' '~' '~' 'N' 'N' 'N' 'N' 'N' 'O' 'A' 'O' 'N' 'N' 'N' 'O' '~' 'N'\n",
      " 'N' 'N' 'O' 'N' '~' 'O' 'N' 'O' 'N' '~' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'O' 'O' 'O' 'N' 'A' '~' 'O' 'O' 'O' 'A' 'O' 'O' 'O' 'N' 'N' 'N' 'O'\n",
      " 'O' 'N' 'N' '~' 'N' 'O' 'N' 'N' 'O' 'N' 'O' 'N' 'O' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N' 'O' 'N' 'O' 'N' 'N' 'N' 'N' 'O' 'N' 'O' 'N' 'N' '~' 'N' 'N'\n",
      " 'O' 'N' 'N' 'A' 'N' 'A' '~' 'O' 'N' 'N' 'N' 'N' 'O' 'O' 'N' 'N' 'N' 'O'\n",
      " 'N' '~' 'N' 'N' 'N' 'N' 'O' 'N' 'O' 'N' 'N' 'N' 'N' 'A' 'N' 'O' 'N' 'A'\n",
      " 'O' 'O' 'O' 'N' 'N' 'N' 'N' 'A' 'N' 'N' 'N' 'N' 'O' 'A' 'O' 'N' 'O' 'O'\n",
      " 'A' 'N' '~' 'N' 'N' 'O' 'N' 'N' 'N' 'N' 'O' 'N' 'N' 'N' '~' 'N' 'O' 'O'\n",
      " 'N' 'N' 'N' 'O' 'N' 'A' 'N' 'O' 'N' 'N' 'O' 'N' 'N' 'N' 'N' 'O' 'O' '~'\n",
      " 'N' 'N' 'N' '~' 'O' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'O' 'O' 'N' 'N' 'O' 'A'\n",
      " 'A' 'N' 'N' 'N' 'O' 'N' 'O' 'O' 'N' '~' 'O' 'O' 'N' 'O' 'N' 'N' 'N' 'N'\n",
      " 'N' 'O' 'A' 'A' 'O' '~' 'N' 'N' 'N' 'N' 'A' 'N' 'N' 'N' 'N' 'N' 'O' 'O'\n",
      " 'O' 'O' 'A' 'O' 'N' 'O' 'N' 'N' 'A' 'O' 'O' 'N' 'N' 'N' 'N' 'N' 'O' 'N'\n",
      " 'O' 'N' 'A' '~' 'A' 'A' 'N' '~' 'N' 'O' 'O' 'N' 'N' 'N' 'A' 'O' 'N' 'N'\n",
      " 'N' 'N' 'N' 'N' 'N' 'O' 'O' 'A' 'O' 'O']\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N' 'N' 'N' 'O' 'O' 'N' 'O' 'N' 'N' 'N' 'N' 'N' 'N' 'O' 'N' '~' 'N' 'N'\n",
      " 'O' 'O' 'N' 'O' 'N' 'O' 'A' 'O' '~' 'N' 'N' 'O' 'N' 'O' 'N' 'N' 'O' 'O'\n",
      " 'N' 'N' 'N' 'N' 'N' 'N' 'O' 'N' 'O' 'A' 'N' 'N' 'N' 'A' 'N' 'O' 'N' 'N'\n",
      " 'A' 'N' 'N' 'N' 'N' 'O' 'N' 'O' 'N' 'O' 'A' 'O' 'O' 'N' 'N' 'N' 'N' 'O'\n",
      " 'N' 'N' 'N' 'N' 'N' '~' 'O' 'A' 'N' 'N' 'O' 'A' 'O' 'N' 'N' 'O' 'N' 'A'\n",
      " 'N' 'O' 'A' 'N' 'N' 'N' 'O' 'N' 'O' 'O' 'N' 'N' 'N' 'N' 'O' 'N' '~' 'A'\n",
      " 'N' 'N' 'N' 'N' '~' 'N' 'N' 'N' 'O' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'A' 'N'\n",
      " 'N' 'N' 'N' 'O' 'O' 'N' 'N' 'N' 'N' 'N' 'N' 'O' 'N' 'O' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N' 'N' 'N' 'O' 'N' 'N' 'N' 'N' 'O' 'N' 'O' 'N' 'A' 'N' 'N' 'A'\n",
      " 'N' 'O' 'A' 'O' 'N' 'N' 'O' 'N' 'A' 'N' 'N' 'N' 'O' 'N' 'O' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N' 'O' 'O' 'A' 'O' 'A' 'O' 'O' 'A' 'O' 'O' 'N' 'O' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N' 'N' 'N' 'O' 'N' 'N' 'N' 'N' 'O' 'N' 'N' 'N' 'O' 'N' 'A' 'O'\n",
      " 'N' 'N' 'N' 'N' 'O' 'N' 'N' 'N' 'O' 'N' 'N' 'N' 'O' 'O' 'O' 'N' 'A' 'N'\n",
      " 'O' 'A' 'N' 'O' 'O' 'A' 'N' 'A' 'N' 'N' 'N' 'N' 'N' 'O' 'A' 'N' 'A' 'N'\n",
      " 'N' 'N' 'N' 'O' 'A' 'N' 'N' 'N' 'O' 'N' 'N' 'N' 'N' 'O' 'N' 'O' 'N' 'N'\n",
      " 'N' 'N' 'A' 'N' 'A' 'A' 'N' 'O' 'A' 'N' 'O' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'O' 'N' 'N' 'N' 'A' 'N' 'O' 'N' 'N' 'N' 'O' 'N' 'N' '~' 'O' 'O' 'N'\n",
      " 'N' 'N' 'N' 'A' 'O' 'N' 'N' 'O' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'O' 'O' 'N'\n",
      " 'O' 'N' 'N' 'N' '~' 'N' 'N' 'O' 'N' '~' 'N' 'N' 'N' 'O' 'O' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N' 'N' 'N' 'N' 'O' 'N' 'A' 'N' 'N' 'N' 'N' 'O' 'O' 'N' 'O' 'N'\n",
      " 'N' 'A' 'O' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'A' 'O' 'N' 'O' 'O' 'O' 'N'\n",
      " '~' 'N' 'O' 'N' 'N' 'N' 'O' 'N' 'O' 'N' 'N' 'N' 'O' 'O' 'N' 'N' 'O' 'N'\n",
      " 'O' 'A' 'N' 'N' 'O' 'O' 'N' 'N' 'O' 'A' 'N' 'N' 'O' 'N' 'N' 'N' 'A' 'N'\n",
      " 'O' 'N' 'N' 'N' 'A' 'N' 'N' 'N' 'N' 'A' 'N' 'A' 'N' 'O' 'N' 'N' 'O' 'O'\n",
      " 'N' 'A' 'N' 'N' 'N' 'O' 'N' 'O' 'N' '~' '~' 'N' 'N' 'A' 'N' 'N' 'N' 'N'\n",
      " 'O' 'O' 'O' '~' 'O' 'N' 'N' 'O' 'O' 'N' 'N' 'N' '~' 'N' 'O' 'N' 'N' 'N'\n",
      " 'O' 'A' 'N' 'N' 'A' 'N' 'O' 'O' 'N' 'A' 'N' 'N' 'O' 'O' 'O' 'N' 'N' 'N'\n",
      " 'N' 'O' 'A' 'N' 'N' 'A' '~' 'N' 'N' 'O' 'O' 'N' 'A' 'O' 'O' 'O' 'A' 'O'\n",
      " 'N' '~' 'N' 'O' 'N' 'O' 'N' 'A' 'O' 'N' 'O' 'O' 'N' 'O' 'N' '~' 'N' 'N'\n",
      " 'N' 'N' 'N' 'N' 'N' 'O' 'O' 'N' 'N' 'O' 'N' 'N' 'O' 'N' 'O' 'N' 'N' 'O'\n",
      " 'N' 'N' 'N' 'N' 'A' 'N' 'N' 'A' 'N' 'N' 'O' 'N' 'O' 'A' 'N' 'N' 'N' 'N'\n",
      " 'O' 'O' 'N' 'N' 'N' 'N' 'N' 'O' 'N' 'N' 'O' 'A' 'N' 'N' 'N' 'N' 'A' 'N'\n",
      " 'N' 'N' 'O' 'O' 'N' 'O' '~' 'O' 'N' 'A' '~' 'N' 'N' 'O' 'O' 'N' 'N' 'N'\n",
      " 'O' 'O' 'A' 'N' 'A' 'A' 'N' 'N' 'O' 'N' 'N' 'N' 'N' 'A' 'O' 'N' 'O' 'O'\n",
      " 'O' 'O' 'O' 'A' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'A' 'A' 'O' 'N' 'O' 'N'\n",
      " 'O' 'O' 'A' 'O' 'N' 'N' 'N' 'N' 'N' 'N' 'O' 'N' 'N' 'N' 'O' 'N' 'N' 'N'\n",
      " 'O' 'N' 'N' 'N' 'N' '~' 'N' 'N' 'N' 'O' 'A' 'N' 'N' 'N' 'N' 'N' 'N' '~'\n",
      " 'O' 'O' 'N' 'N' 'N' 'N' 'O' 'N' 'N' 'O' '~' 'N' 'O' 'N' 'A' 'O' 'N' 'N'\n",
      " 'N' 'O' 'N' 'O' 'O' 'N' 'N' 'O' 'O' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'O' 'N' 'N' 'O' 'O' 'N' 'O' 'N' 'O' 'A' 'N' 'N' 'N' 'O' 'A' 'O' 'N'\n",
      " 'N' 'N' 'O' 'N' 'N' 'N' 'N' 'N' 'N' 'O' 'A' 'O' 'N' 'N' 'N' 'O' 'O' 'N'\n",
      " 'N' 'N' 'O' 'N' 'N' 'O' 'N' 'O' 'N' 'O' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'O' 'O' 'O' 'N' 'A' 'N' 'O' 'O' 'O' 'A' 'O' 'O' 'O' 'N' 'N' 'N' 'O'\n",
      " 'O' 'N' 'N' 'N' 'N' 'O' 'N' 'N' 'O' 'N' 'O' 'N' 'O' 'N' 'N' 'N' 'N' 'N'\n",
      " 'N' 'N' 'N' 'O' 'N' 'O' 'N' 'N' 'N' 'N' 'O' 'N' 'O' 'N' 'N' '~' 'N' 'N'\n",
      " 'O' 'N' 'N' 'O' 'N' 'A' 'O' 'O' 'N' 'N' 'N' 'N' 'O' 'O' 'N' 'N' 'N' 'O'\n",
      " 'N' '~' 'N' 'N' 'N' 'N' 'A' 'N' 'O' 'N' 'N' 'N' 'N' 'O' 'N' 'O' 'N' 'A'\n",
      " 'A' 'O' '~' 'N' 'N' 'N' 'N' 'O' 'N' 'N' 'N' 'O' '~' 'O' 'O' 'N' 'O' 'O'\n",
      " 'O' 'N' 'O' 'N' 'N' 'O' 'N' 'N' 'N' 'N' 'O' 'N' 'N' 'N' 'O' 'N' 'O' 'O'\n",
      " 'N' 'N' 'N' 'O' 'N' 'A' 'N' 'N' 'N' 'N' 'A' 'N' 'N' 'N' 'N' 'O' 'O' 'A'\n",
      " 'N' 'O' 'N' '~' 'O' 'N' 'N' 'O' 'N' 'N' 'N' 'N' 'O' 'O' 'N' 'N' '~' 'A'\n",
      " 'O' 'N' 'N' 'N' 'O' 'N' 'O' 'O' 'N' '~' 'O' 'O' 'N' 'O' 'N' 'N' 'N' 'N'\n",
      " 'N' 'O' 'A' 'A' 'O' '~' 'N' 'N' 'N' 'N' 'A' 'N' 'N' 'N' 'N' 'N' 'O' '~'\n",
      " 'O' 'O' 'A' 'O' 'N' 'O' 'N' 'N' 'A' 'O' 'O' 'N' 'N' 'N' 'N' 'N' 'A' 'N'\n",
      " 'O' 'N' '~' '~' 'A' 'O' 'N' '~' 'N' 'O' 'O' 'N' 'N' 'N' 'A' 'O' 'N' 'N'\n",
      " 'N' 'N' 'N' 'N' 'N' 'O' 'O' 'A' 'O' 'O']\n"
     ]
    }
   ],
   "source": [
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.76040671957\n"
     ]
    }
   ],
   "source": [
    "#get f1 score\n",
    "theMax = 0\n",
    "for i in range(0,1):    \n",
    "    if(accuracy_score(test_labels, predict_list[i]) > theMax):\n",
    "        theMax = np.average(f1_score(test_labels, predictions, average=None))\n",
    "print(theMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 68   0  19   2]\n",
      " [  0 581  13   9]\n",
      " [ 23   8 232  12]\n",
      " [  5   0  10  18]]\n"
     ]
    }
   ],
   "source": [
    "#print the cnfusion matrix\n",
    "results = confusion_matrix(test_labels, predictions,labels=[\"A\", \"N\", \"O\",\"~\"])\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print('Parameters currently in use:\\n')\n",
    "#print(rf.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjAAAAGjCAYAAAAy6y8fAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTVjAjDnxNQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f46a72f4ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#code to get the confusion matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "sn.set(font_scale=1.5)\n",
    "array = [[ 70,   3,  14,   2],\n",
    " [ 10, 502,  70,   21],\n",
    " [ 27,  87, 146,   15],\n",
    " [  2,   3,   6,   22]]\n",
    "df_cm = pd.DataFrame(array, index = [\"A\",\"N\",\"O\",\"~\"],\n",
    "                  columns = [\"A\",\"N\",\"O\",\"~\"])\n",
    "\n",
    "#df_cm = df_cm.round(4)\n",
    "plt.figure(figsize = (10,7))\n",
    "plt.xlabel(\"Perdicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "sn.heatmap(df_cm, annot=True,fmt='g')\n",
    "plt.savefig(\"FIN_TDA_RR.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7076828762553866\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "var1 = 36/(29+28)\n",
    "var2 = 48/(31+39)\n",
    "var3 = 112/(73+66)\n",
    "\n",
    "print((var1+var2+var3)/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
