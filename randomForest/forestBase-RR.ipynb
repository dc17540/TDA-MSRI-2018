{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "theCsv[\"avg_bottle_dist_dim0\"] =theCsv5[\"avg_bottle_dist_dim0\"]\n",
    "theCsv[\"sd_bottle_dist_dim0\"] =theCsv5[\"sd_bottle_dist_dim0\"]\n",
    "\n",
    "\n",
    "#theCsv[\"avg_bottle_dist_dim0\"] =theCsv6[\"avg_bottle_dist_dim0\"]\n",
    "#theCsv[\"sd_bottle_dist_dim0\"] =theCsv6[\"sd_bottle_dist_dim0\"]\n",
    "\n",
    "theCsv[\"avg_bottle_dist_dim0\"] =theCsv7[\"avg_bottle_dist_dim0\"]\n",
    "theCsv[\"sd_bottle_dist_dim0\"] =theCsv7[\"sd_bottle_dist_dim0\"]\n",
    "118\n",
    "\n",
    "['N', 'R', 'R', 'N', 'N', 'AF', 'N', 'R', 'N', 'AF', 'N', 'N', 'N', 'R', 'AF', 'AF', 'N', 'AF', 'N', 'N', 'N', 'R', 'R', 'R', 'AF', 'R', 'N', 'N', 'R', 'R', 'R', 'N', 'N', 'AF', 'N', 'R', 'N', 'R', 'R', 'AF', 'AF', 'N', 'R', 'R', 'N', 'N', 'R', 'N', 'N', 'R', 'AF', 'AF', 'N', 'R', 'R', 'AF', 'AF', 'N', 'N', 'N', 'N', 'N', 'AF', 'R', 'R', 'N', 'R', 'R', 'N', 'AF', 'AF', 'N', 'R', 'AF', 'R', 'R', 'AF', 'AF', 'R', 'R', 'AF', 'R', 'R', 'AF', 'N', 'N', 'N', 'AF', 'AF', 'AF', 'AF', 'R', 'N', 'AF', 'AF', 'AF', 'AF', 'N', 'R', 'N', 'N', 'AF', 'R', 'AF', 'N', 'R', 'N', 'AF', 'AF', 'R', 'N', 'R', 'R', 'R', 'AF', 'AF', 'AF', 'N', 'R', 'R', 'N', 'N', 'AF', 'R', 'N', 'N', 'R', 'AF', 'R', 'R', 'N', 'R', 'N', 'N', 'R', 'N', 'N', 'N', 'AF', 'N', 'N', 'AF', 'N', 'N', 'R', 'N', 'AF', 'R', 'N', 'N', 'R', 'R', 'AF', 'AF', 'R', 'AF', 'N', 'R', 'N', 'N', 'AF', 'AF', 'N', 'R', 'AF', 'N', 'AF', 'AF', 'R', 'AF', 'AF', 'AF', 'R', 'R', 'N', 'N', 'R', 'N', 'N', 'AF', 'N', 'AF', 'R', 'R', 'R', 'AF', 'AF', 'R', 'AF', 'AF', 'R', 'R', 'N', 'AF', 'R', 'AF', 'R', 'AF']\n",
    "\n",
    "['N', 'R', 'R', 'N', 'N', 'AF', 'N', 'R', 'N', 'AF', 'N', 'N', 'N', 'R', 'AF', 'AF', 'N', 'AF', 'N', 'N', 'N', 'R', 'R', 'R', 'AF', 'R', 'N', 'N', 'R', 'R', 'R', 'N', 'N', 'AF', 'N', 'R', 'N', 'R', 'R', 'AF', 'AF', 'N', 'R', 'R', 'N', 'N', 'R', 'N', 'N', 'R', 'AF', 'AF', 'N', 'R', 'R', 'AF', 'AF', 'N', 'N', 'N', 'N', 'N', 'AF', 'R', 'R', 'N', 'R', 'R', 'N', 'AF', 'AF', 'N', 'R', 'AF', 'R', 'R', 'AF', 'AF', 'R', 'R', 'AF', 'R', 'R', 'AF', 'N', 'N', 'N', 'AF', 'AF', 'AF', 'AF', 'R', 'N', 'AF', 'AF', 'AF', 'AF', 'N', 'R', 'N', 'N', 'AF', 'R', 'AF', 'N', 'R', 'N', 'AF', 'AF', 'R', 'N', 'R', 'R', 'R', 'AF', 'AF', 'AF', 'N', 'R', 'R', 'N', 'N', 'AF', 'R', 'N', 'N', 'R', 'AF', 'R', 'R', 'N', 'R', 'N', 'N', 'R', 'N', 'N', 'N', 'AF', 'N', 'N', 'AF', 'N', 'N', 'R', 'N', 'AF', 'R', 'N', 'N', 'R', 'R', 'AF', 'AF', 'R', 'AF', 'N', 'R', 'N', 'N', 'AF', 'AF', 'N', 'R', 'AF', 'N', 'AF', 'AF', 'R', 'AF', 'AF', 'AF', 'R', 'R', 'N', 'N', 'R', 'N', 'N', 'AF', 'N', 'AF', 'R', 'R', 'R', 'AF', 'AF', 'R', 'AF', 'AF', 'R', 'R', 'N', 'AF', 'R', 'AF', 'R', 'AF']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theTotal = []\n",
    "classDict = {}\n",
    "lineCount = 0\n",
    "\n",
    "x = open(\"200_set_of_Norm_AF_Rand.csv\")\n",
    "for line in x:\n",
    "    line = line.strip()\n",
    "    #print(line)\n",
    "    a,b,c,d = line.split(\",\")\n",
    "    if(lineCount != 0):\n",
    "            #normalListTrain.append(b)\n",
    "            theTotal.append(b)\n",
    "            classDict[b] = [\"N\"]\n",
    "            #normalListTest.append(b)\n",
    "            #AFListTrain.append(c)\n",
    "            theTotal.append(c)\n",
    "            classDict[c] = [\"AF\"]\n",
    "            #AFListTest.append(c)\n",
    "            #randomListTest.append(d)\n",
    "            theTotal.append(d)\n",
    "            classDict[\"d\"] = [\"R\"]\n",
    "    lineCount += 1\n",
    "\n",
    "            \n",
    "theFrame = {\"mean\":[],\"std_dev\":[],\"theClass\":[]}\n",
    "\n",
    "theCsv = pd.read_csv(\"Reduced_Pers_Mean_sd_dimension_0.csv\", index_col=0)\n",
    "theCsv2 = pd.read_csv(\"Reduced_Pers_Mean_sd_dimension_1.csv\",index_col=0)\n",
    "theCsv3 = pd.read_csv(\"Reduced_Pers_Mean_sd_dimension_2.csv\",index_col=0)\n",
    "theCsv4 = pd.read_csv(\"Reduced_Pers_Lifetimes_dim_0_1_2.csv\",index_col=0)\n",
    "theCsv5 = pd.read_csv(\"reduced_bottleneck_ave_sd_dim0.csv\",index_col=0)\n",
    "theCsv6 = pd.read_csv(\"reduced_bottleneck_ave_sd_dist_dim1.csv\",index_col=0)\n",
    "theCsv7 = pd.read_csv(\"reduced_bottleneck_ave_sd_dist_dim2.csv\",index_col=0)\n",
    "theCsv8 = pd.read_csv(\"number_of_births_deaths_dim0.csv\",index_col=0)\n",
    "theCsv9 = pd.read_csv(\"number_of_births_deaths_dim1.csv\",index_col=0)\n",
    "theCsv10 = pd.read_csv(\"number_of_births_deaths_dim2.csv\",index_col=0)\n",
    "theCsv11 = pd.read_csv(\"skewness_birth_dim12.csv\",index_col=0)\n",
    "theCsv12 = pd.read_csv(\"skewness_death_dim012.csv\",index_col=0)\n",
    "theCsv13 = pd.read_csv(\"a.csv\",index_col=0)\n",
    "theCsv14 = pd.read_csv(\"Total_matrix_RR_interval.csv\",index_col=0)\n",
    "theCsv15 = pd.read_csv(\"rr_normal.csv\",index_col=0)\n",
    "theCsv16 = pd.read_csv(\"rr_R.csv\",index_col=0)\n",
    "#theCsv8 = pd.read_csv(\"reduced_bottleneck_ave_sd_dist_dim2.csv\",index_col=0)\n",
    "#bigData = theCsv.append(theCsv2, ignore_index=True)\n",
    "\n",
    "#print(bigData)\n",
    "\n",
    "aList = []\n",
    "aList2 = []\n",
    "aList3 = []\n",
    "for i in range(0,200):\n",
    "    aList.append(\"N\")\n",
    "    aList2.append(0)\n",
    "    aList3.append(0)\n",
    "\n",
    "for i in range(0,200):\n",
    "    aList.append(\"AF\")\n",
    "    aList2.append(1)\n",
    "    aList3.append(0)\n",
    "    \n",
    "for i in range(0,200):\n",
    "    aList.append(\"R\")\n",
    "    aList2.append(0)\n",
    "    aList3.append(1)\n",
    "\n",
    "#theCsv[\"Normal\"] = np.asarray(aList)\n",
    "#theCsv[\"AF\"] = np.asarray(aList2)\n",
    "#theCsv[\"Random\"] = np.asarray(aList3)\n",
    "#### make dataframe \n",
    "###\n",
    "#bigData  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#theCsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Means_dim0_birth  Means_dim0_death  sd_dim0_birth  sd_dim0_death  \\\n",
      "1                   0          0.598550              0       0.325249   \n",
      "2                   0          0.769444              0       0.422174   \n",
      "3                   0          0.422764              0       0.169927   \n",
      "4                   0          0.329685              0       0.157529   \n",
      "5                   0          0.444172              0       0.199625   \n",
      "6                   0          0.415409              0       0.142401   \n",
      "7                   0          0.487156              0       0.117997   \n",
      "8                   0          0.223625              0       0.081608   \n",
      "9                   0          0.835012              0       0.314351   \n",
      "10                  0          0.876449              0       0.442794   \n",
      "11                  0          0.245021              0       0.081972   \n",
      "12                  0          0.537592              0       0.380163   \n",
      "13                  0          0.313160              0       0.133355   \n",
      "14                  0          0.913464              0       0.279195   \n",
      "15                  0          0.300976              0       0.127002   \n",
      "16                  0          0.893381              0       0.373875   \n",
      "17                  0          0.633013              0       0.135913   \n",
      "18                  0          1.140010              0       0.360468   \n",
      "19                  0          0.787729              0       0.338633   \n",
      "20                  0          0.710843              0       0.174307   \n",
      "21                  0          1.152414              0       0.767847   \n",
      "22                  0          0.639620              0       0.481503   \n",
      "23                  0          0.711189              0       0.197527   \n",
      "24                  0          0.396955              0       0.198593   \n",
      "25                  0          1.217304              0       0.643141   \n",
      "26                  0          0.574782              0       0.336467   \n",
      "27                  0          0.848572              0       0.237090   \n",
      "28                  0          1.063943              0       0.484311   \n",
      "29                  0          0.860867              0       0.271795   \n",
      "30                  0          0.357090              0       0.148263   \n",
      "..                ...               ...            ...            ...   \n",
      "571                 0          2.032057              0       0.695359   \n",
      "572                 0          1.086241              0       0.373980   \n",
      "573                 0          1.306506              0       0.480511   \n",
      "574                 0          1.335675              0       1.025286   \n",
      "575                 0          0.944797              0       0.484791   \n",
      "576                 0          2.042231              0       0.672383   \n",
      "577                 0          0.966941              0       0.347803   \n",
      "578                 0          0.263831              0       0.068312   \n",
      "579                 0          0.828338              0       0.184340   \n",
      "580                 0          2.109686              0       0.408663   \n",
      "581                 0          1.762157              0       0.764576   \n",
      "582                 0          1.514601              0       0.454889   \n",
      "583                 0          0.567754              0       0.340497   \n",
      "584                 0          2.285339              0       1.446577   \n",
      "585                 0          3.001147              0       2.829302   \n",
      "586                 0          1.039154              0       1.013890   \n",
      "587                 0          1.196421              0       0.469518   \n",
      "588                 0          0.273497              0       0.140318   \n",
      "589                 0          1.186527              0       0.366699   \n",
      "590                 0          2.121315              0       1.209431   \n",
      "591                 0          1.643915              0       0.470013   \n",
      "592                 0          0.367983              0       0.070054   \n",
      "593                 0          3.411767              0       0.469826   \n",
      "594                 0          0.710974              0       0.092038   \n",
      "595                 0          2.087713              0       2.201413   \n",
      "596                 0          0.578447              0       0.168414   \n",
      "597                 0          3.331093              0       2.420588   \n",
      "598                 0          2.555481              0       2.760034   \n",
      "599                 0          0.951689              0       0.220347   \n",
      "600                 0          0.204416              0       0.328289   \n",
      "\n",
      "      RR_AF_mean     RR_AF_SD   RR_AF_Skew  \n",
      "1     248.428571    87.045238    -1.059212  \n",
      "2     217.777778    27.424419    -3.700081  \n",
      "3     310.642857    19.669073    -1.909149  \n",
      "4     287.300000    15.539520    -0.404926  \n",
      "5     276.015625     7.003330    -0.200431  \n",
      "6     254.285714     4.651092    -0.786530  \n",
      "7     267.593750    10.708815    -2.474211  \n",
      "8     324.812500    25.671528    -0.114771  \n",
      "9     214.585366    26.475922    -4.415577  \n",
      "10    335.720000    10.113437    -0.626692  \n",
      "11    238.404255    27.970090    -2.471607  \n",
      "12    281.967742     5.778067    -0.195120  \n",
      "13    295.655172     4.907952    -0.220557  \n",
      "14    309.750000     2.640684    -0.217468  \n",
      "15    281.984127     2.319634     0.248172  \n",
      "16    212.341463     9.979515     0.863284  \n",
      "17    226.394737    94.458440    -0.488919  \n",
      "18    288.633333     8.072519    -0.185220  \n",
      "19    214.700000     5.282992    -0.131599  \n",
      "20    250.382353    34.606200    -4.549948  \n",
      "21    194.955556    22.668094    -3.282786  \n",
      "22    270.281250    43.351928    -2.511749  \n",
      "23    255.088235    15.403146    -0.392701  \n",
      "24    204.953488     3.627758     0.201156  \n",
      "25    251.352941     4.043021     0.557217  \n",
      "26    293.666667     5.101198     0.564437  \n",
      "27    191.911111     6.083940    -1.397103  \n",
      "28    270.750000     7.115125     0.256236  \n",
      "29    286.333333     4.444722    -0.419771  \n",
      "30    271.812500    64.676328    -2.024639  \n",
      "..           ...          ...          ...  \n",
      "571   250.000000    89.043809    -0.998295  \n",
      "572   251.476190    54.417801    -1.542407  \n",
      "573  1101.285714  2206.370433     2.022969  \n",
      "574   328.269231   310.521219     3.695758  \n",
      "575   155.958333    51.758638    -0.582628  \n",
      "576   235.307692    81.208549    -0.299875  \n",
      "577  1000.000000  1000.000000  1000.000000  \n",
      "578   149.590909    52.032035     0.336696  \n",
      "579    92.072917    40.357064     3.213349  \n",
      "580   226.230769    64.762470    -1.368011  \n",
      "581   147.266667    53.852535     0.412288  \n",
      "582   514.423077   728.308112     2.671770  \n",
      "583   168.211538    64.311243     0.591931  \n",
      "584   456.894737   726.783606     2.761163  \n",
      "585   242.805556    70.889123    -0.748490  \n",
      "586   183.928571    76.203172    -0.317474  \n",
      "587  1000.000000  1000.000000  1000.000000  \n",
      "588   144.704918    73.888783     2.716140  \n",
      "589   217.571429    69.527707    -1.082779  \n",
      "590   219.769231    87.588332    -0.654745  \n",
      "591   239.305556    67.170521     1.014701  \n",
      "592   116.828947    41.672403     0.832576  \n",
      "593   161.018519    66.865396     0.321953  \n",
      "594   248.857143    64.525584    -1.257656  \n",
      "595   149.422222    70.659587     0.372554  \n",
      "596   339.636364   351.960468     2.012468  \n",
      "597   184.829787    44.227804     2.201267  \n",
      "598   172.560000    48.278426    -0.754102  \n",
      "599  1000.000000  1000.000000  1000.000000  \n",
      "600          NaN          NaN          NaN  \n",
      "\n",
      "[600 rows x 7 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dr-dunstan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/dr-dunstan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/dr-dunstan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#theCsv2.loc[599] =[0,0,0,0]\n",
    "#theCsv2.loc[600] =[0,0,0,0]\n",
    "#theCsv2\n",
    "#bigdata = pd.concat([theCsv, theCsv2])\n",
    "\n",
    "#theCsv[\"Means_dim1_birth\"] = theCsv2[\"Means_dim1_birth\"]\n",
    "#theCsv[\"Means_dim1_death\"] = theCsv2[\"Means_dim1_birth\"]\n",
    "#theCsv[\"sd_dim1_birth\"] = theCsv2[\"sd_dim1_birth\"]\n",
    "#theCsv[\"sd_dim1_death\"] =theCsv2[\"sd_dim1_death\"]\n",
    "\n",
    "#theCsv[\"Means_dim2_birth\"] = theCsv3[\"Means_dim2_birth\"]\n",
    "#theCsv[\"Means_dim2_death\"] = theCsv3[\"Means_dim2_birth\"]\n",
    "#theCsv[\"sd_dim2_birth\"] = theCsv3[\"sd_dim2_birth\"]\n",
    "#theCsv[\"sd_dim2_death\"] =theCsv3[\"sd_dim2_death\"]\n",
    "\n",
    "#theCsv[\"Means_dim0_birth\"] = theCsv4[\"Means_dim0_birth\"]\n",
    "#theCsv[\"Means_dim0_death\"] = theCsv4[\"Means_dim0_birth\"]\n",
    "#theCsv[\"sd_dim0_birth\"] = theCsv4[\"sd_dim0_birth\"]\n",
    "#theCsv[\"sd_dim0_death\"] =theCsv4[\"sd_dim0_death\"]\n",
    "\n",
    "#theCsv[\"Lifetime_dim0\"] = theCsv4[\"Lifetime_dim0\"]\n",
    "#theCsv[\"Lifetime_dim1\"] = theCsv4[\"Lifetime_dim1\"]\n",
    "#theCsv[\"Lifetime_dim2\"] =theCsv4[\"Lifetime_dim2\"]\n",
    "\n",
    "\n",
    "#theCsv[\"avg_bottle_dist_dim0\"] =theCsv5[\"V1\"]\n",
    "#theCsv[\"sd_bottle_dist_dim0\"] =theCsv5[\"V2\"]\n",
    "\n",
    "\n",
    "#theCsv[\"avg_bottle_dist_dim1\"] =theCsv6[\"V1\"]\n",
    "#theCsv[\"sd_bottle_dist_dim1\"] =theCsv6[\"V2\"]\n",
    "\n",
    "#theCsv[\"avg_bottle_dist_dim2\"] =theCsv7[\"V1\"]\n",
    "#theCsv[\"sd_bottle_dist_dim2\"] =theCsv7[\"V2\"]\n",
    "\n",
    "#theCsv[\"num_dim0\"] = theCsv8[\"x\"]\n",
    "#theCsv[\"num_dim1\"] = theCsv9[\"x\"]\n",
    "#theCsv[\"num_dim2\"] = theCsv10[\"x\"]\n",
    "\n",
    "#theCsv[\"num_dim1\"] = theCsv10[\"x\"]\n",
    "\n",
    "#theCsv[\"skew_death1\"] =theCsv12[\"skew.death.dim1\"]\n",
    "#theCsv[\"skew_death2\"] =theCsv12[\"skew.death.dim2\"]\n",
    "#theCsv[\"skew_death0\"] =theCsv12[\"skew.death.dim0\"]\n",
    "\n",
    "\n",
    "#theCsv[\"skew_birth1\"] = theCsv11[\"skew.birth.dim1\"]\n",
    "#theCsv[\"skew_birth2\"] = theCsv11[\"skew.birth.dim2\"]\n",
    "\n",
    "\n",
    "#theCsv[\"num_per0\"] = theCsv13[\"V1\"]\n",
    "#theCsv[\"num_per1\"] = theCsv13[\"V2\"]\n",
    "#theCsv[\"num_per2\"] = theCsv13[\"V3\"]\n",
    "\n",
    "\n",
    "theCsv[\"RR_AF_mean\"] = theCsv14[\"0\"]\n",
    "theCsv[\"RR_AF_SD\"] = theCsv14[\"1\"]\n",
    "theCsv[\"RR_AF_Skew\"] = theCsv14[\"3\"]\n",
    "#theCsv[\"RR_R_mean\"] = theCsv16[\"0\"]\n",
    "print(theCsv)\n",
    "#theCsv\n",
    "#print(np.isnan(theCsv))\n",
    "\n",
    "theCsv[\"RR_AF_mean\"][600] = 1000\n",
    "theCsv[\"RR_AF_SD\"][600] = 1000\n",
    "theCsv[\"RR_AF_Skew\"][600] = 1000\n",
    "\n",
    "theCsv[\"Normal\"] = np.asarray(aList)\n",
    "#theCsv\n",
    "\n",
    "#theCsv.fillna(theCsv.mean())\n",
    "\n",
    "#print(np.where(theCsv.values >= np.finfo(np.float64).max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### code from meduim torwards data scienec example\n",
    "# Labels are the values we want to pred\n",
    "\n",
    "labels = np.array(theCsv[\"Normal\"])\n",
    "\n",
    "# Remove the labels from the features\n",
    "# axis 1 refers to the columns\n",
    "theCsv = theCsv.drop('Normal', axis = 1)\n",
    "#theCsv = theCsv.drop('AF', axis = 1)\n",
    "#theCsv = theCsv.drop('Random', axis = 1)\n",
    "\n",
    "# Saving feature names for later use\n",
    "feature_list = list(theCsv.columns)\n",
    "\n",
    "# Convert to numpy array\n",
    "features = np.array(theCsv)\n",
    "\n",
    "\n",
    "# Using Skicit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(theCsv, labels, test_size = 0.33, random_state = 42)\n",
    "\n",
    "\n",
    "#print(test_labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the model we are using\n",
    "#from sklearn.ensemble import RandomForest\n",
    "predict_list = []\n",
    "# Instantiate model with 1000 decision trees\n",
    "for i in range(0,600):\n",
    "    #rf = RandomForestClassifier(bootstrap=True,max_depth=20,max_features=\"sqrt\",min_samples_leaf=4,min_samples_split=10,n_estimators=50,random_state=118)\n",
    "    rf = RandomForestClassifier(bootstrap=True,max_depth=20,max_features=\"sqrt\",min_samples_leaf=4,min_samples_split=10,n_estimators=50,random_state=i)\n",
    "\n",
    "# Train the model on training data\n",
    "    rf.fit(train_features, train_labels)\n",
    "\n",
    "    predictions = rf.predict(test_features)\n",
    "    predict_list.append(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AF' 'R' 'N' 'N' 'N' 'AF' 'N' 'R' 'N' 'AF' 'N' 'N' 'N' 'R' 'AF' 'AF' 'N'\n",
      " 'AF' 'N' 'N' 'N' 'R' 'R' 'R' 'AF' 'R' 'N' 'N' 'R' 'R' 'AF' 'N' 'N' 'AF'\n",
      " 'R' 'R' 'N' 'R' 'R' 'AF' 'R' 'N' 'R' 'R' 'N' 'N' 'R' 'N' 'N' 'R' 'N' 'AF'\n",
      " 'N' 'R' 'R' 'R' 'AF' 'N' 'N' 'N' 'N' 'N' 'AF' 'R' 'R' 'N' 'R' 'R' 'N' 'AF'\n",
      " 'N' 'N' 'R' 'N' 'R' 'AF' 'AF' 'AF' 'R' 'AF' 'AF' 'N' 'R' 'AF' 'N' 'N' 'N'\n",
      " 'AF' 'AF' 'AF' 'N' 'AF' 'N' 'AF' 'AF' 'AF' 'AF' 'N' 'N' 'N' 'N' 'N' 'R'\n",
      " 'AF' 'N' 'N' 'N' 'AF' 'AF' 'R' 'N' 'R' 'R' 'R' 'AF' 'R' 'R' 'N' 'AF' 'R'\n",
      " 'N' 'N' 'AF' 'R' 'N' 'N' 'R' 'AF' 'R' 'R' 'N' 'R' 'N' 'N' 'R' 'N' 'N' 'N'\n",
      " 'AF' 'AF' 'N' 'AF' 'N' 'N' 'R' 'N' 'AF' 'R' 'N' 'N' 'N' 'R' 'AF' 'AF' 'R'\n",
      " 'AF' 'N' 'R' 'N' 'AF' 'AF' 'R' 'N' 'R' 'AF' 'R' 'AF' 'AF' 'AF' 'AF' 'AF'\n",
      " 'AF' 'R' 'R' 'N' 'N' 'R' 'N' 'N' 'AF' 'N' 'AF' 'R' 'R' 'N' 'N' 'AF' 'R'\n",
      " 'AF' 'N' 'R' 'R' 'N' 'AF' 'R' 'AF' 'R' 'AF']\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N' 'R' 'R' 'N' 'N' 'AF' 'N' 'R' 'N' 'AF' 'N' 'N' 'N' 'R' 'AF' 'AF' 'N'\n",
      " 'AF' 'N' 'N' 'N' 'R' 'R' 'R' 'AF' 'R' 'N' 'N' 'R' 'R' 'R' 'N' 'N' 'AF' 'N'\n",
      " 'R' 'N' 'R' 'R' 'AF' 'AF' 'N' 'R' 'R' 'N' 'N' 'R' 'N' 'N' 'R' 'AF' 'AF'\n",
      " 'N' 'R' 'R' 'AF' 'AF' 'N' 'N' 'N' 'N' 'N' 'AF' 'R' 'R' 'N' 'R' 'R' 'N'\n",
      " 'AF' 'AF' 'N' 'R' 'AF' 'R' 'R' 'AF' 'AF' 'R' 'R' 'AF' 'R' 'R' 'AF' 'N' 'N'\n",
      " 'N' 'AF' 'AF' 'AF' 'AF' 'R' 'N' 'AF' 'AF' 'AF' 'AF' 'N' 'R' 'N' 'N' 'AF'\n",
      " 'R' 'AF' 'N' 'R' 'N' 'AF' 'AF' 'R' 'N' 'R' 'R' 'R' 'AF' 'AF' 'AF' 'N' 'R'\n",
      " 'R' 'N' 'N' 'AF' 'R' 'N' 'N' 'R' 'AF' 'R' 'R' 'N' 'R' 'N' 'N' 'R' 'N' 'N'\n",
      " 'N' 'AF' 'N' 'N' 'AF' 'N' 'N' 'R' 'N' 'AF' 'R' 'N' 'N' 'R' 'R' 'AF' 'AF'\n",
      " 'R' 'AF' 'N' 'R' 'N' 'N' 'AF' 'AF' 'N' 'R' 'AF' 'N' 'AF' 'AF' 'R' 'AF'\n",
      " 'AF' 'AF' 'R' 'R' 'N' 'N' 'R' 'N' 'N' 'AF' 'N' 'AF' 'R' 'R' 'R' 'AF' 'AF'\n",
      " 'R' 'AF' 'AF' 'R' 'R' 'N' 'AF' 'R' 'AF' 'R' 'AF']\n"
     ]
    }
   ],
   "source": [
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.851307704184\n"
     ]
    }
   ],
   "source": [
    "theMax = 0\n",
    "for i in range(0,600):    \n",
    "    if(accuracy_score(test_labels, predict_list[i]) > theMax):\n",
    "        theMax = np.average(f1_score(test_labels, predictions, average=None))\n",
    "print(theMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[49  7  5]\n",
      " [ 3 66  2]\n",
      " [ 6  6 54]]\n"
     ]
    }
   ],
   "source": [
    "results = confusion_matrix(test_labels, predictions,labels=[\"AF\", \"N\", \"R\"])\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print('Parameters currently in use:\\n')\n",
    "#print(rf.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "random_grid ={'bootstrap': [True, False],\n",
    " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    " 'max_features': ['auto', 'sqrt'],\n",
    " 'min_samples_leaf': [1, 2, 4],\n",
    " 'min_samples_split': [2, 5, 10],\n",
    " 'n_estimators': [10,15,20,25,30,50,100,200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "#rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 500, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "#rf_random.fit(train_features, train_labels)\n",
    "\n",
    "#rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7076828762553866\n"
     ]
    }
   ],
   "source": [
    "var1 = 36/(29+28)\n",
    "var2 = 48/(31+39)\n",
    "var3 = 112/(73+66)\n",
    "\n",
    "print((var1+var2+var3)/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
