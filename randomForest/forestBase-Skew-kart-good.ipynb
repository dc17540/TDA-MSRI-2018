{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "theCsv[\"avg_bottle_dist_dim0\"] =theCsv5[\"avg_bottle_dist_dim0\"]\n",
    "theCsv[\"sd_bottle_dist_dim0\"] =theCsv5[\"sd_bottle_dist_dim0\"]\n",
    "\n",
    "\n",
    "#theCsv[\"avg_bottle_dist_dim0\"] =theCsv6[\"avg_bottle_dist_dim0\"]\n",
    "#theCsv[\"sd_bottle_dist_dim0\"] =theCsv6[\"sd_bottle_dist_dim0\"]\n",
    "\n",
    "theCsv[\"avg_bottle_dist_dim0\"] =theCsv7[\"avg_bottle_dist_dim0\"]\n",
    "theCsv[\"sd_bottle_dist_dim0\"] =theCsv7[\"sd_bottle_dist_dim0\"]\n",
    "118\n",
    "\n",
    "['N', 'R', 'R', 'N', 'N', 'AF', 'N', 'R', 'N', 'AF', 'N', 'N', 'N', 'R', 'AF', 'AF', 'N', 'AF', 'N', 'N', 'N', 'R', 'R', 'R', 'AF', 'R', 'N', 'N', 'R', 'R', 'R', 'N', 'N', 'AF', 'N', 'R', 'N', 'R', 'R', 'AF', 'AF', 'N', 'R', 'R', 'N', 'N', 'R', 'N', 'N', 'R', 'AF', 'AF', 'N', 'R', 'R', 'AF', 'AF', 'N', 'N', 'N', 'N', 'N', 'AF', 'R', 'R', 'N', 'R', 'R', 'N', 'AF', 'AF', 'N', 'R', 'AF', 'R', 'R', 'AF', 'AF', 'R', 'R', 'AF', 'R', 'R', 'AF', 'N', 'N', 'N', 'AF', 'AF', 'AF', 'AF', 'R', 'N', 'AF', 'AF', 'AF', 'AF', 'N', 'R', 'N', 'N', 'AF', 'R', 'AF', 'N', 'R', 'N', 'AF', 'AF', 'R', 'N', 'R', 'R', 'R', 'AF', 'AF', 'AF', 'N', 'R', 'R', 'N', 'N', 'AF', 'R', 'N', 'N', 'R', 'AF', 'R', 'R', 'N', 'R', 'N', 'N', 'R', 'N', 'N', 'N', 'AF', 'N', 'N', 'AF', 'N', 'N', 'R', 'N', 'AF', 'R', 'N', 'N', 'R', 'R', 'AF', 'AF', 'R', 'AF', 'N', 'R', 'N', 'N', 'AF', 'AF', 'N', 'R', 'AF', 'N', 'AF', 'AF', 'R', 'AF', 'AF', 'AF', 'R', 'R', 'N', 'N', 'R', 'N', 'N', 'AF', 'N', 'AF', 'R', 'R', 'R', 'AF', 'AF', 'R', 'AF', 'AF', 'R', 'R', 'N', 'AF', 'R', 'AF', 'R', 'AF']\n",
    "\n",
    "['N', 'R', 'R', 'N', 'N', 'AF', 'N', 'R', 'N', 'AF', 'N', 'N', 'N', 'R', 'AF', 'AF', 'N', 'AF', 'N', 'N', 'N', 'R', 'R', 'R', 'AF', 'R', 'N', 'N', 'R', 'R', 'R', 'N', 'N', 'AF', 'N', 'R', 'N', 'R', 'R', 'AF', 'AF', 'N', 'R', 'R', 'N', 'N', 'R', 'N', 'N', 'R', 'AF', 'AF', 'N', 'R', 'R', 'AF', 'AF', 'N', 'N', 'N', 'N', 'N', 'AF', 'R', 'R', 'N', 'R', 'R', 'N', 'AF', 'AF', 'N', 'R', 'AF', 'R', 'R', 'AF', 'AF', 'R', 'R', 'AF', 'R', 'R', 'AF', 'N', 'N', 'N', 'AF', 'AF', 'AF', 'AF', 'R', 'N', 'AF', 'AF', 'AF', 'AF', 'N', 'R', 'N', 'N', 'AF', 'R', 'AF', 'N', 'R', 'N', 'AF', 'AF', 'R', 'N', 'R', 'R', 'R', 'AF', 'AF', 'AF', 'N', 'R', 'R', 'N', 'N', 'AF', 'R', 'N', 'N', 'R', 'AF', 'R', 'R', 'N', 'R', 'N', 'N', 'R', 'N', 'N', 'N', 'AF', 'N', 'N', 'AF', 'N', 'N', 'R', 'N', 'AF', 'R', 'N', 'N', 'R', 'R', 'AF', 'AF', 'R', 'AF', 'N', 'R', 'N', 'N', 'AF', 'AF', 'N', 'R', 'AF', 'N', 'AF', 'AF', 'R', 'AF', 'AF', 'AF', 'R', 'R', 'N', 'N', 'R', 'N', 'N', 'AF', 'N', 'AF', 'R', 'R', 'R', 'AF', 'AF', 'R', 'AF', 'AF', 'R', 'R', 'N', 'AF', 'R', 'AF', 'R', 'AF']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theTotal = []\n",
    "classDict = {}\n",
    "lineCount = 0\n",
    "\n",
    "x = open(\"200_set_of_Norm_AF_Rand.csv\")\n",
    "for line in x:\n",
    "    line = line.strip()\n",
    "    #print(line)\n",
    "    a,b,c,d = line.split(\",\")\n",
    "    if(lineCount != 0):\n",
    "            #normalListTrain.append(b)\n",
    "            theTotal.append(b)\n",
    "            classDict[b] = [\"N\"]\n",
    "            #normalListTest.append(b)\n",
    "            #AFListTrain.append(c)\n",
    "            theTotal.append(c)\n",
    "            classDict[c] = [\"AF\"]\n",
    "            #AFListTest.append(c)\n",
    "            #randomListTest.append(d)\n",
    "            theTotal.append(d)\n",
    "            classDict[\"d\"] = [\"R\"]\n",
    "    lineCount += 1\n",
    "\n",
    "            \n",
    "theFrame = {\"mean\":[],\"std_dev\":[],\"theClass\":[]}\n",
    "\n",
    "theCsv = pd.read_csv(\"Reduced_Pers_Mean_sd_dimension_0.csv\", index_col=0)\n",
    "theCsv2 = pd.read_csv(\"Reduced_Pers_Mean_sd_dimension_1.csv\",index_col=0)\n",
    "theCsv3 = pd.read_csv(\"Reduced_Pers_Mean_sd_dimension_2.csv\",index_col=0)\n",
    "theCsv4 = pd.read_csv(\"Reduced_Pers_Lifetimes_dim_0_1_2.csv\",index_col=0)\n",
    "theCsv5 = pd.read_csv(\"reduced_bottleneck_ave_sd_dim0.csv\",index_col=0)\n",
    "theCsv6 = pd.read_csv(\"reduced_bottleneck_ave_sd_dist_dim1.csv\",index_col=0)\n",
    "theCsv7 = pd.read_csv(\"reduced_bottleneck_ave_sd_dist_dim2.csv\",index_col=0)\n",
    "theCsv8 = pd.read_csv(\"number_of_births_deaths_dim0.csv\",index_col=0)\n",
    "theCsv9 = pd.read_csv(\"number_of_births_deaths_dim1.csv\",index_col=0)\n",
    "theCsv10 = pd.read_csv(\"number_of_births_deaths_dim2.csv\",index_col=0)\n",
    "theCsv11 = pd.read_csv(\"skewness_birth_dim12.csv\",index_col=0)\n",
    "theCsv12 = pd.read_csv(\"skewness_death_dim012.csv\",index_col=0)\n",
    "theCsv13 = pd.read_csv(\"kurtosis_birth_dim12.csv\",index_col=0)\n",
    "theCsv14 = pd.read_csv(\"kurtosis_death_dim012.csv\",index_col=0)\n",
    "#theCsv8 = pd.read_csv(\"reduced_bottleneck_ave_sd_dist_dim2.csv\",index_col=0)\n",
    "#bigData = theCsv.append(theCsv2, ignore_index=True)\n",
    "\n",
    "#print(bigData)\n",
    "\n",
    "aList = []\n",
    "aList2 = []\n",
    "aList3 = []\n",
    "for i in range(0,200):\n",
    "    aList.append(\"N\")\n",
    "    aList2.append(0)\n",
    "    aList3.append(0)\n",
    "\n",
    "for i in range(0,200):\n",
    "    aList.append(\"AF\")\n",
    "    aList2.append(1)\n",
    "    aList3.append(0)\n",
    "    \n",
    "for i in range(0,200):\n",
    "    aList.append(\"R\")\n",
    "    aList2.append(0)\n",
    "    aList3.append(1)\n",
    "\n",
    "#theCsv[\"Normal\"] = np.asarray(aList)\n",
    "#theCsv[\"AF\"] = np.asarray(aList2)\n",
    "#theCsv[\"Random\"] = np.asarray(aList3)\n",
    "#### make dataframe \n",
    "###\n",
    "#bigData  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#theCsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Means_dim0_birth  Means_dim0_death  sd_dim0_birth  sd_dim0_death  \\\n",
      "1                   0          0.598550              0       0.325249   \n",
      "2                   0          0.769444              0       0.422174   \n",
      "3                   0          0.422764              0       0.169927   \n",
      "4                   0          0.329685              0       0.157529   \n",
      "5                   0          0.444172              0       0.199625   \n",
      "6                   0          0.415409              0       0.142401   \n",
      "7                   0          0.487156              0       0.117997   \n",
      "8                   0          0.223625              0       0.081608   \n",
      "9                   0          0.835012              0       0.314351   \n",
      "10                  0          0.876449              0       0.442794   \n",
      "11                  0          0.245021              0       0.081972   \n",
      "12                  0          0.537592              0       0.380163   \n",
      "13                  0          0.313160              0       0.133355   \n",
      "14                  0          0.913464              0       0.279195   \n",
      "15                  0          0.300976              0       0.127002   \n",
      "16                  0          0.893381              0       0.373875   \n",
      "17                  0          0.633013              0       0.135913   \n",
      "18                  0          1.140010              0       0.360468   \n",
      "19                  0          0.787729              0       0.338633   \n",
      "20                  0          0.710843              0       0.174307   \n",
      "21                  0          1.152414              0       0.767847   \n",
      "22                  0          0.639620              0       0.481503   \n",
      "23                  0          0.711189              0       0.197527   \n",
      "24                  0          0.396955              0       0.198593   \n",
      "25                  0          1.217304              0       0.643141   \n",
      "26                  0          0.574782              0       0.336467   \n",
      "27                  0          0.848572              0       0.237090   \n",
      "28                  0          1.063943              0       0.484311   \n",
      "29                  0          0.860867              0       0.271795   \n",
      "30                  0          0.357090              0       0.148263   \n",
      "..                ...               ...            ...            ...   \n",
      "571                 0          2.032057              0       0.695359   \n",
      "572                 0          1.086241              0       0.373980   \n",
      "573                 0          1.306506              0       0.480511   \n",
      "574                 0          1.335675              0       1.025286   \n",
      "575                 0          0.944797              0       0.484791   \n",
      "576                 0          2.042231              0       0.672383   \n",
      "577                 0          0.966941              0       0.347803   \n",
      "578                 0          0.263831              0       0.068312   \n",
      "579                 0          0.828338              0       0.184340   \n",
      "580                 0          2.109686              0       0.408663   \n",
      "581                 0          1.762157              0       0.764576   \n",
      "582                 0          1.514601              0       0.454889   \n",
      "583                 0          0.567754              0       0.340497   \n",
      "584                 0          2.285339              0       1.446577   \n",
      "585                 0          3.001147              0       2.829302   \n",
      "586                 0          1.039154              0       1.013890   \n",
      "587                 0          1.196421              0       0.469518   \n",
      "588                 0          0.273497              0       0.140318   \n",
      "589                 0          1.186527              0       0.366699   \n",
      "590                 0          2.121315              0       1.209431   \n",
      "591                 0          1.643915              0       0.470013   \n",
      "592                 0          0.367983              0       0.070054   \n",
      "593                 0          3.411767              0       0.469826   \n",
      "594                 0          0.710974              0       0.092038   \n",
      "595                 0          2.087713              0       2.201413   \n",
      "596                 0          0.578447              0       0.168414   \n",
      "597                 0          3.331093              0       2.420588   \n",
      "598                 0          2.555481              0       2.760034   \n",
      "599                 0          0.951689              0       0.220347   \n",
      "600                 0          0.204416              0       0.328289   \n",
      "\n",
      "     Means_dim1_birth  Means_dim1_death  sd_dim1_birth  sd_dim1_death  \\\n",
      "1            1.284435          1.284435       0.313212       0.314137   \n",
      "2            0.691411          0.691411       0.192202       0.201836   \n",
      "3            0.782745          0.782745       0.382480       0.419952   \n",
      "4            0.461572          0.461572       0.193760       0.200632   \n",
      "5            0.830100          0.830100       0.423910       0.450631   \n",
      "6            0.597036          0.597036       0.192414       0.188718   \n",
      "7            0.786389          0.786389       0.343099       0.407018   \n",
      "8            0.385175          0.385175       0.210120       0.240807   \n",
      "9            1.144442          1.144442       0.381452       0.382397   \n",
      "10           1.432237          1.432237       0.411485       0.439688   \n",
      "11           0.369096          0.369096       0.137954       0.149169   \n",
      "12           0.686811          0.686811       0.214156       0.226297   \n",
      "13           0.629557          0.629557       0.352562       0.368346   \n",
      "14           1.297229          1.297229       0.579653       0.574725   \n",
      "15           0.538179          0.538179       0.300642       0.338293   \n",
      "16           1.295717          1.295717       0.280585       0.354474   \n",
      "17           0.861261          0.861261       0.355476       0.422977   \n",
      "18           1.728994          1.728994       0.638648       0.673556   \n",
      "19           1.364652          1.364652       1.235272       1.613931   \n",
      "20           1.007454          1.007454       0.236842       0.248333   \n",
      "21           1.642072          1.642072       1.598830       1.774963   \n",
      "22           0.654435          0.654435       0.815272       1.104542   \n",
      "23           1.169777          1.169777       0.445554       0.429771   \n",
      "24           0.674123          0.674123       0.262384       0.278650   \n",
      "25           1.979452          1.979452       0.702800       0.778056   \n",
      "26           1.268732          1.268732       0.558765       0.583114   \n",
      "27           1.011814          1.011814       0.162762       0.180054   \n",
      "28           1.666648          1.666648       0.944572       1.022676   \n",
      "29           1.163423          1.163423       0.369480       0.418245   \n",
      "30           0.486765          0.486765       0.133055       0.132667   \n",
      "..                ...               ...            ...            ...   \n",
      "571          3.265097          3.265097       1.186269       1.455257   \n",
      "572          1.361555          1.361555       0.566658       0.658613   \n",
      "573          1.901435          1.901435       0.947743       1.056165   \n",
      "574          1.743563          1.743563       1.456333       1.731958   \n",
      "575          1.494539          1.494539       1.618121       2.162564   \n",
      "576          2.837703          2.837703       0.962174       1.034347   \n",
      "577          1.538946          1.538946       0.471370       0.499525   \n",
      "578          0.851071          0.851071       0.391018       0.399763   \n",
      "579          1.362482          1.362482       0.434493       0.482239   \n",
      "580          2.512398          2.512398       0.386706       0.457353   \n",
      "581          2.611204          2.611204       1.239935       1.355501   \n",
      "582          1.472145          1.472145       0.341055       0.338298   \n",
      "583          0.550301          0.550301       0.260488       0.259932   \n",
      "584          2.551591          2.551591       1.920823       2.385201   \n",
      "585          1.414272          1.414272       3.306665       4.436312   \n",
      "586          1.729950          1.729950       1.339197       1.439646   \n",
      "587          1.361701          1.361701       0.451375       0.427143   \n",
      "588          0.582321          0.582321       0.423588       0.443422   \n",
      "589          3.397923          3.397923       1.197246       1.260684   \n",
      "590          2.616019          2.616019       1.658117       1.865390   \n",
      "591          2.572121          2.572121       1.173522       1.264618   \n",
      "592          0.741728          0.741728       0.308462       0.306384   \n",
      "593          3.491103          3.491103       0.257966       0.235569   \n",
      "594          0.721031          0.721031       0.063021       0.056340   \n",
      "595          4.364224          4.364224       3.003316       3.260256   \n",
      "596          0.883425          0.883425       0.450514       0.484753   \n",
      "597          2.460673          2.460673       2.107810       2.266861   \n",
      "598          4.090383          4.090383       3.338844       3.571901   \n",
      "599          1.030507          1.030507       0.121454       0.129681   \n",
      "600          0.430807          0.430807       0.682598       0.679984   \n",
      "\n",
      "     Means_dim2_birth  Means_dim2_death       ...        avg_bottle_dist_dim2  \\\n",
      "1            1.561889          1.561889       ...                    0.061541   \n",
      "2            0.858379          0.858379       ...                    0.062474   \n",
      "3            0.936557          0.936557       ...                    0.057456   \n",
      "4            0.670767          0.670767       ...                    0.056214   \n",
      "5            1.247428          1.247428       ...                    0.092483   \n",
      "6            0.790674          0.790674       ...                    0.055660   \n",
      "7            1.142985          1.142985       ...                    0.055489   \n",
      "8            0.372033          0.372033       ...                    0.073313   \n",
      "9            1.589180          1.589180       ...                    0.062855   \n",
      "10           1.990209          1.990209       ...                    0.069199   \n",
      "11           0.478308          0.478308       ...                    0.055068   \n",
      "12           0.614864          0.614864       ...                    0.087400   \n",
      "13           0.899480          0.899480       ...                    0.092332   \n",
      "14           1.687923          1.687923       ...                    0.083215   \n",
      "15           0.651271          0.651271       ...                    0.055106   \n",
      "16           1.643321          1.643321       ...                    0.056343   \n",
      "17           0.953622          0.953622       ...                    0.055091   \n",
      "18           1.921403          1.921403       ...                    0.055299   \n",
      "19           1.441518          1.441518       ...                    0.065575   \n",
      "20           1.273168          1.273168       ...                    0.055148   \n",
      "21           2.403754          2.403754       ...                    0.070142   \n",
      "22           0.577017          0.577017       ...                    0.077517   \n",
      "23           1.512870          1.512870       ...                    0.094515   \n",
      "24           0.845724          0.845724       ...                    0.056772   \n",
      "25           3.314061          3.314061       ...                    0.078752   \n",
      "26           5.115427          5.115427       ...                    0.133837   \n",
      "27           1.258359          1.258359       ...                    0.065132   \n",
      "28           1.646384          1.646384       ...                    0.070099   \n",
      "29           1.294558          1.294558       ...                    0.059836   \n",
      "30           0.640478          0.640478       ...                    0.073940   \n",
      "..                ...               ...       ...                         ...   \n",
      "571          3.446914          3.446914       ...                    0.174801   \n",
      "572          1.649356          1.649356       ...                    0.071184   \n",
      "573          1.673315          1.673315       ...                    0.117903   \n",
      "574          1.176934          1.176934       ...                    0.055088   \n",
      "575          1.816016          1.816016       ...                    0.060595   \n",
      "576          2.924431          2.924431       ...                    0.079696   \n",
      "577          1.740199          1.740199       ...                    0.130372   \n",
      "578          0.765161          0.765161       ...                    0.055217   \n",
      "579          1.508548          1.508548       ...                    0.065747   \n",
      "580          3.144668          3.144668       ...                    0.129220   \n",
      "581          3.337556          3.337556       ...                    0.123816   \n",
      "582          1.596274          1.596274       ...                    0.058558   \n",
      "583          0.939860          0.939860       ...                    0.055407   \n",
      "584          1.695611          1.695611       ...                    0.066002   \n",
      "585          1.348981          1.348981       ...                    0.058193   \n",
      "586          1.662019          1.662019       ...                    0.060872   \n",
      "587          1.406188          1.406188       ...                    0.070761   \n",
      "588          0.502764          0.502764       ...                    0.055114   \n",
      "589          3.528633          3.528633       ...                    0.066438   \n",
      "590          2.574910          2.574910       ...                    0.102798   \n",
      "591          2.628700          2.628700       ...                    0.160086   \n",
      "592          0.839176          0.839176       ...                    0.056420   \n",
      "593          3.723754          3.723754       ...                    0.145463   \n",
      "594          0.783939          0.783939       ...                    0.057578   \n",
      "595          2.418486          2.418486       ...                    0.056332   \n",
      "596          1.462797          1.462797       ...                    0.057270   \n",
      "597          1.305100          1.305100       ...                    0.061278   \n",
      "598          4.603214          4.603214       ...                    0.060142   \n",
      "599          1.149985          1.149985       ...                    0.059426   \n",
      "600          0.093008          0.093008       ...                    0.055066   \n",
      "\n",
      "     sd_bottle_dist_dim2  num_dim0  num_dim2  skew_death1  skew_death2  \\\n",
      "1               0.072998       690       120    -0.180632     0.563984   \n",
      "2               0.072875       690        62    -0.983487    -1.532287   \n",
      "3               0.074710       690       363     0.535746     1.272393   \n",
      "4               0.075185       690       109    -0.146649    -1.948632   \n",
      "5               0.066193       690        26    -0.576041    -0.510067   \n",
      "6               0.075681       690       113     1.558897     0.734677   \n",
      "7               0.075710       690       101     2.452916     2.157282   \n",
      "8               0.069835       690         4    -0.176425     0.707106   \n",
      "9               0.072846       690       156    -0.186800    -1.135454   \n",
      "10              0.071034       690       158    -0.777945     0.243424   \n",
      "11              0.076072       690        43     0.610134    -0.161541   \n",
      "12              0.067061       690         2    -0.336854     1.625699   \n",
      "13              0.066114       690         9    -0.057204    -3.090184   \n",
      "14              0.067716       690        97     2.088273     1.626180   \n",
      "15              0.076035       690        11     0.155053     0.000199   \n",
      "16              0.075356       690       133    -1.289862     0.222988   \n",
      "17              0.076036       690       352     3.303857     0.060032   \n",
      "18              0.075774       690        67     0.635853     1.250785   \n",
      "19              0.071919       690       102     2.504677     2.152506   \n",
      "20              0.075993       690       262     0.254586    -0.711558   \n",
      "21              0.070641       690        57     1.344356     1.022715   \n",
      "22              0.069048       690       303     4.462882    -0.647052   \n",
      "23              0.065832       690       150     1.963278     0.555109   \n",
      "24              0.075075       690        72    -0.116391     0.781148   \n",
      "25              0.068797       690       165    -0.073595     1.646291   \n",
      "26              0.060458       690        19     1.548622     0.018101   \n",
      "27              0.071905       690       240    -1.059336    -0.302240   \n",
      "28              0.070753       690       165     1.420271     0.747406   \n",
      "29              0.073874       690       119     0.361393     0.872945   \n",
      "30              0.069588       690       149    -0.273740     0.418000   \n",
      "..                   ...       ...       ...          ...          ...   \n",
      "571             0.056356       690       219     1.689669     3.608745   \n",
      "572             0.070330       690       135     1.667449     1.465152   \n",
      "573             0.062756       690       180     1.186420     1.016963   \n",
      "574             0.075956       690        35     1.578968     1.308941   \n",
      "575             0.073534       690        94     1.578025     1.121061   \n",
      "576             0.068452       690       107     0.370786     0.784570   \n",
      "577             0.061093       690       231     1.104847     1.476431   \n",
      "578             0.075929       690        52     0.105992     0.084373   \n",
      "579             0.071813       690       278     1.511693     1.397986   \n",
      "580             0.061102       690       331     0.396910     1.277460   \n",
      "581             0.061788       690        71     0.261857     0.674745   \n",
      "582             0.074247       690       173    -0.185073     0.119708   \n",
      "583             0.075840       690        49     0.783679     1.358081   \n",
      "584             0.071713       690        72     2.058921    -0.280842   \n",
      "585             0.074466       690       125     3.944573     0.042216   \n",
      "586             0.073431       690       117     1.152211     1.636616   \n",
      "587             0.070547       690       116     0.791469    -0.203693   \n",
      "588             0.076038       690        75     0.842995     0.791578   \n",
      "589             0.071634       690        25     0.042168    -0.337320   \n",
      "590             0.064476       690       148     1.172728     2.843525   \n",
      "591             0.057757       690       257     1.857567     0.853789   \n",
      "592             0.075254       690       118     3.267186     0.003800   \n",
      "593             0.059313       690      1942     0.466109     0.207401   \n",
      "594             0.074734       690       120     0.510906     0.292201   \n",
      "595             0.075282       690        44    -0.028848     2.300833   \n",
      "596             0.074877       690        39     1.530188     0.162684   \n",
      "597             0.073218       690       114     0.836754     1.053887   \n",
      "598             0.073708       690       113     0.489360     0.513846   \n",
      "599             0.073794       690       600     0.144650     0.723706   \n",
      "600             0.076073       690        29     2.056136     4.184859   \n",
      "\n",
      "     skew_birth2  katorsis1  katorsis0  katorsisBirth1  \n",
      "1       0.655589  -0.180632   0.214888        0.655589  \n",
      "2      -1.839043  -0.983487   0.006570       -1.839043  \n",
      "3       1.284825   0.535746   1.170836        1.284825  \n",
      "4      -2.030569  -0.146649  -0.072532       -2.030569  \n",
      "5      -0.538198  -0.576041  -0.194996       -0.538198  \n",
      "6       0.787484   1.558897   1.158602        0.787484  \n",
      "7       2.239437   2.452916  -0.426374        2.239437  \n",
      "8       0.707078  -0.176425   1.699154        0.707078  \n",
      "9      -0.785742  -0.186800   0.023680       -0.785742  \n",
      "10     -0.011514  -0.777945   1.108318       -0.011514  \n",
      "11     -0.132375   0.610134   0.346481       -0.132375  \n",
      "12      1.621421  -0.336854   0.988516        1.621421  \n",
      "13     -3.047589  -0.057204   1.928578       -3.047589  \n",
      "14      1.636639   2.088273  -0.685096        1.636639  \n",
      "15     -0.000018   0.155053   0.600617       -0.000018  \n",
      "16      0.368845  -1.289862  -0.338114        0.368845  \n",
      "17      0.478087   3.303857   0.492033        0.478087  \n",
      "18      1.239002   0.635853  -0.772677        1.239002  \n",
      "19      2.150569   2.504677   0.441409        2.150569  \n",
      "20     -0.712221   0.254586   0.212995       -0.712221  \n",
      "21      1.020350   1.344356   0.229845        1.020350  \n",
      "22     -0.705151   4.462882   1.349137       -0.705151  \n",
      "23      0.732403   1.963278  -1.182396        0.732403  \n",
      "24      0.771551  -0.116391   0.901381        0.771551  \n",
      "25      1.710797  -0.073595   0.669532        1.710797  \n",
      "26      0.017156   1.548622   0.451043        0.017156  \n",
      "27     -0.100032  -1.059336  -1.426761       -0.100032  \n",
      "28      0.717866   1.420271   0.483860        0.717866  \n",
      "29      0.871158   0.361393  -0.488488        0.871158  \n",
      "30      0.313205  -0.273740   0.025051        0.313205  \n",
      "..           ...        ...        ...             ...  \n",
      "571     3.662403   1.689669   0.084122        3.662403  \n",
      "572     1.506883   1.667449  -0.486118        1.506883  \n",
      "573     1.281736   1.186420   0.108166        1.281736  \n",
      "574     1.302556   1.578968   0.599188        1.302556  \n",
      "575     1.141186   1.578025   0.138391        1.141186  \n",
      "576     0.793361   0.370786   0.515692        0.793361  \n",
      "577     1.636480   1.104847  -0.197533        1.636480  \n",
      "578     0.070036   0.105992   0.400497        0.070036  \n",
      "579     1.419013   1.511693  -0.496061        1.419013  \n",
      "580     1.510509   0.396910  -0.550794        1.510509  \n",
      "581     0.724097   0.261857  -0.231734        0.724097  \n",
      "582     0.167504  -0.185073  -0.225731        0.167504  \n",
      "583     1.361721   0.783679   0.310880        1.361721  \n",
      "584    -0.311121   2.058921  -0.019232       -0.311121  \n",
      "585     0.035910   3.944573   0.319040        0.035910  \n",
      "586     1.656057   1.152211   1.982573        1.656057  \n",
      "587     0.013419   0.791469   0.584061        0.013419  \n",
      "588     0.802201   0.842995   0.010791        0.802201  \n",
      "589    -0.325822   0.042168  -0.263664       -0.325822  \n",
      "590     2.890054   1.172728   0.176946        2.890054  \n",
      "591     0.849296   1.857567  -0.449137        0.849296  \n",
      "592     0.011522   3.267186  -0.542130        0.011522  \n",
      "593     0.368809   0.466109   0.157929        0.368809  \n",
      "594     0.558179   0.510906  -0.168111        0.558179  \n",
      "595     2.298905  -0.028848   1.028089        2.298905  \n",
      "596     0.161420   1.530188   0.381097        0.161420  \n",
      "597     1.141602   0.836754   0.013449        1.141602  \n",
      "598     0.513550   0.489360   1.179306        0.513550  \n",
      "599     0.823865   0.144650   0.107928        0.823865  \n",
      "600     4.185813   2.056136   1.675942        4.185813  \n",
      "\n",
      "[600 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "#theCsv2.loc[599] =[0,0,0,0]\n",
    "#theCsv2.loc[600] =[0,0,0,0]\n",
    "#theCsv2\n",
    "#bigdata = pd.concat([theCsv, theCsv2])\n",
    "\n",
    "theCsv[\"Means_dim1_birth\"] = theCsv2[\"Means_dim1_birth\"]\n",
    "theCsv[\"Means_dim1_death\"] = theCsv2[\"Means_dim1_birth\"]\n",
    "theCsv[\"sd_dim1_birth\"] = theCsv2[\"sd_dim1_birth\"]\n",
    "theCsv[\"sd_dim1_death\"] =theCsv2[\"sd_dim1_death\"]\n",
    "\n",
    "theCsv[\"Means_dim2_birth\"] = theCsv3[\"Means_dim2_birth\"]\n",
    "theCsv[\"Means_dim2_death\"] = theCsv3[\"Means_dim2_birth\"]\n",
    "theCsv[\"sd_dim2_birth\"] = theCsv3[\"sd_dim2_birth\"]\n",
    "theCsv[\"sd_dim2_death\"] =theCsv3[\"sd_dim2_death\"]\n",
    "\n",
    "#theCsv[\"Means_dim0_birth\"] = theCsv4[\"Means_dim0_birth\"]\n",
    "#theCsv[\"Means_dim0_death\"] = theCsv4[\"Means_dim0_birth\"]\n",
    "#theCsv[\"sd_dim0_birth\"] = theCsv4[\"sd_dim0_birth\"]\n",
    "#theCsv[\"sd_dim0_death\"] =theCsv4[\"sd_dim0_death\"]\n",
    "\n",
    "theCsv[\"Lifetime_dim0\"] = theCsv4[\"Lifetime_dim0\"]\n",
    "theCsv[\"Lifetime_dim1\"] = theCsv4[\"Lifetime_dim1\"]\n",
    "theCsv[\"Lifetime_dim2\"] =theCsv4[\"Lifetime_dim2\"]\n",
    "\n",
    "\n",
    "theCsv[\"avg_bottle_dist_dim0\"] =theCsv5[\"V1\"]\n",
    "theCsv[\"sd_bottle_dist_dim0\"] =theCsv5[\"V2\"]\n",
    "\n",
    "\n",
    "theCsv[\"avg_bottle_dist_dim1\"] =theCsv6[\"V1\"]\n",
    "theCsv[\"sd_bottle_dist_dim1\"] =theCsv6[\"V2\"]\n",
    "\n",
    "theCsv[\"avg_bottle_dist_dim2\"] =theCsv7[\"V1\"]\n",
    "theCsv[\"sd_bottle_dist_dim2\"] =theCsv7[\"V2\"]\n",
    "\n",
    "theCsv[\"num_dim0\"] = theCsv8[\"x\"]\n",
    "#theCsv[\"num_dim1\"] = theCsv9[\"x\"]\n",
    "theCsv[\"num_dim2\"] = theCsv10[\"x\"]\n",
    "\n",
    "#theCsv[\"num_dim1\"] = theCsv10[\"x\"]\n",
    "\n",
    "theCsv[\"skew_death1\"] =theCsv12[\"skew.death.dim1\"]\n",
    "theCsv[\"skew_death2\"] =theCsv12[\"skew.death.dim2\"]\n",
    "#theCsv[\"skew_death0\"] =theCsv12[\"skew.death.dim0\"]\n",
    "\n",
    "\n",
    "#theCsv[\"skew_birth1\"] = theCsv11[\"skew.birth.dim1\"]\n",
    "theCsv[\"skew_birth2\"] = theCsv11[\"skew.birth.dim2\"]\n",
    "\n",
    "theCsv[\"katorsis1\"] =theCsv14[\"kurt.death.dim1\"]\n",
    "#theCsv[\"katorsis2\"] =theCsv14[\"kurt.death.dim2\"]\n",
    "theCsv[\"katorsis0\"] =theCsv14[\"kurt.death.dim0\"]\n",
    "\n",
    "\n",
    "theCsv[\"katorsisBirth1\"] = theCsv13[\"kurt.birth.dim1\"]\n",
    "theCsv[\"katorsisBirth1\"] = theCsv13[\"kurt.birth.dim2\"]\n",
    "\n",
    "\n",
    "\n",
    "print(theCsv)\n",
    "#theCsv\n",
    "#print(np.isnan(theCsv))\n",
    "theCsv[\"Normal\"] = np.asarray(aList)\n",
    "#theCsv\n",
    "\n",
    "#theCsv.fillna(theCsv.mean())\n",
    "\n",
    "#print(np.where(theCsv.values >= np.finfo(np.float64).max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### code from meduim torwards data scienec example\n",
    "# Labels are the values we want to pred\n",
    "\n",
    "labels = np.array(theCsv[\"Normal\"])\n",
    "\n",
    "# Remove the labels from the features\n",
    "# axis 1 refers to the columns\n",
    "theCsv = theCsv.drop('Normal', axis = 1)\n",
    "#theCsv = theCsv.drop('AF', axis = 1)\n",
    "#theCsv = theCsv.drop('Random', axis = 1)\n",
    "\n",
    "# Saving feature names for later use\n",
    "feature_list = list(theCsv.columns)\n",
    "\n",
    "# Convert to numpy array\n",
    "features = np.array(theCsv)\n",
    "\n",
    "\n",
    "# Using Skicit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(theCsv, labels, test_size = 0.33, random_state = 42)\n",
    "\n",
    "\n",
    "#print(test_labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the model we are using\n",
    "#from sklearn.ensemble import RandomForest\n",
    "predict_list = []\n",
    "# Instantiate model with 1000 decision trees\n",
    "for i in range(0,300):\n",
    "    #rf = RandomForestClassifier(bootstrap=True,max_depth=20,max_features=\"sqrt\",min_samples_leaf=4,min_samples_split=10,n_estimators=50,random_state=118)\n",
    "    rf = RandomForestClassifier(bootstrap=True,max_depth=20,max_features=\"sqrt\",min_samples_leaf=4,min_samples_split=10,n_estimators=50,random_state=i)\n",
    "\n",
    "# Train the model on training data\n",
    "    rf.fit(train_features, train_labels)\n",
    "\n",
    "    predictions = rf.predict(test_features)\n",
    "    predict_list.append(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N' 'N' 'R' 'N' 'N' 'AF' 'R' 'R' 'N' 'AF' 'AF' 'N' 'R' 'R' 'AF' 'AF' 'R'\n",
      " 'N' 'N' 'N' 'N' 'R' 'R' 'R' 'AF' 'R' 'N' 'R' 'R' 'N' 'R' 'R' 'N' 'AF' 'AF'\n",
      " 'R' 'N' 'R' 'N' 'AF' 'R' 'N' 'R' 'R' 'R' 'N' 'R' 'N' 'N' 'R' 'AF' 'AF' 'N'\n",
      " 'R' 'N' 'R' 'N' 'N' 'N' 'AF' 'N' 'N' 'N' 'R' 'R' 'R' 'R' 'R' 'AF' 'AF'\n",
      " 'AF' 'AF' 'N' 'AF' 'R' 'N' 'AF' 'AF' 'R' 'R' 'N' 'R' 'AF' 'N' 'N' 'N' 'AF'\n",
      " 'AF' 'AF' 'AF' 'R' 'AF' 'N' 'AF' 'N' 'AF' 'AF' 'N' 'R' 'N' 'N' 'N' 'R'\n",
      " 'AF' 'N' 'N' 'AF' 'N' 'AF' 'R' 'AF' 'R' 'R' 'R' 'AF' 'AF' 'AF' 'R' 'N' 'R'\n",
      " 'AF' 'N' 'AF' 'R' 'N' 'R' 'R' 'AF' 'R' 'R' 'N' 'R' 'R' 'N' 'R' 'N' 'AF'\n",
      " 'N' 'AF' 'AF' 'AF' 'N' 'AF' 'R' 'R' 'AF' 'N' 'R' 'AF' 'AF' 'N' 'R' 'AF'\n",
      " 'AF' 'R' 'AF' 'AF' 'R' 'AF' 'R' 'R' 'N' 'N' 'N' 'AF' 'N' 'N' 'N' 'N' 'AF'\n",
      " 'N' 'N' 'R' 'R' 'AF' 'AF' 'AF' 'AF' 'N' 'AF' 'AF' 'AF' 'R' 'R' 'AF' 'AF'\n",
      " 'R' 'AF' 'N' 'N' 'R' 'R' 'AF' 'AF' 'R' 'AF' 'R' 'N']\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N' 'R' 'R' 'N' 'N' 'AF' 'N' 'R' 'N' 'AF' 'N' 'N' 'N' 'R' 'AF' 'AF' 'N'\n",
      " 'AF' 'N' 'N' 'N' 'R' 'R' 'R' 'AF' 'R' 'N' 'N' 'R' 'R' 'R' 'N' 'N' 'AF' 'N'\n",
      " 'R' 'N' 'R' 'R' 'AF' 'AF' 'N' 'R' 'R' 'N' 'N' 'R' 'N' 'N' 'R' 'AF' 'AF'\n",
      " 'N' 'R' 'R' 'AF' 'AF' 'N' 'N' 'N' 'N' 'N' 'AF' 'R' 'R' 'N' 'R' 'R' 'N'\n",
      " 'AF' 'AF' 'N' 'R' 'AF' 'R' 'R' 'AF' 'AF' 'R' 'R' 'AF' 'R' 'R' 'AF' 'N' 'N'\n",
      " 'N' 'AF' 'AF' 'AF' 'AF' 'R' 'N' 'AF' 'AF' 'AF' 'AF' 'N' 'R' 'N' 'N' 'AF'\n",
      " 'R' 'AF' 'N' 'R' 'N' 'AF' 'AF' 'R' 'N' 'R' 'R' 'R' 'AF' 'AF' 'AF' 'N' 'R'\n",
      " 'R' 'N' 'N' 'AF' 'R' 'N' 'N' 'R' 'AF' 'R' 'R' 'N' 'R' 'N' 'N' 'R' 'N' 'N'\n",
      " 'N' 'AF' 'N' 'N' 'AF' 'N' 'N' 'R' 'N' 'AF' 'R' 'N' 'N' 'R' 'R' 'AF' 'AF'\n",
      " 'R' 'AF' 'N' 'R' 'N' 'N' 'AF' 'AF' 'N' 'R' 'AF' 'N' 'AF' 'AF' 'R' 'AF'\n",
      " 'AF' 'AF' 'R' 'R' 'N' 'N' 'R' 'N' 'N' 'AF' 'N' 'AF' 'R' 'R' 'R' 'AF' 'AF'\n",
      " 'R' 'AF' 'AF' 'R' 'R' 'N' 'AF' 'R' 'AF' 'R' 'AF']\n"
     ]
    }
   ],
   "source": [
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.636363636364\n"
     ]
    }
   ],
   "source": [
    "theMax = 0\n",
    "for i in range(0,300):    \n",
    "    if(accuracy_score(test_labels, predict_list[i]) > theMax):\n",
    "        theMax = accuracy_score(test_labels, predict_list[i])\n",
    "print(theMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[38 18  5]\n",
      " [23 36 12]\n",
      " [ 5 11 50]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.62657222026813209"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = confusion_matrix(test_labels, predictions,labels=[\"AF\", \"N\", \"R\"])\n",
    "print(results)\n",
    "np.average(f1_score(test_labels, predictions, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGfCAYAAAB1KinVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAMByCCgAAMByCCgAAMBy/h+HigvWTd37DQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1af0cecf60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "sn.set(font_scale=1.5)\n",
    "array = [[38, 18,  5],\n",
    " [23, 36, 12],\n",
    " [ 5, 11, 50]]\n",
    "df_cm = pd.DataFrame(array, index = [\"AF\",\"N\",\"R\"],\n",
    "                  columns = [\"AF\",\"N\",\"R\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True)\n",
    "plt.savefig(\"tuff.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "random_grid ={'bootstrap': [True, False],\n",
    " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    " 'max_features': ['auto', 'sqrt'],\n",
    " 'min_samples_leaf': [1, 2, 4],\n",
    " 'min_samples_split': [2, 5, 10],\n",
    " 'n_estimators': [10,15,20,25,30,50,100,200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "#rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 500, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "#rf_random.fit(train_features, train_labels)\n",
    "\n",
    "#rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7076828762553866\n"
     ]
    }
   ],
   "source": [
    "var1 = 36/(29+28)\n",
    "var2 = 48/(31+39)\n",
    "var3 = 112/(73+66)\n",
    "\n",
    "print((var1+var2+var3)/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
